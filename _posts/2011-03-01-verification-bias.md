---
title: Verification Bias
author: [CL_AT_JonelleMPetscavageMDMPH,CL_AT_MichaelLRichardsonMD,CL_AT_RobertBCarrMD]
date: 2011-03-01 00:00:00 +0700 +07
categories: [Academic Radiology, Volume 18, Issue 3]
tags: [Journals,General Radiology]
---
## Rationale and Objectives

Diagnostic tests are validated by comparison against a “gold standard” reference test. When the reference test is invasive or expensive, it may not be applied to all patients. This can result in biased estimates of the sensitivity and specificity of the diagnostic test. This type of bias is called “verification bias,” and is a common problem in imaging research. The purpose of our study is to estimate the prevalence of verification bias in the recent radiology literature.

## Materials and Methods

All issues of the _American Journal of Roentgenology_ ( _AJR_ ), _Academic Radiology_ , _Radiology_ , and _European Journal of Radiology_ ( _EJR_ ) between November 2006 and October 2009 were reviewed for original research articles mentioning sensitivity or specificity as endpoints. Articles were read to determine whether verification bias was present and searched for author recognition of verification bias in the design.

## Results

During 3 years, these journals published 2969 original research articles. A total of 776 articles used sensitivity or specificity as an outcome. Of these, 211 articles demonstrated potential verification bias. The fraction of articles with potential bias was respectively 36.4%, 23.4%, 29.5%, and 13.4% for _AJR_ , _Academic Radiology_ , _Radiology,_ and _EJR_ . The total fraction of papers with potential bias in which the authors acknowledged this bias was 17.1%.

## Conclusion

Verification bias is a common and frequently unacknowledged source of error in efficacy studies of diagnostic imaging. Bias can often be eliminated by proper study design. When it cannot be eliminated, it should be estimated and acknowledged.

New diagnostic tests are validated by comparing them against a “gold standard” reference test. Key indices of the efficacy of a test include sensitivity and specificity and receiver operator curves (ROC). When the reference test is invasive or expensive, it may not be applied to all patients. This can lead to biased estimates of the sensitivity and specificity of the diagnostic test . This type of bias is called “verification bias,” “workup bias,” or “posttest referral bias.” Verification bias is a common problem in imaging research, particularly in retrospective studies. This type of bias is introduced if patients receiving the test of interest are not equally likely to undergo the reference standard to verify their diagnosis and only those who receive the “gold standard” are included in the statistical analysis .

Additional forms of verification bias occur when an inappropriate reference standard is used or when patients are verified using different reference standards in the same study . Verification bias tends to falsely inflate estimates of sensitivity and falsely deflate estimates of specificity and decrease the area under the ROC. Clinicians consider estimates of sensitivity and specificity when choosing one diagnostic radiology examination over another. Thus, the false estimates may result in a patient undergoing a diagnostic examination that is not the most accurate for diagnosis. For certain examinations, such as computed tomography or fluoroscopy, this results in unnecessary radiation exposure. Additionally, verification bias can result in false trust in the imaging examination’s ability to rule in or out a diagnosis. This may adversely alter clinical decisions to admit or discharge a patient, medically versus surgically treat a patient, or order additional tests.

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Materials and methods

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Results

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

![Figure 1, Flowchart of data collected from original research articles in four journals, November 2006−October 2009.](https://storage.googleapis.com/dl.dentistrykey.com/clinical/VerificationBias/0_1s20S1076633210005726.jpg)

Table 1


Frequency Table of Data Collected from Original Research Articles in Four Journals, November 2006−October 2009


American Journal of Roentgenology Academic Radiology Radiology European Journal of Radiology All Original research articles 1,004 422 1,043 500 2,969 Sensitivity and specificity listed as study end point (%) 24.7 19.2 24.9 37.4 26.1 Potential verification bias (%) 36.4 23.4 29.5 13.4 27.2 Bias acknowledged in discussion (%) 4.4 26.3 28.9 20 17.1

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Discussion

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## References

- 1\. Zhou X.H., Obuchowski N.A., Obuchowski D.M.: Statistical Methods in Diagnostic Medicine.2002.Wiley & SonsNew York


- 2\. Sica G.T.: Bias in research studies. Radiology 2006; 238: pp. 780-789.


- 3\. Begg C.B.: Biases in the assessment of diagnostic tests. Stat Med 1987; 6: pp. 411-423.


- 4\. Revesz G., Kundel H.L., Bonitatibus M.: The effect of verification on the assessment of imaging techniques. Invest Radiol 1990; 25: pp. 461.


- 5\. Kosinski A.S., Barnhart H.X.: A global sensitivity analysis of performance of a medical diagnostic test when verification bias is present. Stat Med 2003; 22: pp. 2711-2721.


- 6\. Whiting P., Rutjies A.W., Reitsman J.B., et. al.: Sources of verification and bias in studies of diagnostic accuracy—a systematic review. Ann Intern Med 2004; 140: pp. 189-202.


- 7\. Bates A.S., Margolis P.A., Evans A.T.: Verification bias in pediatric studies evaluating diagnostic tests. J Pediatr 1993; 122: pp. 585-590.


- 8\. Cronin A.M., Vickers A.J.: Statistical methods to correct for verification bias in diagnostic studies are inadequate when there are few false negatives: a simulation study. BMC Med Res Methodol 2008; 8: pp. 75.


- 9\. Mallet S., Deeks J.J., Halligan S., et. al.: Systematic review of diagnostic tests in cancer: review of methods and reporting. BMJ 2006; 333: pp. 413.


- 10\. Diamond G.A.: Reverend Bayes’ silent majority. An alternative factor affecting sensitivity and specificity of exercise electrocardiography. Am J Cardiol 1986; 57: pp. 1175-1180.


- 11\. Rubin D.B., Schenker N.: Logit-based interval estimation for binomial data using the Jeffreys prior. Sociol Methodol 1987; 17: pp. 131-144.


- 12\. Harel O., Zhou X.H.: Multiple imputation for correcting verification bias. Stat Med 2006; 25: pp. 3769-3786.


- 13\. Begg C.B., Greenes R.A.: Assessment of diagnostic tests when disease verification is subject to selection bias. Biometrics 1983; 39: pp. 207-215.


- 14\. Punglia R.S., D’Amico A.V., Catalona W.J., et. al.: Effect of verification bias on screening for prostate cancer by measurement of prostate-specific antigen. N Engl J Med 2003; 349: pp. 335-342.


- 15\. Nishikawa H., Imanaka Y., Sekimoto M., et. al.: Influence of verification bias on the assessment of MRI in the diagnosis of meniscal tear. AJR Am J Roentgenol 2009; 193: pp. 1596-1602.


- 16\. Reitsma J.B., Rutjes W.S., Khan K.S., et. al.: A review of solutions for diagnostic accuracy studies with an imperfect or missing reference standard. J Clin Epidemiol 2009; 62: pp. 797-806.
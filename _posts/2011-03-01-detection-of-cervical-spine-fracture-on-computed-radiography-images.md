---
title: Detection of Cervical Spine Fracture on Computed Radiography Images
author: [Omer Awan MD,Nabile M. Safdar MD,Khan M. Siddiqui MD,Ryan Moffitt BS,Eliot L. Siegel MD]
date: 2011-03-01 00:00:00 +0700 +07
categories: [{Academic Radiology, Volume 18, Issue 3 SOURCE CL_S_AcademicRadiologyVolume18Issue3 1}]
tags: [Journals,General Radiology]
---
## Rationale and Objectives

The purpose of this study was to evaluate the diagnostic accuracy of radiologists using monochrome medical-grade 5 megapixel (MP), 3 MP, 2 MP, and 1 MP displays for the detection of cervical fractures on cervical radiographs, while controlling factors such as luminance and ambient conditions.

## Materials and Methods

Institutional review board approval was obtained. Two hundred lateral cervical computed radiography images, 97 with fractures, were randomly displayed on 5-MP, 3-MP, 2-MP, or 1-MP liquid crystal displays (LCDs) for a total of 450 interpretations per display. These radiographs were presented in eight sessions, each with 25 radiographs, to nine readers. The reference standard for all cases was computed tomography. Ambient lighting, monitor luminance, and gamma were controlled throughout the study. Measures included receiver operator characteristic areas under the curve (AUC), sensitivity, specificity, and accuracy, mean elapsed time by display, and mean confidence level by display. One way analysis of variance was performed. Results were considered to be significant at an alpha level of 0.05.

## Results

AUCs were 0.76 (95% CI, 0.72–0.80) for the 1 MP, 0.80 (95% CI, 0.76–0.84) for the 2 MP, 0.77 (95% CI, 0.73–0.81) for the 3 MP, and 0.76 (95% CI, 0.72–0.80) for the 5 MP medical grade LCDs. There was no significant difference in the AUCs ( _P_ values between .0651 and .8693), confidence ( _P_ = .158), or interpretation times ( _P_ = .751).

## Conclusion

When controlling factors such as luminance and ambient light, a difference in accuracy in the detection of cervical fractures by resolution could not be detected when using medical-grade displays. Interpretation time and confidence were also not affected by resolution.

The use of lower resolution medical grade monochrome displays is becoming more common in medical imaging. These displays may have some of the same features as higher resolution displays, with comparable luminance, contrast ratios, and methods for calibration, but are more cost effective. As these liquid crystal displays (LCDs) have become increasingly popular for general radiology practices in a digital environment, the 5 megapixel (MP) cathode ray tubes (CRTs) used by the early adopters of Picture Archiving and Communication Systems (PACS) have been replaced in most settings by LCDs which are nominally of 3 MP or, less commonly, even lower resolution. This has lead to heterogeneous display environments in clinical settings.

With the exception of digital mammography , regulatory mandates for minimum resolution requirements of medical display systems do not exist today in the United States. However, the American College of Radiology Technical Standard for the Electronic Practice of Medical Imaging provides specific illustrations of whether monitors would require the use of magnification to achieve the recommended displayed resolution of 2.5 line pairs (lp)/millimeter (mm). It states that a “5 MP (2048 × 2560) monitor exceeds the American College of Radiology standard of a displayed resolution of at least 2.5 lp/mm when viewing a 14“ × 17” image and thus is sufficient for viewing all types of computed radiography/digital radiography images, a “2 MP (1200 × 1600) or 3 MP (1535 × 2048) monitor needs a 2× magnification when viewing 14“ x 17” images,” and “a 1K × 1.2K (1024 × 1280) will not permit a 10“ × 12”, 12“ × 14”, or a 14“ × 17” image with at least 2.5 lp/mm resolution without zooming or magnifying the image” .

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Materials and methods

## Subjects and Reference Standards

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Descriptive Statistics of Cases

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

![Figure 1, Lateral radiograph of the spine and sagittally reformatted computed tomography demonstrate a minimally displaced fracture of the posterior elements of C2.](https://storage.googleapis.com/dl.dentistrykey.com/clinical/DetectionofCervicalSpineFractureonComputedRadiographyImages/0_1s20S107663321000632X.jpg)

![Figure 2, Lateral radiograph of the spine and sagittally reformatted computed tomography demonstrate a minimally displaced fracture of the dens.](https://storage.googleapis.com/dl.dentistrykey.com/clinical/DetectionofCervicalSpineFractureonComputedRadiographyImages/1_1s20S107663321000632X.jpg)

![Figure 3, A representative receiver operating characteristic plot of one of the observers.](https://storage.googleapis.com/dl.dentistrykey.com/clinical/DetectionofCervicalSpineFractureonComputedRadiographyImages/2_1s20S107663321000632X.jpg)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Acquisition

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Reading Sessions

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Displays

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Training Session

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Reading Sessions

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Ambient Conditions

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Statistics

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Results

## Sensitivity, Specificity, and Accuracy for Detection of the Presence of Fractures for Each Monitor

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

Table 1


Accuracy, Sensitivity, and Specificity for Detecting Cervical Fracture with Different Monitor Resolutions


1 mp 2 mp 3 mp 5 mp Accuracy: 77% Accuracy: 80% Accuracy: 78% Accuracy: 76% Sensitivity: 70% Sensitivity: 73% Sensitivity: 69% Sensitivity: 74% Specificity: 84% Specificity: 87% Specificity: 86% Specificity: 79%

mp, megapixel.


[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## ROC Curves for Detection of the Presence of Fractures at the Case Level for Each Monitor

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

Table 2


Statistical Analysis of ROC Curves for the Various Monitor Resolutions


Display Area Under Curve 95% CI 1 mp 0.76 0.72–0.80 2 mp 0.80 0.76–0.84 3 mp 0.77 0.73–0.81 5 mp 0.76 0.72–0.80

Contrast Difference 95% CI_P_ 1mp vs 2 mp −0.04 −0.08 to 0.00 .0714 1 mp vs 3 mp −0.01 −0.05 to 0.03 .5562 1 mp vs 5 mp 0.00 −0.04 to 0.04 .8693 2 mp vs 3 mp 0.03 −0.01 to 0.06 .1757 2 mp vs 5 mp 0.03 0.00 to 0.07 .0651 3 mp vs 5 mp 0.01 −0.03 to 0.05 .6384

CI, confidence interval; mp, megapixel; ROC, receiver operator characteristic.


[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Sensitivity and Specificity for Detection of the Presence of Fractures for Each Reader

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

Table 3


Sensitivity and Specificity for Detection of Cervical Fracture for all Nine Readers


Sensitivity 95% CI Specificity 95% CI Reader 1 0.695 0.592–0.785 0.895 0.820–0.947 Reader 2 0.621 0.516–0.719 0.886 0.809–0.940 Reader 3 0.695 0.592–0.785 0.886 0.809–0.940 Reader 4 0.779 0.682–0.858 0.800 0.711–0.872 Reader 5 0.737 0.636–0.822 0.829 0.743–0.895 Reader 6 0.684 0.581–0.776 0.838 0.753–0.903 Reader 7 0.779 0.682–0.858 0.790 0.700–0.864 Reader 8 0.684 0.581–0.776 0.790 0.700–0.864 Reader 9 0.758 0.659–0.840 0.810 0.721–0.880

CI, confidence interval.


[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Time Difference between Monitors

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Confidence Differences by Monitor

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## Discussion

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

[Get Radiology Tree app to read full this article<](https://clinicalpub.com/app)

## References

- 1\. American College of Radiology: Practice guideline for the performance of screening and diagnostic mammography.2008.American College of RadiologyReston, VA


- 2\. American College of Radiology: Technical standard for the electronic practice of medical imaging.2007.American College of RadiologyReston, VA


- 3\. Herron J.M., Bender T.M., Campbell W.L., et. al.: Effects of luminance and resolution on observer performance with chest radiographs. Radiology 2000; 215: pp. 169-174.


- 4\. Goo J., Choi J., Im J., et. al.: Effect of monitor luminance and ambient light on observer performance in soft-copy reading of digital chest radiographs. Radiology 2004; 232: pp. 762-766.


- 5\. Krupinski E., Roehrig H., Furukawa T.: Influence of film and monitor display luminance on observer performance and visual search. Acad Radiol 1999; 6: pp. 411-418.


- 6\. Fuchsjager M.H., Schaefer-Prokop C.M., Eisenhuber E., et. al.: Impact of ambient light and window settings on the detectability of catheters on softcopy display of chest radiographs at bedside. AJR Am J Roentgenol 2003; 181: pp. 1415-1421.


- 7\. Parasyn A., Hanson R.M., Peat J.K., et. al.: A comparison between digital images viewed on a picture archiving and communication system diagnostic workstation and on a PC-based remote viewing system by emergency physicians. J Digit Imaging 1998; 11: pp. 45-49.


- 8\. Balassy C., Prokop M., Weber M., et. al.: Flat-panel display (LCD) versus high-resolution gray-scale display (CRT) for chest radiography: an observer preference study. Am J Roentgenol 2005; 184: pp. 752.


- 9\. Doyle A.J., Le Fevre J., Anderson G.D.: Personal computer versus workstation display: observer performance in detection of wrist fractures on digital radiographs. Radiology 2005; 237: pp. 872-877.


- 10\. Scharitzer M., Prokop M., Weber M., et. al.: Detectability of catheters on bedside chest radiographs: comparison between liquid crystal display and high-resolution cathode-ray tube monitors. Radiology 2005; 234: pp. 611-616.


- 11\. Langer S., Bartholmai B., Fetterly K., et. al.: SCAR R&D Symposium 2003: comparing the efficacy of 5-MP CRT versus 3-MP LCD in the evaluation of interstitial lung disease. J Digit Imaging 2004; 17: pp. 149-157.


- 12\. Oschatz E., Prokop M., Scharitzer M., et. al.: Comparison of liquid crystal versus cathode ray tube display for the detection of simulated chest lesions. Eur Radiol 2005; 15: pp. 1472-1476.


- 13\. Usami H., Ikeda M., Ishigakil T., et. al.: The influence of liquid crystal display (LCD) monitors on observer performance for the detection of nodular lesions on chest radiographs. Eur Radiol 2006; 16: pp. 726-732.


- 14\. DeLong E.R., DeLong D.M., Clarke-Pearson D.L.: Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach. Biometrics 1988; 44: pp. 837-845.


- 15\. Stephan Carsten, Wesseling S., Schink T., et. al.: Comparison of eight computer programs for receiver-operating characteristic analysis. Clin Chem 2003; 49: pp. 433-439.


- 16\. Streitwieser D.R., Knopp R., Wales L.R., et. al.: Accuracy of standard radiographic views in detecting cervical spine fractures. Ann Emerg Med 1983; 12: pp. 538-542.


- 17\. Krupinski E.: A medical grade vs. off-the-shelf color displays: influence on observer performance and visual search. JDI 2009; 4: pp. 362-368.


- 18\. Krupinski E., Berbaum K.: The medical image perception society update on key issues for image perception research. Radiology 2009; 253: pp. 230-233.


- 19\. Obuchowski N.A.: ROC analysis. AJR Am J Roentgenol 2005; 184: pp. 364-372.


- 20\. Obuchowski N.A.: Multireader receiver operating characteristic studies: a comparison of study designs. Acad Radiol 1995; 2: pp. 709-716.
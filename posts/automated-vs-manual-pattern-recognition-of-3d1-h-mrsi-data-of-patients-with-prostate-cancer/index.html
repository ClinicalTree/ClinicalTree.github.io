<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Automated vs. Manual Pattern Recognition of 3D1 H MRSI Data of Patients with Prostate Cancer" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/automated-vs-manual-pattern-recognition-of-3d1-h-mrsi-data-of-patients-with-prostate-cancer/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/automated-vs-manual-pattern-recognition-of-3d1-h-mrsi-data-of-patients-with-prostate-cancer/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2012-05-31T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Automated vs. Manual Pattern Recognition of 3D1 H MRSI Data of Patients with Prostate Cancer" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-10T02:43:55+00:00","datePublished":"2012-05-31T17:00:00+00:00","description":"Rationale and Objectives","headline":"Automated vs. Manual Pattern Recognition of 3D1 H MRSI Data of Patients with Prostate Cancer","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/automated-vs-manual-pattern-recognition-of-3d1-h-mrsi-data-of-patients-with-prostate-cancer/"},"url":"https://clinicaltree.github.io/posts/automated-vs-manual-pattern-recognition-of-3d1-h-mrsi-data-of-patients-with-prostate-cancer/"}</script><title>Automated vs. Manual Pattern Recognition of 3D1 H MRSI Data of Patients with Prostate Cancer | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Automated vs. Manual Pattern Recognition of 3D1 H MRSI Data of Patients with Prostate Cancer</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Automated vs. Manual Pattern Recognition of 3D1 H MRSI Data of Patients with Prostate Cancer</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1338483600" data-df="ll" data-toggle="tooltip" data-placement="bottom"> May 31, 2012 </em> </span> <span> Updated <em class="" data-ts="1681094635" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 10, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Christian M. Zechmann MD</a> </em>, <em> <a href="">Bjoern H. Menze PhD</a> </em>, <em> <a href="">B. Michael Kelm PhD</a> </em>, <em> <a href="">Patrik Zamecnik MD</a> </em>, <em> <a href="">Uwe Ikinger MD</a> </em>, <em> <a href="">Frederik L. Giesel MD MBA</a> </em>, <em> <a href="">Christian Thieke MD PhD</a> </em>, <em> <a href="">Stefan Delorme MD</a> </em>, <em> <a href="">Fred A. Hamprecht PhD</a> </em>, <em> <a href="">Peter Bachert PhD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2616 words"> <em>14 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The aim of this study was to assess (1) automated analysis methods versus manual evaluation by human experts of three-dimensional proton magnetic resonance spectroscopic imaging (MRSI) data from patients with prostate cancer and (2) the contribution of spatial information to decision making.</p><h2 id="materials-and-methods"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Three-dimensional proton MRSI was applied at 1.5 T. MRSI data from 10 patients with histologically proven prostate adenocarcinoma, scheduled either for prostatectomy or intensity-modulated radiation therapy, were evaluated. First, two readers manually labeled spectra using spatial information to identify the localization of spectra and neighborhood information, establishing the reference set of this study. Then, spectra were labeled again manually in a blinded and randomized manner and evaluated automatically using software that applied spectral line fitting as well as pattern recognition routines. Statistical analysis of the results of the different approaches was performed.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Altogether, 1018 spectra were evaluable by all methods. Numbers of evaluable spectra differed significantly depending on patient and evaluation method. Compared to automated analysis, the readers made rather binary decisions, using information from neighboring spectra in ambiguous cases, when evaluating MRSI data as a whole. Differences between anatomically blinded and unblinded evaluation were larger than differences between evaluations using blinded data and automated techniques.</p><h2 id="conclusions"><span class="mr-2">Conclusions</span><a href="#conclusions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>An automated approach, which evaluates each spectrum individually, can be as good as an anatomy-blinded human reader. Spatial information is routinely used by human experts to support their final decisions. Automated procedures that consider anatomic information for spectral evaluation will enhance the diagnostic impact of MRSI of the human prostate.</p><p>The large-scale measurement of serum prostate-specific antigen in recent years has resulted in the detection of an immense number of prostate carcinomas . In particular, when initial biopsy results are negative, magnetic resonance (MR) imaging (MRI) is applied to visualize the zonal anatomy of the prostate and localize a possible tumor . High-resolution T2-weighted (T2w) MRI performed with pelvic array coils provides good specificity (up to 90%) but low sensitivity (27%–61%) for tumor detection and localization . The use of an endorectal coil for signal reception raises the sensitivity for tumors &gt;1 cm. However, the reported sensitivity in the literature ranges from 27% to 100%, and 32% to 99% for specificity, depending on the size of the examined tumors . Moreover, false-positive results of T2w MRI remain a problem. They are often caused by local signal reduction due to postbiopsy hemorrhage, prostatitis, or previous treatment .</p><p>These limitations fostered the inclusion of functional imaging techniques such as diffusion-weighted MRI, dynamic contrast-enhanced MRI, and proton MR spectroscopic imaging ( 1 H MRSI) in diagnostic imaging protocols. Using MRSI, prostate cancer is characterized by increases in cholines (ie, free choline and choline-containing compounds; Cho) and a decrease in citrate levels . Single-center studies have shown that with MRSI supplementing T2w MRI, prostate cancer can be better differentiated from normal glandular tissue than with conventional MRI alone . Recently published results have demonstrated that most tumors in the prostate were missed because of their small sizes . Thus, MRSI with higher spatial resolution is needed. However, the number of obtained spectra will increase. The large set of spectra resulting from a single examination and the demand for extensive postprocessing and expertise required to interpret the data have hampered the broader application of MRSI.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="methods"><span class="mr-2">Methods</span><a href="#methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="data"><span class="mr-2">Data</span><a href="#data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="patients"><span class="mr-2">Patients</span><a href="#patients" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="spectroscopic-imaging"><span class="mr-2">Spectroscopic imaging</span><a href="#spectroscopic-imaging" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/0_1s20S1076633212001031.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/0_1s20S1076633212001031.jpg" alt="Figure 1, Color-coded tumor probability map of the prostate of patient e (aged 58 years) with adenocarcinoma, calculated and displayed by CLARET (21) software. Tumor voxels are marked in red and areas without pathologic findings in green . Representative spectra displayed from voxels indicated by blue arrows . Magnetic resonance spectroscopic imaging (MRSI) measurement technique: three-dimensional proton MRSI point-resolved spectroscopy with water and lipid signal suppression (repetition time, 650 ms; echo time, 120 ms; nominal voxel size, 6 × 6 × 6 mm 3 ; matrix size, 16 × 16 × 16). Cho, cholines; Ci, citrate; Cr, creatine." class="lazyload" data-proofer-ignore></a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/1_1s20S1076633212001031.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/1_1s20S1076633212001031.jpg" alt="Figure 2, Color maps showing tissue classification obtained by both readers consensually ( left ) ( an ) compared to the evaluation of one reader ( right ) ( e1 ) without spatial context of in vivo prostate proton magnetic resonance spectroscopic imaging (MRSI). The maps show the tissue classification for the 12 central slices (1–12) of 10 different MRSI data sets (a–j). Spectra were labeled according to a five-point scale using the relative intensities of choline plus creatine and citrate resonances. Voxels of spectra that identify healthy prostate tissue are marked in yellow (class 1), while dark red voxels label tumor (class 5). Voxels that could not be evaluated because of localization outside the prostate or poor spectral quality are white . Note that with spatial context ( an ), more spectra of patients c and h were deemed evaluable." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="postprocessing-of-mrsi-data"><span class="mr-2">Postprocessing of MRSI data</span><a href="#postprocessing-of-mrsi-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="evaluation-procedures"><span class="mr-2">Evaluation Procedures</span><a href="#evaluation-procedures" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="step-1-visual-evaluation-of-mr-spectroscopic-and-anatomic-data-reference-data"><span class="mr-2">Step 1: Visual evaluation of MR spectroscopic and anatomic data (reference data)</span><a href="#step-1-visual-evaluation-of-mr-spectroscopic-and-anatomic-data-reference-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="step-2-visual-evaluation-of-randomized-spectra-blinded-reference"><span class="mr-2">Step 2: Visual evaluation of randomized spectra (blinded reference)</span><a href="#step-2-visual-evaluation-of-randomized-spectra-blinded-reference" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/2_1s20S1076633212001031.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/2_1s20S1076633212001031.jpg" alt="Figure 3, Results of different evaluation methods ( an , pr , e1 , e2 , f1 , f2 , and fl ) of two exemplary magnetic resonance spectroscopic imaging data sets (from patients b and e; see Fig 2 ). Data show high variability between the outcomes of the different methods, motivating a more detailed quantitative analysis. The central slices (1–12) were evaluated by consensus reading with spatial context ( an ), automated pattern recognition ( pr ), expert 1 ( e1 ), and expert 2 ( e2 ) without anatomic information and by fitting metabolite signal templates ( f1 and f2 ) as well as resonance line models ( fl ). Healthy prostate tissue is marked in yellow , and dark red voxels correspond to tumor. White pixels correspond to spectra that were not evaluable." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="step-3-automated-evaluation-using-spectral-fits"><span class="mr-2">Step 3: Automated evaluation using spectral fits</span><a href="#step-3-automated-evaluation-using-spectral-fits" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="step-4-automated-evaluation-using-pattern-recognition"><span class="mr-2">Step 4: Automated evaluation using pattern recognition</span><a href="#step-4-automated-evaluation-using-pattern-recognition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="statistical-evaluation"><span class="mr-2">Statistical Evaluation</span><a href="#statistical-evaluation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="visualization"><span class="mr-2">Visualization</span><a href="#visualization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 1</p><p>Comparison of Class Predictions between Readers and Fitting Methods</p><p>Comparison Class 1 Class 2 Class 3 Class 4 Class 5<em>e1</em> vs <em>e2</em> Class 1 315 86 15 0 0 Class 2 28 317 7 2 0 Class 3 1 11 83 0 1 Class 4 0 2 13 44 6 Class 5 0 0 0 7 80<em>f1</em> vs <em>f2</em> Class 1 392 3 7 0 0 Class 2 9 228 9 9 0 Class 3 1 8 144 7 0 Class 4 3 5 21 109 1 Class 5 0 0 2 16 44</p><p><em>e1</em> , reader 1; <em>e2</em> , reader 2; <em>f1</em> , fitting method 1; <em>f2</em> , fitting method 2.</p><p>Comparison of class predictions by two “blinded” readers evaluating the spectra in a single-voxel fashion shows high agreement. Few evaluations differed by more than one class, and overall variation was less than the differences between algorithms of the fitting metabolite signal templates.</p><p>Table 2</p><p>Similarity of Performance of the Different Processing Methods, as Measured by Kendall’s τ</p><p>Method_an__pr__e1<em>_e2__ea__f1__f2__fl</em> Expert anatomic ( <em>an</em> ) 1 0.73 (0.11) 0.72 (0.09) 0.62 (0.11) 0.67 (0.10) 0.73 (0.06) 0.68 (0.06) 0.58 (0.06) Pattern recognition ( <em>pr</em> ) — 1 0.83 (0.06) 0.68 (0.08) 0.77 (0.07) 0.81 (0.04) 0.75 (0.05) 0.64 (0.05) Expert 1 ( <em>e1</em> ) — — 1 0.84 (0.05) 0.93 (0.03) 0.74 (0.06) 0.68 (0.04) 0.59 (0.06) Expert 2 ( <em>e2</em> ) — — — 1 0.93 (0.03) 0.63 (0.08) 0.58 (0.06) 0.51 (0.07) Expert average ( <em>ea</em> ) — — — — 1 0.69 (0.07) 0.64 (0.06) 0.54 (0.05) Fitting metabolite 1 ( <em>f1</em> ) — — — — — 1 0.95 (0.01) 0.81 (0.04) Fitting metabolite 2 ( <em>f2</em> ) — — — — — — 1 0.85 (0.04) Fitting lines ( <em>fl</em> ) — — — — — — — 1</p><p>Values in parentheses are the standard deviations from bootstrapping. The first line, for example, shows that the expert anatomic method had the highest correlations with <em>pr</em> and <em>f1</em> , both with τ = 0.73. Here, a τ value 1 indicates perfect correlation and a τ value of 0 complete randomness between two methods. Data are visualized in Figure 6 .</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/3_1s20S1076633212001031.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/3_1s20S1076633212001031.jpg" alt="Figure 4, Visualization of data shown in Tables 1 and 3 . Multidimensional scaling (MDS) 1 yields the differences between the “single-voxel” methods, whereas MDS 2 shows the differences between anatomic and single-voxel methods. The distances encode the similarity or dissimilarity of the different methods. Scaling of both axes is arbitrary. Although the results of fitting metabolite signal templates ( f1 and f2 ) are at nearly identical positions, the anatomic evaluations ( an ) separate from the other postprocessing methods obviously caused by the anatomic information. Automated pattern recognition ( pr ) is located between visual inspection ( e1 , e2 , and ea ) and spectral fitting ( fl , f1 , and f2 ). This indicates that pattern recognition is the closest method to the readers e1 and e2 ." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="general"><span class="mr-2">General</span><a href="#general" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="evaluation-times"><span class="mr-2">Evaluation times</span><a href="#evaluation-times" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="evaluable-data"><span class="mr-2">Evaluable data</span><a href="#evaluable-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 3</p><p>Numbers of Spectra Deemed Evaluable in the Different Approaches and Overlap between the Different Evaluation Methods</p><p>Method_an__pr__e1<em>_e2__ea__f1__f2</em> Expert anatomic ( <em>an</em> ) 4516 (100%) 2093 (46.3%) 2108 (46.7%) 1786 (39.6%) 2259 (50.0%) 2306 (51.1%) 2014 (44.6%) Pattern recognition ( <em>pr</em> ) 2093 (84.0%) 2493 (100%) 1897 (76.1%) 1589 (63.7%) 1785 (71.6%) 1785 (71.6%) 1633 (65.5%) Blinded expert 1 ( <em>e1</em> ) 2108 (78.8%) 1897 (71.0%) 2674 (100%) 2252 (84.2%) 1897 (70.9%) 1906 (71.3%) 1906 (64.1%) Blinded expert 2 ( <em>e2</em> ) 1786 (77.5%) 1589 (68.9%) 2252 (97.7%) 2305 (100%) 1588 (68.9%) 1599 (69.4%) 1432 (62.1%) Metabolite spectral fitting (jMRUI) 1 ( <em>f1</em> ) 2259 (47.3%) 1785 (37.3%) 1897 (39.7%) 1588 (33.2%) 4777 (100%) 4723 (98.9%) 4007 (83.9%) Metabolite spectral fitting (CSItools) 2 ( <em>f2</em> ) 2306 (47.1%) 1785 (36.4%) 1906 (38.9%) 1599 (33.6%) 4777 (96.4%) 4900 (100%) 4010 (81.8%) Line functions spectral fitting (AMARES) ( <em>fl</em> ) 2014 (49.7%) 1633 (40.3%) 1715 (42.3%) 1432 (35.3%) 4007 (98.8%) 4010 (98.9%) 4055 (100%)</p><p>Percentages (in parentheses) indicate the amount of overlap between the methods in the respective row. As an example, among the 4516 spectra evaluated in the anatomic inspection of the data ( <em>an</em> , first row), a subset of 44.6% (2014 spectra) could be evaluated by fitting resonance line models ( <em>fl</em> ). Expert 1 and expert 2 labeled 2674 and 2305 spectra, respectively, and 2252 spectra could be labeled by both.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="automated-versus-rater"><span class="mr-2">Automated Versus Rater</span><a href="#automated-versus-rater" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="experts-single-voxel-consensus"><span class="mr-2">Experts’ single-voxel consensus</span><a href="#experts-single-voxel-consensus" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="line-fitting"><span class="mr-2">Line fitting</span><a href="#line-fitting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/4_1s20S1076633212001031.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/4_1s20S1076633212001031.jpg" alt="Figure 5, Spatial information emphasizes binary decisions, as demonstrated by the scatter plot (a) , in which anatomic knowledge as a function of the average evaluation by both readers without anatomic knowledge is shown. Whereas the evaluation without anatomic information makes use of all five classes, the one with anatomic details is clustered in the extreme classes 1 and 5. The box plots (b) show results from the evaluation with anatomic information ( y axis), grouped by the decisions from visual inspection without this information ( x axis). Median ( thick black line ), quartiles ( box extensions ), and outliers ( whiskers and circles ) of the distributions are also shown. The curved black line indicates the trend approximated by a local polynomial regression." class="lazyload" data-proofer-ignore></a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/5_1s20S1076633212001031.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomatedvsManualPatternRecognitionof3D1HMRSIDataofPatientswithProstateCancer/5_1s20S1076633212001031.jpg" alt="Figure 6, CC/C value ([I choline + I creatine ]/I citrate ) as a function of the average expert's label of spectra according to the five-point scale (1 = definitely healthy, 2 = possibly healthy, 3 = undecided, 4 = possibly tumor, and 5 = definitely tumor). The horizontal axis shows the average label assigned to the spectrum from the visual inspections by the two readers. The vertical axis is the calculated CC/C ratio using method fl . Box plots show median ( thick black lines ), quartiles ( box extensions ), and outliers ( whiskers and points ) for the CC/C values of spectra. Dotted horizontal lines (at y = 0.89, 1.29, 1.96, and 5.34) indicate cutoff values for the assignments to classes 1 to 5. The average scores from human readers and the calculated CC/C values show a linear trend, also indicating good performance of the visual inspection of the two readers." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="pattern-recognition"><span class="mr-2">Pattern recognition</span><a href="#pattern-recognition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="single-voxel-versus-spatial-analysis"><span class="mr-2">Single-Voxel Versus Spatial Analysis</span><a href="#single-voxel-versus-spatial-analysis" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="experts-labels"><span class="mr-2">Experts’ labels</span><a href="#experts-labels" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="experts-labels-versus-automated-methods"><span class="mr-2">Experts’ labels versus automated methods</span><a href="#experts-labels-versus-automated-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">Discussion</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="general-1"><span class="mr-2">General</span><a href="#general-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="evaluation-time"><span class="mr-2">Evaluation time</span><a href="#evaluation-time" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="evaluable-data-1"><span class="mr-2">Evaluable data</span><a href="#evaluable-data-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="limitations"><span class="mr-2">Limitations</span><a href="#limitations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="performance-of-automated-methods"><span class="mr-2">Performance of Automated Methods</span><a href="#performance-of-automated-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="evaluation-of-single-voxel-spectra"><span class="mr-2">Evaluation of single-voxel spectra</span><a href="#evaluation-of-single-voxel-spectra" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="visual-inspection"><span class="mr-2">Visual inspection</span><a href="#visual-inspection" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="need-for-a-spatial-analysis"><span class="mr-2">Need for a Spatial Analysis</span><a href="#need-for-a-spatial-analysis" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="visual-inspection-of-the-mrsi-data"><span class="mr-2">Visual inspection of the MRSI data</span><a href="#visual-inspection-of-the-mrsi-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="implications"><span class="mr-2">Implications</span><a href="#implications" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="conclusions-1"><span class="mr-2">Conclusions</span><a href="#conclusions-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Jemal A., Siegel R., Xu J., et. al.: Cancer statistics, 2010. CA Cancer J Clin 2010; 60: pp. 277-300.</p><li><p>2. Kurhanewicz J., Swanson M.G., Nelson S.J., et. al.: Combined magnetic resonance imaging and spectroscopic imaging approach to molecular imaging of prostate cancer. J Magn Reson Imaging 2002; 16: pp. 451-463.</p><li><p>3. Scheidler J., Hricak H., Vigneron D.B., et. al.: Prostate cancer: localization with three-dimensional proton MR spectroscopic imaging—clinicopathologic study. Radiology 1999; 213: pp. 473-480.</p><li><p>4. Hricak H., White S., Vigneron D., et. al.: Carcinoma of the prostate gland: MR imaging with pelvic phased array coil versus integrated endorectal-pelvic phased-array coils. Radiology 1994; 193: pp. 703-709.</p><li><p>5. Roethke M.C., Lichy M.P., Jurgschat L., et. al.: Tumorsize dependent detection rate of endorectal MRI of prostate cancer—a histopathologic correlation with whole-mount sections in 70 patients with prostate cancer. Eur J Radiol 2011; 79: pp. 189-195.</p><li><p>6. Perrotti M., Kaufman R.P., Jennings T.A., et. al.: Endo-rectal coil magnetic resonance imaging in clinically localized prostate cancer: is it accurate?. J Urol 1996; 156: pp. 106-109.</p><li><p>7. Miao H., Fukatsu H., Ishigaki T.: Prostate cancer detection with 3-T MRI: Comparison of diffusion-weighted and T2-weighted imaging. Eur J Radiol 2007; 61: pp. 297-302.</p><li><p>8. Quinn S.F., Franzini D.A., Demlow T.A., et. al.: MR imaging of prostate cancer with an endorectal surface coil technique: correlation with whole-mount specimens. Radiology 1994; 190: pp. 323-327.</p><li><p>9. D’Amico A.V., Schnall M., Whittington R., et. al.: Endorectal coil magnetic resonance imaging identifies locally advanced prostate cancer in select patients with clinically localized disease. Urology 1998; 51: pp. 449-454.</p><li><p>10. Reinsberg S.A., Payne G.S., Riches S.F., et. al.: Combined use of diffusion-weighted MRI and 1H MR spectroscopy to increase accuracy in prostate cancer detection. AJR Am J Roentgenol 2007; 188: pp. 91-98.</p><li><p>11. Schiebler M.L., Yankaskas B.C., Tempany C., et. al.: MR imaging in adenocarcinoma of the prostate: interobserver variation and efficacy for determining stage C disease. AJR Am J Roentgenol 1992; 158: pp. 559-562.</p><li><p>12. Weinreb J.C., Blume J.D., Coakley F.V., et. al.: Prostate cancer: sextant localization at MR imaging and MR spectroscopic imaging before prostatectomy—results of ACRIN prospective multi-institutional clinicopathologic study. Radiology 2009; 251: pp. 122-133.</p><li><p>13. Scheenen T.W., Fütterer J., Weiland E., et. al.: Discriminating cancer from noncancer tissue in the prostate by 3-dimensional proton magnetic resonance spectroscopic imaging: a prospective multicenter validation study. Invest Radiol 2011; 46: pp. 25-33.</p><li><p>14. Kelm B.M., Menze B.H., Zechmann C.M., et. al.: Automated estimation of tumor probability in prostate magnetic resonance spectroscopic imaging: pattern recognition vs quantification. Magn Reson Med 2007; 57: pp. 150-159.</p><li><p>15. Pels P., Ozturk-Isik E., Swanson M.G., et. al.: Quantification of prostate MRSI data by model-based time domain fitting and frequency domain analysis. NMR Biomed 2006; 19: pp. 188-197.</p><li><p>16. Scheenen T.W., Klomp D.W., Röll S.A., et. al.: Fast acquisition-weighted three-dimensional proton MR spectroscopic imaging of the human prostate. Magn Reson Med 2004; 52: pp. 80-88.</p><li><p>17. de Beer R., van den Boogaart A., van Ormondt D., et. al.: Application of time-domain fitting in the quantification of in vivo 1H spectroscopic imaging data sets. NMR Biomed 1992; 5: pp. 171-178.</p><li><p>18. Pijnappel W.W.F., Van den Boogaart A., de Beer R., et. al.: SVD-based quantification of magnetic resonance signals. J Magn Reson 1969; 97: pp. 122-134.</p><li><p>19. Naressi A., Couturier C., Devos J.M., et. al.: Java-based graphical user interface for the MRUI quantitation package. MAGMA 2001; 12: pp. 141-152.</p><li><p>20. Kreis R.: Issues of spectral quality in clinical 1H-magnetic resonance spectroscopy and a gallery of artifacts. NMR Biomed 2004; 17: pp. 361-381.</p><li><p>21. Kelm B.M., Menze B.H., Neff T., et. al.: CLARET: a tool for fully automated evaluation of MRSI with pattern recognition methods.Handels H.Erhardt J.Horsch A. et. al.Bildverarbeitung für die Medizin 2006—Algorithmen, Systeme, Anwendungen.2006.SpringerBerlin, Germany:pp. 51-55.</p><li><p>22. Menze B.H., Kelm B.M., Weber M.A., et. al.: Mimicking the human expert: a pattern recognition approach to score the data quality in MRSI. Magn Reson Med 2008; 59: pp. 1457-1466.</p><li><p>23. Bouix S., Martin-Fernandez M., Ungar L., et. al.: On evaluating brain tissue classifiers without a ground truth. Neuroimage 2007; 36: pp. 1207-1224.</p><li><p>24. Kendall M.: Rank Correlation Methods.1948.Charles Griffin &amp; CompanyLondon 160</p><li><p>25. Borg I., Groenen P.: Modern Multidimensional Scaling: Theory and Applications.2nd ed.2005.SpringerNew York 614</p><li><p>26. Fütterer J.J., Scheenen T.W., Heijmink S.W., et. al.: Standardized threshold approach using three-dimensional proton magnetic resonance spectroscopic imaging in prostate cancer localization of the entire prostate. Invest Radiol 2007; 42: pp. 116-122.</p><li><p>27. Jung J.A., Coakley F.V., Vigneron D.B., et. al.: Prostate depiction at endorectal MR spectroscopic imaging: investigation of a standardized evaluation system. Radiology 2004; 233: pp. 701-708.</p><li><p>28. Cosío F.A.: Automatic initialization of an active shape model of the prostate. Med Image Anal 2008; 12: pp. 469-483.</p><li><p>29. Costa M.J., Delingette H., Novellas S., et. al.: Automatic segmentation of bladder and prostate using coupled 3D deformable models. Med Image Comput Comput Assist Interv 2007; 10: pp. 252-260.</p><li><p>30. Zhu Y., Williams S., Zwiggelaar R.: Computer technology in detection and staging of prostate carcinoma: a review. Med Image Anal 2006; 10: pp. 178-199.</p><li><p>31. Shen D., Lao Z., Zeng J., et. al.: Optimized prostate biopsy via a statistical atlas of cancer spatial distribution. Med Image Anal 2004; 8: pp. 139-150.</p><li><p>32. Laudadio T., Pels P., De Lathauwer L., et. al.: Tissue segmentation and classification of MRSI data using canonical correlation analysis. Magn Reson Med 2005; 54: pp. 1519-1529.</p><li><p>33. Görlitz L., Menze B.H., Weber M.A., et. al.: Semi-supervised tumor detection in magnetic resonance spectroscopic images using discriminative random fields.Hamprecht F.A.Schnörr C.Jähne B.Proceedings of the 29th Symposium of the German Association for Pattern Recognition (DAGM 07), Heidelberg, Germany, Pattern Recognition.2007.SpringerBerlin, Germany:pp. 224-233.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-19/'>Volume 19</a>, <a href='/categories/issue-6/'>Issue 6</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Automated%20vs.%20Manual%20Pattern%20Recognition%20of%203D1%20H%20MRSI%20Data%20of%20Patients%20with%20Prostate%20Cancer%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fautomated-vs-manual-pattern-recognition-of-3d1-h-mrsi-data-of-patients-with-prostate-cancer%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Automated%20vs.%20Manual%20Pattern%20Recognition%20of%203D1%20H%20MRSI%20Data%20of%20Patients%20with%20Prostate%20Cancer%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fautomated-vs-manual-pattern-recognition-of-3d1-h-mrsi-data-of-patients-with-prostate-cancer%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fautomated-vs-manual-pattern-recognition-of-3d1-h-mrsi-data-of-patients-with-prostate-cancer%2F&text=Automated%20vs.%20Manual%20Pattern%20Recognition%20of%203D1%20H%20MRSI%20Data%20of%20Patients%20with%20Prostate%20Cancer%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/a-new-formula-for-rapid-assessment-of-pericardial-effusion-volume-by-computed-tomography/"><div class="card-body"> <em class="small" data-ts="1338483600" data-df="ll" > May 31, 2012 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>A New Formula for Rapid Assessment of Pericardial Effusion Volume by Computed Tomography</h3><div class="text-muted small"><p> Rationale and Objectives The aim of this study was to evaluate a new formula for the rapid assessment of pericardial effusion (PE) volume by computed tomography. Materials and Methods Twenty com...</p></div></div></a></div><div class="card"> <a href="/posts/assessing-first-year-radiology-resident-competence-pre-call/"><div class="card-body"> <em class="small" data-ts="1338483600" data-df="ll" > May 31, 2012 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Assessing First Year Radiology Resident Competence Pre-call</h3><div class="text-muted small"><p> Rationale and Objectives Whether first-year radiology residents are ready to start call after 6 or 12 months has been a subject of much debate. The purpose of this study was to establish an assess...</p></div></div></a></div><div class="card"> <a href="/posts/assessing-renal-parenchymal-volume-on-unenhanced-ct-as-a-marker-for-predicting-renal-function-in-pat/"><div class="card-body"> <em class="small" data-ts="1338483600" data-df="ll" > May 31, 2012 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Assessing Renal Parenchymal Volume on Unenhanced CT as a Marker for Predicting Renal Function in Patients with Chronic Kidney Disease</h3><div class="text-muted small"><p> Objectives To estimate renal volume in chronic kidney disease (CKD) patients using a semiautomated software and compare them with split renal function estimates from radionuclide renogram (RR). We...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/assessing-renal-parenchymal-volume-on-unenhanced-ct-as-a-marker-for-predicting-renal-function-in-pat/" class="btn btn-outline-primary" prompt="Older"><p>Assessing Renal Parenchymal Volume on Unenhanced CT as a Marker for Predicting Renal Function in Patients with Chronic Kidney Disease</p></a> <a href="/posts/automatic-left-ventricle-segmentation-in-cardiac-mri-using-topological-stable-state-thresholding-and/" class="btn btn-outline-primary" prompt="Newer"><p>Automatic Left Ventricle Segmentation in Cardiac MRI Using Topological Stable-State Thresholding and Region Restricted Dynamic Programming</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

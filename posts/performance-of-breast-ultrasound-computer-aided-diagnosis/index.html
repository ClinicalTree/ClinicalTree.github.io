<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Performance of Breast Ultrasound Computer-aided Diagnosis" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/performance-of-breast-ultrasound-computer-aided-diagnosis/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/performance-of-breast-ultrasound-computer-aided-diagnosis/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2008-09-30T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Performance of Breast Ultrasound Computer-aided Diagnosis" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-07T07:15:32+00:00","datePublished":"2008-09-30T17:00:00+00:00","description":"Rationale and Objectives","headline":"Performance of Breast Ultrasound Computer-aided Diagnosis","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/performance-of-breast-ultrasound-computer-aided-diagnosis/"},"url":"https://clinicaltree.github.io/posts/performance-of-breast-ultrasound-computer-aided-diagnosis/"}</script><title>Performance of Breast Ultrasound Computer-aided Diagnosis | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Performance of Breast Ultrasound Computer-aided Diagnosis</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Performance of Breast Ultrasound Computer-aided Diagnosis</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1222794000" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Sep 30, 2008 </em> </span> <span> Updated <em class="" data-ts="1680851732" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 7, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Nicholas P. Gruszauskas MS</a> </em>, <em> <a href="">Karen Drukker PhD</a> </em>, <em> <a href="">Maryellen L. Giger PhD</a> </em>, <em> <a href="">Charlene A. Sennett MD</a> </em>, <em> <a href="">Lorenzo L. Pesce PhD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2327 words"> <em>12 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The automated classification of sonographic breast lesions is generally accomplished by extracting and quantifying various features from the lesions. The selection of images to be analyzed, however, is usually left to the radiologist. Here we present an analysis of the effect that image selection can have on the performance of a breast ultrasound computer-aided diagnosis system.</p><h2 id="materials-and-methods"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>A database of 344 different sonographic lesions was analyzed for this study (219 cysts/benign processes, 125 malignant lesions). The database was collected in an institutional review board–approved, Health Insurance Portability and Accountability Act–compliant manner. Three different image selection protocols were used in the automated classification of each lesion: all images, first image only, and randomly selected images. After image selection, two different protocols were used to classify the lesions: (a) the average feature values were input to the classifier or (b) the classifier outputs were averaged together. Both protocols generated an estimated probability of malignancy. Round-robin analysis was performed using a Bayesian neural network-based classifier. Receiver-operating characteristic analysis was used to evaluate the performance of each protocol. Significance testing of the performance differences was performed via 95% confidence intervals and noninferiority tests.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The differences in the area under the receiver-operating characteristic curves were never more than 0.02 for the primary protocols. Noninferiority was demonstrated between these protocols with respect to standard input techniques (all images selected and feature averaging).</p><h2 id="conclusion"><span class="mr-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>We have proved that our automated lesion classification scheme is robust and can perform well when subjected to variations in user input.</p><p>Breast cancer continues to be the most common form of cancer and the second most common cause of death from cancer among women in the United States ( ). Although routine mammography is currently the only screening method recommended for the general public ( ), there is still considerable research being done to augment the breast cancer detection and diagnosis process. The utility of ultrasound, for example, to evaluate and diagnose lesions and abnormalities within the breast has increased dramatically over the past decade ( ). Previous studies have shown breast ultrasound to have an accuracy of 96%–100% in the diagnosis of cysts ( ) and its use in differentiating between different types of solid lesions (i.e., benign vs. malignant) is becoming more prevalent ( ). This increased interest in ultrasound as a diagnostic tool for breast cancer has led to, among other things, rapid developments in the application of computer-aided diagnosis (CADx) to breast sonography ( ).</p><p>The automated classification of sonographic breast lesions is generally accomplished by extracting and quantifying various features from the lesions. Features such as margin shape, margin sharpness, lesion texture, and posterior acoustic behavior have been shown to be particularly useful in computerized classification schemes ( ) and CADx systems based on these features have been shown to perform the benign versus malignant classification task well ( ). However, such systems are still subject to several different kinds of user-induced variability. The choice of images to be analyzed, for example, is generally left to the user of the system. As a result, the manner in which a particular lesion is input into the system may vary between different users (i.e., radiologists). This variability may have the potential to impact the output, and thus the performance, of the classifier. Here we present an analysis of the effect that image selection can have on the performance of a sonographic breast lesion CADx system.</p><h2 id="materials-and-methods-1"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="image-database"><span class="mr-2">Image Database</span><a href="#image-database" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 1</p><p>Composition of the Sonographic Database</p><p>Pathology Biopsied? No. of Patients No. of Images No. of Physical Lesions Cyst Yes 48 189 62 Cyst No 36 120 54 Benign solid/tumor Yes 63 208 68 Benign solid/tumor No 15 48 18 Benign fibrocystic Yes 15 58 17 Malignant Yes 104 444 125 Totals 281 1067 344</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/0_1s20S1076633208002572.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/0_1s20S1076633208002572.jpg" alt="Figure 1, The distribution of the number of images available per lesion." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="image-selection-protocols"><span class="mr-2">Image Selection Protocols</span><a href="#image-selection-protocols" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/1_1s20S1076633208002572.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/1_1s20S1076633208002572.jpg" alt="Figure 2, Four different images depicting the same physical lesion. In the “all images” view selection protocol, features from all four of the images are extracted and used in analysis ( solid outline ). In the “first image only” view selection protocol, only features from the first image are used in analysis ( dashed-dotted outline ). In the “random images” view selection protocol, only features from a randomly selected group of images are used in analysis ( dashed outline ); in this example, two of the four images were randomly selected via this protocol." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="lesion-classification-protocols"><span class="mr-2">Lesion Classification Protocols</span><a href="#lesion-classification-protocols" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/2_1s20S1076633208002572.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/2_1s20S1076633208002572.jpg" alt="Figure 3, A flowchart depicting the two main protocols used to evaluate our Bayesian neural network (BNN) classifier. In protocol A, features from multiple images of the same physical lesion are extracted and averaged together before they are input into the classifier. In protocol B, features from multiple images of the same physical lesion are input into the classifier directly, and then the classifier outputs from each of these images are averaged together." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="performance-assessment-and-statistical-analysis"><span class="mr-2">Performance Assessment and Statistical Analysis</span><a href="#performance-assessment-and-statistical-analysis" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/3_1s20S1076633208002572.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/3_1s20S1076633208002572.jpg" alt="Figure 4, An example of a lesion with a relatively large difference in estimated probability of malignancy between the two different classification protocols. Both images depict the same physical lesion, a biopsy-proved carcinoma. The estimated probability of malignancy for each image individually is 0.8495 and 0.3834, respectively. The estimated probability of malignancy for the lesion is 0.8589 when using classification protocol A (feature averaging), and it is 0.6165 when using protocol B (classifier output averaging), demonstrating a difference of 0.24 between the two protocols. The “all images” view selection protocol was used in this example." class="lazyload" data-proofer-ignore></a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/4_1s20S1076633208002572.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/4_1s20S1076633208002572.jpg" alt="Figure 5, An example of a lesion with a relatively small difference in estimated probability of malignancy between the two different classification protocols. All three images depict the same physical lesion, an aspiration-proved cyst. The estimated probability of malignancy for each image individually is 0.0791, 0.0388, and 0.0323 respectively. The estimated probability of malignancy for the lesion is 0.0434 when using classification protocol A (feature averaging) and it is 0.0501 when using protocol B (classifier output averaging), demonstrating a difference of 0.007 between the two protocols. The “all images” view selection protocol was used in this example." class="lazyload" data-proofer-ignore></a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/5_1s20S1076633208002572.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/5_1s20S1076633208002572.jpg" alt="Figure 6, Receiver-operating characteristic curves resulting from the round robin testing of the different view selection protocols when using feature averaging during classification (protocol A) ( N = 344 for each test). AUC, area under the curve." class="lazyload" data-proofer-ignore></a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/6_1s20S1076633208002572.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/6_1s20S1076633208002572.jpg" alt="Figure 7, Receiver-operating characteristic curves resulting from the round robin testing of the different view selection protocols when using classifier output averaging during classification (protocol B) ( N = 344 for each test). AUC, area under the curve." class="lazyload" data-proofer-ignore></a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/7_1s20S1076633208002572.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/7_1s20S1076633208002572.jpg" alt="Figure 8, Receiver-operating characteristic curves resulting from the round robin testing of the different view selection protocols when no averaging is used (ie, neither feature nor classifier output averaging) during classification (protocol C) ( N = 1067 for the “all images” protocol and N = 517 for the “random images” protocol). AUC, area under the curve." class="lazyload" data-proofer-ignore></a></p><p>Table 2</p><p>Results of Round-robin Analyses for All Classification and View Selection Protocols Given as the Area Under the Receiver-Operating Characteristic Curve</p><p>View Protocol Classification Protocol A B C All images 0.86 (0.813–0.895) 0.87 (0.827–0.905) 0.83 (0.758–0.861) Random images 0.85 (0.806–0.889) 0.85 (0.810–0.892) 0.83 (0.745–0.870) First image only 0.86 (0.811–0.893) 0.86 (0.816–0.898) 0.86 (0.816–0.898)</p><p>Note: Data are indicated as area under the curve (two-sided 95% confidence interval).</p><p>Protocol A: Feature averaging; Protocol B: Classifier output averaging; Protocol C: No averaging.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 3</p><p>Differences in Performance Between the View Selection Protocols for Each Classification Protocol</p><p>View Protocol Comparison Classification Protocol A B C All images vs. random images +0.01 (0.00 to 1) † +0.02 (0.00 to 0.04) ⁎ +0.00 (−0.02 to 1) † All images vs. first image only +0.00 (0.00 to 1) † +0.01 (0.00 to 1) † −0.04 (−0.08 to −0.01) ⁎ First image only vs. random images +0.01 (0.00 to 1) † +0.00 (0.00 to 1) † +0.04 (0.00 to 0.09) ⁎</p><p>Note: Data are indicated as difference in areas under the curves (95% confidence interval).</p><p>Protocol A: Feature averaging; Protocol B: Classifier output averaging; Protocol C: No averaging.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 4</p><p>Differences in Performance Between the Classification Protocols for Each View Selection Protocol</p><p>View Protocol Classification Protocol Comparison B vs. A A vs. C B vs. C All images +0.01 (0.00–1) † +0.04 (0.01–0.09) ⁎ +0.05 (0.03–0.10) ⁎ Random images +0.00 (0.00–1) † +0.03 (0.00–0.09) ⁎ +0.03 (0.00–0.09) ⁎</p><p>Note: Data are indicated as difference in area under the curves (95% confidence interval).</p><p>Protocol A: Feature averaging; Protocol B: Classifier output averaging; Protocol C: No averaging.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">Discussion</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="appendix-1"><span class="mr-2">Appendix 1</span><a href="#appendix-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>O=Area(C∩R)Area(C∪R), O</p><p>=</p><p>A</p><p>r</p><p>e</p><p>a</p><p>(</p><p>C</p><p>∩</p><p>R</p><p>)</p><p>A</p><p>r</p><p>e</p><p>a</p><p>(</p><p>C</p><p>∪</p><p>R</p><p>)</p><p>,</p><p>where <em>O</em> ranges from 0 to 1, with 0 representing no overlap and 1 representing a perfect match. The median value of the overlap was 0.924 with a 95% confidence interval of 0.922–0.927. The distribution of overlap values ( Fig 9 ) demonstrates that the seedpoint selected to begin automated segmentation has only a minimal effect on the segmentation process and that overall the process is fairly consistent. Instances of extremely low overlap ( <em>O</em> &lt; 0.3) were often the result of random seedpoints that were as far from the center of the lesion as the constraints would allow, which is much less likely to occur if the user is instructed to place seedpoints on the center of the lesion (it is also less likely if the lesions are oddly shaped, as the lesion center becomes more “obvious” in those cases). If the random seedpoints are constrained to lie within a mask that has the same shape and centerpoint as the original lesion but only a quarter of its size, the median overlap improves to 0.943 (95% confidence interval, 0.941–0.945). Again this “quarter-size lesion mask” constraint is not unreasonable, as over time the user can be trained to place seedpoints as close to the center of a lesion as possible with minimal effort (using our observer data from above, radiologists placed seedpoints in this manner 93% (1313 of 1406) of the time). When comparing the values of the sonographic features extracted from the outlines, the average difference between the center seedpoint- and random seedpoint–generated outline feature values is nearly 0 for all four features ( Table 5 ). If the random seedpoints are constrained with a quarter-size mask instead of a half-size mask, the average feature differences remain consistent; only the average difference in the radial gradient index value decreased significantly ( <em>P</em> = .0001). Although the feature value standard deviations were not negligible, they seem to be small enough to conclude that overall the automated segmentation process is robust and can operate consistently with variations in input. However, we have also shown that it may be useful to pay more attention to seedpoint placement as the effect it might have is small but not necessarily irrelevant.</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/8_1s20S1076633208002572.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/PerformanceofBreastUltrasoundComputeraidedDiagnosis/8_1s20S1076633208002572.jpg" alt="Figure 9, Histogram depicting the distribution of overlap values between centerpoint–generated lesion outlines and random point–generated lesion outlines." class="lazyload" data-proofer-ignore></a></p><p>Table 5</p><p>Average Difference in Feature Values Between Outlines Generated Using the Center of the Lesion and Outlines Generated Using a Random Point Within the Lesion</p><p>Random Seedpoint Constraint Feature Difference D2W RGI MSD Corrl Mean SD Mean SD Mean SD Mean SD Quarter-size mask &lt;0.001 0.053 0.001 0.085 −0.002 0.057 0.002 0.110 Half-size mask &lt;0.001 0.060 0.005 0.098 −0.002 0.066 &lt;0.001 0.120</p><p>Corrl: autocorrelation in depth direction (texture and shape); D2W: depth-to-width ratio (shape); MSD: maximum side difference (posterior acoustic behavior); RGI: radial gradient index (shape and sharpness).</p><p>Feature values have been normalized to between 0 and 1.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="appendix-2"><span class="mr-2">Appendix 2</span><a href="#appendix-2" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Edwards B.K., Brown M.L., Wingo P.A., et. al.: Annual report to the nation on the status of cancer, 1975–2002, featuring population-based trends in cancer treatment. J Natl Cancer Inst 2005; 97: pp. 1407-1427.</p><li><p>2. Elmore J.G., Armstrong K., Lehman C.D., Fletcher S.W.: Screening for breast cancer. JAMA 2005; 293: pp. 1245-1256.</p><li><p>3. Fine R.E., Staren E.D.: Updates in breast ultrasound. Surg Clin North Am 2004; 84: pp. 1001-1034.</p><li><p>4. Kolb T.M.: Breast US for screening, diagnosing, and staging breast cancer: Issues and controversies; RSNA Categorical Course in Diagnostic Radiology Physics: Advances in Breast Imaging–Physics, Technology, and Clinical Applications 2004.2004.Radiologic Society of North AmericaChicago, IL ; 247–257</p><li><p>5. Berg W.A., Gutierrez L., NessAiver M.S., et. al.: Diagnostic accuracy of mammography, clinical examination, US, and MR imaging in preoperative assessment of breast cancer. Radiology 2004; 233: pp. 830-849.</p><li><p>6. Berg W.A., Blume J.D., Cormack J.B., Mendelson E.B., Madsen E.L., ACRIN 6666 Investigators: Lesion detection and characterization in a breast US phantom: Results of the ACRIN 6666 investigators. Radiology 2006; 239: pp. 693-702.</p><li><p>7. Jackson V.P.: The role of US in breast imaging. Radiology 1990; 177: pp. 305-311.</p><li><p>8. Sickles E.A.: Breast imaging: From 1965 to the present. Radiology 2000; 215: pp. 1-16.</p><li><p>9. Weinstein S.P., Conant E.F., Sehgal C.: Technical advances in breast ultrasound imaging. Semin Ultrasound CT MRI 2006; 27: pp. 273-283.</p><li><p>10. Horsch K., Giger M.L., Venta L.A., Vyborny C.J.: Computerized diagnosis of breast lesions on ultrasound. Med Phys 2002; 29: pp. 157-164.</p><li><p>11. Horsch K., Giger M.L., Vyborny C.J., Venta L.A.: Performance of computer-aided diagnosis in the interpretation of lesions on breast sonography. Acad Radiol 2004; 11: pp. 272-280.</p><li><p>12. Horsch K., Giger M.L., Vyborny C.J., Lan L., Mendelson E.B., Hendrick R.E.: Classification of breast lesions with multimodality computer-aided diagnosis: Observer study results on an independent clinical data set. Radiology 2006; 240: pp. 357-368.</p><li><p>13. Horsch K., Giger M.L., Venta L.A., Vyborny C.J.: Automatic segmentation of breast lesions on ultrasound. Med Phys 2001; 28: pp. 1652-1659.</p><li><p>14. Madjar H., Jellins J.: The Practice of Breast Ultrasound: Techniques, Findings, Differential Diagnosis.2000.ThiemeStuttgart/New York</p><li><p>15. Kupinski M.A., Edwards D.C., Giger M.L., Metz C.E.: Ideal observer approximation using Bayesian classification neural networks. IEEE Trans Med Imaging 2001; 20: pp. 886-899.</p><li><p>16. Metz C.E.: Fundamental ROC analysis.Beutel J.Kundel H.J.Van Metter R.L.Handbook of Medical Imaging, Volume 1: Physics and Psychophysics.2000.SPIE PressBellingham, WA:pp. 751-764.</p><li><p>17. Obuchowski N.A.: Receiver operating characteristic curves and their use in radiology. Radiology 2003; 229: pp. 3-8.</p><li><p>18. Pesce L.L., Metz C.E.: Proproc v2.2.0. Department of Radiology, University of Chicago. http://xray.bsd.uchicago.edu/krl/roc_soft.htm Updated February 27, 2007. Accessed July 1, 2007</p><li><p>19. Pesce L.L., Metz C.E.: Reliable and computationally efficient maximum-likelihood estimation of “proper” binormal ROC curves. Acad Radiol 2007; 14: pp. 814-829.</p><li><p>20. Pepe M.S.: The Statistical Evaluation of Medical Tests for Classification and Prediction.2004.Oxford University PressNew York</p><li><p>21. Mossman D.: Resampling techniques in the analysis of non-binormal ROC data. Med Decis Making 1995; 15: pp. 358-366.</p><li><p>22. Glantz S.A.: Primer of Biostatistics.6th ed2005.McGraw-HillNew York :219–251</p><li><p>23. Pocock S.J.: The pros and cons of noninferiority trials. Fundam Clin Pharmacol 2003; 17: pp. 483-490.</p><li><p>24. Piaggio G., Elbourne D.R., Altman D.G., Pocock S.J., Evans S.J.W.: Reporting of noninferiority and equivalence randomized trials: An extension of the CONSORT statement. JAMA 2006; 295: pp. 1152-1160.</p><li><p>25. Jenkins R., Burton A.M.: 100% accuracy in automatic face recognition. Science 2008; 319: pp. 435.</p><li><p>26. Huo Z., Giger M.L., Vyborny C.J.: Computerized analysis of multiple-mammographic views: Potential usefulness of special view mammograms in computer-aided diagnosis. IEEE Trans Med Imaging 2001; 20: pp. 1285-1292.</p><li><p>27. Liu B., Metz C.E., Jiang Y.: Effect of correlation on combining diagnostic information from two images of the same patient. Med Phys 2005; 32: pp. 3329-3338.</p><li><p>28. Metz C.E., Pan X.: “Proper” binormal ROC curves: Theory and maximum-likelihood estimation. J Math Psychol 1999; 43: pp. 1-33.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-15/'>Volume 15</a>, <a href='/categories/issue-10/'>Issue 10</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Performance%20of%20Breast%20Ultrasound%20Computer-aided%20Diagnosis%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fperformance-of-breast-ultrasound-computer-aided-diagnosis%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Performance%20of%20Breast%20Ultrasound%20Computer-aided%20Diagnosis%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fperformance-of-breast-ultrasound-computer-aided-diagnosis%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fperformance-of-breast-ultrasound-computer-aided-diagnosis%2F&text=Performance%20of%20Breast%20Ultrasound%20Computer-aided%20Diagnosis%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/abstracts-of-funded-national-institutes-of-health-grants/"><div class="card-body"> <em class="small" data-ts="1222794000" data-df="ll" > Sep 30, 2008 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Abstracts of Funded National Institutes of Health Grants</h3><div class="text-muted small"><p> The following abstracts of diagnostic radiology research and training grants funded by the National Institutes of Health (NIH) were awarded to principal investigators (PIs) whose primary appointmen...</p></div></div></a></div><div class="card"> <a href="/posts/accurate-automatic-papillary-muscle-identification-for-quantitative-left-ventricle-mass-measurements/"><div class="card-body"> <em class="small" data-ts="1222794000" data-df="ll" > Sep 30, 2008 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Accurate Automatic Papillary Muscle Identification for Quantitative Left Ventricle Mass Measurements in Cardiac Magnetic Resonance Imaging</h3><div class="text-muted small"><p> Rationale and Objectives We sought to evaluate the automatic detection of the papillary muscle and to determine its influence on quantitative left ventricular (LV) mass assessment. Materials and ...</p></div></div></a></div><div class="card"> <a href="/posts/all-you-need-to-know/"><div class="card-body"> <em class="small" data-ts="1222794000" data-df="ll" > Sep 30, 2008 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>All you need to know</h3><div class="text-muted small"><p> My friend Bob Gayler loaned me a small book that tells, in 100 tightly written pages, all an aspiring radiologist needs to know about how x-rays are generated, how patients should be positioned, an...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/performance-assessments-of-diagnostic-systems-under-the-froc-paradigm/" class="btn btn-outline-primary" prompt="Older"><p>Performance Assessments of Diagnostic Systems Under the FROC Paradigm</p></a> <a href="/posts/sonographically-guided-metallic-marker-placement-at-time-of-wire-localization-for-intraductal-or-cys/" class="btn btn-outline-primary" prompt="Newer"><p>Sonographically-guided Metallic Marker Placement at Time of Wire Localization for Intraductal or Cystic Lesions</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Registering Histologic and MR Images of Prostate for Image-based Cancer Detection" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/registering-histologic-and-mr-images-of-prostate-for-image-based-cancer-detection/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/registering-histologic-and-mr-images-of-prostate-for-image-based-cancer-detection/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2007-10-31T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Registering Histologic and MR Images of Prostate for Image-based Cancer Detection" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-07T07:15:32+00:00","datePublished":"2007-10-31T17:00:00+00:00","description":"Rationale and Objectives","headline":"Registering Histologic and MR Images of Prostate for Image-based Cancer Detection","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/registering-histologic-and-mr-images-of-prostate-for-image-based-cancer-detection/"},"url":"https://clinicaltree.github.io/posts/registering-histologic-and-mr-images-of-prostate-for-image-based-cancer-detection/"}</script><title>Registering Histologic and MR Images of Prostate for Image-based Cancer Detection | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Registering Histologic and MR Images of Prostate for Image-based Cancer Detection</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Registering Histologic and MR Images of Prostate for Image-based Cancer Detection</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1193850000" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Oct 31, 2007 </em> </span> <span> Updated <em class="" data-ts="1680851732" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 7, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Yiqiang Zhan PhD</a> </em>, <em> <a href="">Yangming Ou BS</a> </em>, <em> <a href="">Michael Feldman MD</a> </em>, <em> <a href="">John Tomaszeweski MD</a> </em>, <em> <a href="">Christos Davatzikos PhD</a> </em>, <em> <a href="">Dinggang Shen PhD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4166 words"> <em>23 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Needle biopsy is currently the only way to confirm prostate cancer. To increase prostate cancer diagnostic rate, needles are expected to be deployed at suspicious cancer locations. High-contrast magnetic resonance (MR) imaging provides a powerful tool for detecting suspicious cancerous tissues. To do this, MR appearances of cancerous tissue should be characterized and learned from a sufficient number of prostate MR images with known cancer information. However, ground-truth cancer information is only available in histologic images. Therefore it is necessary to warp ground-truth cancerous regions in histological images to MR images by a registration procedure. The objective of this article is to develop a registration technique for aligning histological and MR images of the same prostate.</p><h2 id="material-and-methods"><span class="mr-2">Material and Methods</span><a href="#material-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Five pairs of histological and T2-weighted MR images of radical prostatectomy specimens are collected. For each pair, registration is guided by two sets of correspondences that can be reliably established on prostate boundaries and internal salient bloblike structures of histologic and MR images.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Our developed registration method can accurately register histologic and MR images. It yields results comparable to manual registration, in terms of landmark distance and volume overlap. It also outperforms both affine registration and boundary-guided registration methods.</p><h2 id="conclusions"><span class="mr-2">Conclusions</span><a href="#conclusions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>We have developed a novel method for deformable registration of histologic and MR images of the same prostate. Besides the collection of ground-truth cancer information in MR images, the method has other potential applications. An automatic, accurate registration of histologic and MR images actually builds a bridge between in vivo anatomical information and ex vivo pathologic information, which is valuable for various clinical studies.</p><p>Prostate cancer is classified as an adenocarcinoma, or glandular cancer, that begins when normal semen-secreting prostate gland cells mutate into cancer cells. Pathologic analysis shows the regular glands of the normal prostate are replaced by irregular glands and clumps of cells for prostate cancer ( ). From the radiologists’ perspective, the variations at the cell level lead to changes of signal intensity in in vivo medical images (eg, magnetic resonance [MR] and ultrasound images). Because MR images provide better contrast between prostate cancer and normal tissue in the peripheral zone ( ), some researchers proposed to use endorectal or whole-body coil MR images for image-based prostate cancer identification ( ). Recently, with the progress of pattern recognition theory, some algorithms ( ) have been designed to automatically identify cancerous tissue using image features extracted from MR images.</p><p>In our study toward the early diagnosis of prostate cancer, we proposed a computer-aided biopsy system, which aims to increase the diagnosis accuracy of prostate biopsy using population-based statistical information ( ) as well as patient-specific image information. As shown in Fig 1 , our proposed biopsy system consists of three modules, respectively for image-based biopsy optimization, atlas-based biopsy optimization, and integration and application of optimized biopsy strategies. In the atlas-based biopsy optimization module, biopsy needles are deployed at the locations where the statistical atlas of prostate cancer distribution exhibits higher cancer incidence. In the image-based biopsy optimization module, biopsy needles are deployed at the locations where the tissue appearances are similar to those of cancerous tissue. To achieve this objective, an automatic image analysis method is expected for labeling the suspicious cancerous tissue by learning the MR signatures of cancerous tissue from a sufficient number of prostate MR image samples where ground-truth cancer has been identified. However, since the ground-truth cancer information is only available in the histological images, it is necessary to warp the confirmed cancerous regions in histological images to MR images, in order to collect ground-truth cancer information in MR images. Figure 2 shows an example of warping a ground-truth cancerous region from the histological image to the MR image of the same prostate. The dark pink region in Fig 2 a indicates ground-truth cancerous region in the histological image, and the green region in Fig 2 c denotes the warped ground-truth cancerous region in the MR image.</p><p><a href="APKAICLNFGBCWWYGVIZQ" class="popup img-link "><img data-src="https://d1niluoi1dd30v.cloudfront.net/10766332/S1076633207X00928/S1076633207004461/gr1.jpg?Signature=Ix-cZrY868td46WWivAZxoeoqnyNBIJGg5rDzAVo5Tg5ndpc8DHwzlgistYGPCFvZHygW6KCiVnkiWRePt0R-DIUn2HqGboNK0qk3Gprzmx1Rv8RL0edxB7WCL7%7E0-UZCxpOkwx6A3M9qDJFc%7E2Cm0t8Iu7UewH2m5cID%7E7qr68_&amp;Expires=1669522064&amp;Key-Pair-Id=APKAICLNFGBCWWYGVIZQ" alt="" class="lazyload" data-proofer-ignore></a>Open full size image</p><p>Figure 1</p><p>Schematic description of our proposed computer-aided biopsy system. (1) Generate optimal biopsy strategy based on patient-specific image information. (2) Generate optimal biopsy strategy based on population-based statistical information. (3) Integrate the two biopsy strategies and apply them to an individual patient.</p><p><a href="APKAICLNFGBCWWYGVIZQ" class="popup img-link "><img data-src="https://d1niluoi1dd30v.cloudfront.net/10766332/S1076633207X00928/S1076633207004461/gr2.jpg?Signature=ZmpGgbUIFj7-hFuXpplDxRvwSq9Pe5hb7wvi2KNhrAnO3Gqw0xq2A3mksO7EoIXz9XU36CUz1Q6Qp5ZW8YJy7F9oY8cSnM7HFOX9J4U2xPBrM4XYWi1rhs7O2UZLiIS-9rF1fDFwYra06r6h6ci4wKiL90G4Cql0pqYf6HZ709A_&amp;Expires=1669522064&amp;Key-Pair-Id=APKAICLNFGBCWWYGVIZQ" alt="" class="lazyload" data-proofer-ignore></a>Open full size image</p><p>Figure 2</p><p>An example of warping a ground-truth cancerous region from the histological image to the magnetic resonance (MR) image of the same prostate. <strong>(a)</strong> Prostate histologic image, where the dark pink region denotes ground-truth cancer labeled by a pathologist. <strong>(b)</strong> Prostate T2-weighted MR image. <strong>(c)</strong> Prostate T2-weighted MR image with manually warped cancer ground truth as indicated by a green region.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="related-work"><span class="mr-2">Related work</span><a href="#related-work" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="methods"><span class="mr-2">Methods</span><a href="#methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="boundary-landmarks"><span class="mr-2">Boundary Landmarks</span><a href="#boundary-landmarks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="boundary-landmarks-detection"><span class="mr-2">Boundary landmarks detection</span><a href="#boundary-landmarks-detection" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="similarity-definition-of-boundary-landmarks"><span class="mr-2">Similarity definition of boundary landmarks</span><a href="#similarity-definition-of-boundary-landmarks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/0_1s20S1076633207004461.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/0_1s20S1076633207004461.jpg" alt="Figure 3, Geometric attributes of a boundary landmark. For a boundary landmark x i , its geometric attributes are defined by the volumes of the tetrahedrons formed by vertices x i and its neighbors nbrl,0(xi)nbrl,m1 nbrl,0(xi)nbrl,m1 and nbrl,m2(xi) nbrl,m2(xi) . Here, m1=⌊SIl(xi)/3⌋ m1=⌊SIl(xi)/3⌋ and m2=⌊SIl(xi)×2/3⌋ m2=⌊SIl(xi)×2/3⌋ , (⌊.⌋defines the floor function) where SIl( x i ) is the number of vertices contained by l -th neighborhood layer of x i ." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>S(xi,yj)=1−∥∥F¯¯¯(xi)−F¯¯¯(yj)∥∥ S</p><p>(</p><p>x</p><p>i</p><p>,</p><p>y</p><p>j</p><p>)</p><p>=</p><p>1</p><p>−</p><p>‖</p><p>F</p><p>¯</p><p>(</p><p>x</p><p>i</p><p>)</p><p>−</p><p>F</p><p>¯</p><p>(</p><p>y</p><p>j</p><p>)</p><p>‖</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="internal-landmarks"><span class="mr-2">Internal Landmarks</span><a href="#internal-landmarks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/1_1s20S1076633207004461.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/1_1s20S1076633207004461.jpg" alt="Figure 4, Corresponding bloblike structures in prostate histological and magnetic resonance (MR) images. (a) Prostate histologic image. (b) Prostate MR images. Red arrows point to the corresponding bloblike structures commonly available in histologic and MR images." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="salient-structure-detection-with-automatic-scale-selection"><span class="mr-2">Salient structure detection with automatic scale selection</span><a href="#salient-structure-detection-with-automatic-scale-selection" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>L(x,y,z;s)=g(x,y,z;s)∗f(x,y,z) L</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>;</p><p>s</p><p>)</p><p>=</p><p>g</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>;</p><p>s</p><p>)</p><p>∗</p><p>f</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>)</p><p>where g(x,y,z;s)=1(2πs2)3/2e−(x2+y2+z2)/2s2 g</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>;</p><p>s</p><p>)</p><p>=</p><p>1</p><p>(</p><p>2</p><p>π</p><p>s</p><p>2</p><p>)</p><p>3</p><p>/</p><p>2</p><p>e</p><p>−</p><p>(</p><p>x</p><p>2</p><p>+</p><p>y</p><p>2</p><p>+</p><p>z</p><p>2</p><p>)</p><p>/</p><p>2</p><p>s</p><p>2 . Gaussian function is selected here as a convolution kernel, since it is stated as the unique kernel for generating a scale-space within the class of linear transformations ( ).</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>∂ξ=s∂x ∂</p><p>ξ</p><p>=</p><p>s</p><p>∂</p><p>x</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>∇normL(x,y,z;s)=∇ξL(x,y,z;s)=s∇L(x,y,z;s) ∇</p><p>n</p><p>o</p><p>r</p><p>m</p><p>L</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>;</p><p>s</p><p>)</p><p>=</p><p>∇</p><p>ξ</p><p>L</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>;</p><p>s</p><p>)</p><p>=</p><p>s</p><p>∇</p><p>L</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>;</p><p>s</p><p>)</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="internal-landmarks-detection"><span class="mr-2">Internal landmarks detection</span><a href="#internal-landmarks-detection" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/2_1s20S1076633207004461.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/2_1s20S1076633207004461.jpg" alt="Figure 5, Schematic explanation of the scale-space analysis method. The local peak responses of normalized Laplacian describe important properties of bloblike structures and are used for selecting the candidates of internal landmarks." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>f(x,y,z)=A(32s20)3/2e−((x−x0)2+(y−y0)2+(z−z0)2)/2(32s20) f</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>)</p><p>=</p><p>A</p><p>(</p><p>3</p><p>2</p><p>s</p><p>0</p><p>2</p><p>)</p><p>3</p><p>/</p><p>2</p><p>e</p><p>−</p><p>(</p><p>(</p><p>x</p><p>−</p><p>x</p><p>0</p><p>)</p><p>2</p><p>+</p><p>(</p><p>y</p><p>−</p><p>y</p><p>0</p><p>)</p><p>2</p><p>+</p><p>(</p><p>z</p><p>−</p><p>z</p><p>0</p><p>)</p><p>2</p><p>)</p><p>/</p><p>2</p><p>(</p><p>3</p><p>2</p><p>s</p><p>0</p><p>2</p><p>)</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>L(x,y,z;s)=A(32s20+s2)3/2e−((x−x0)2+(y−y0)2+(z−z0)2)/2(32s20+s2) L</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>;</p><p>s</p><p>)</p><p>=</p><p>A</p><p>(</p><p>3</p><p>2</p><p>s</p><p>0</p><p>2</p><p>+</p><p>s</p><p>2</p><p>)</p><p>3</p><p>/</p><p>2</p><p>e</p><p>−</p><p>(</p><p>(</p><p>x</p><p>−</p><p>x</p><p>0</p><p>)</p><p>2</p><p>+</p><p>(</p><p>y</p><p>−</p><p>y</p><p>0</p><p>)</p><p>2</p><p>+</p><p>(</p><p>z</p><p>−</p><p>z</p><p>0</p><p>)</p><p>2</p><p>)</p><p>/</p><p>2</p><p>(</p><p>3</p><p>2</p><p>s</p><p>0</p><p>2</p><p>+</p><p>s</p><p>2</p><p>)</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Q(s)=max(x,y,z)∣∣(∇2normL(x,y,z;s)∣∣=∣∣(∇2normL(x0,y0,z0;s)∣∣=3As2(32s20+s2)5/2 Q</p><p>(</p><p>s</p><p>)</p><p>=</p><p>max</p><p>⁡</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>)</p><p>|</p><p>(</p><p>∇</p><p>n</p><p>o</p><p>r</p><p>m</p><p>2</p><p>L</p><p>(</p><p>x</p><p>,</p><p>y</p><p>,</p><p>z</p><p>;</p><p>s</p><p>)</p><p>|</p><p>=</p><p>|</p><p>(</p><p>∇</p><p>n</p><p>o</p><p>r</p><p>m</p><p>2</p><p>L</p><p>(</p><p>x</p><p>0</p><p>,</p><p>y</p><p>0</p><p>,</p><p>z</p><p>0</p><p>;</p><p>s</p><p>)</p><p>|</p><p>=</p><p>3</p><p>A</p><p>s</p><p>2</p><p>(</p><p>3</p><p>2</p><p>s</p><p>0</p><p>2</p><p>+</p><p>s</p><p>2</p><p>)</p><p>5</p><p>/</p><p>2</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>dQds=9As(s20−s2)(32s20+s2)7/2 d</p><p>Q</p><p>d</p><p>s</p><p>=</p><p>9</p><p>A</p><p>s</p><p>(</p><p>s</p><p>0</p><p>2</p><p>−</p><p>s</p><p>2</p><p>)</p><p>(</p><p>3</p><p>2</p><p>s</p><p>0</p><p>2</p><p>+</p><p>s</p><p>2</p><p>)</p><p>7</p><p>/</p><p>2</p><p>Because Eq 8 equals to zero when <em>s</em> = <em>s</em> 0 , the normalized Laplacian achieves its maximum at ( <em>x</em> 0 , <em>y</em> 0 , <em>z</em> 0 ; <em>s</em> 0 ) in the scale-space, which indicates a blob detected with center ( <em>x</em> 0 , <em>y</em> 0 , <em>z</em> 0 ) and size 32−−√s0 3</p><p>2</p><p>s</p><p>0 . In other words, if we detect a peak at a location ( <em>x</em> 0 , <em>y</em> 0 , <em>z</em> 0 ) with scale <em>s</em> 0 , it indicates that there might exist a blob centered at ( <em>x</em> 0 , <em>y</em> 0 , <em>z</em> 0 ) with the size of 32−−√s0 3</p><p>2</p><p>s</p><p>0 .</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/3_1s20S1076633207004461.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/3_1s20S1076633207004461.jpg" alt="Figure 6, Detection of internal landmarks. The internal landmarks are detected from prostate histological image (a) and magnetic resonance image (b) , respectively. The blue/red dots denote the centers of the detected bloblike structures and the sizes of the circles indicate the salient scales of the bloblike structures." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="similarity-definition-of-internal-landmarks"><span class="mr-2">Similarity definition of internal landmarks</span><a href="#similarity-definition-of-internal-landmarks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>M(u,v)=max−α≤Δ≤α∑Ni=1NMI{V(u,i⋅su),T(V(v,i⋅sv);susv,Δ)} M</p><p>(</p><p>u</p><p>,</p><p>v</p><p>)</p><p>=</p><p>max</p><p>⁡</p><p>−</p><p>α</p><p>≤</p><p>Δ</p><p>≤</p><p>α</p><p>∑</p><p>i</p><p>=</p><p>1</p><p>N</p><p>N</p><p>M</p><p>I</p><p>{</p><p>V</p><p>(</p><p>u</p><p>,</p><p>i</p><p>⋅</p><p>s</p><p>u</p><p>)</p><p>,</p><p>T</p><p>(</p><p>V</p><p>(</p><p>v</p><p>,</p><p>i</p><p>⋅</p><p>s</p><p>v</p><p>)</p><p>;</p><p>s</p><p>u</p><p>s</p><p>v</p><p>,</p><p>Δ</p><p>)</p><p>}</p><p>Where <em>V</em> ( <em>u, R</em> ) denotes a spherical local patch around the landmark <em>u</em> with the radius <em>R</em> . T(V; s, Δ <em>θ</em> ) is the transformation operator with a scaling factor <em>s</em> and a rotation factor Δ <em>θ</em> . The variable <em>i</em> is the size factor of the local patch where NMI is calculated, and <em>N</em> is the total number of multiple local patches used. <em>NMI</em> { · , · } denotes the normalized mutual information between two same-sized spherical volume images. (Δθ = π/8 π</p><p>/</p><p>8 and <em>N</em> = 3 in this study)</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="overall-similarity-function"><span class="mr-2">Overall Similarity Function</span><a href="#overall-similarity-function" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>A={aik} A</p><p>=</p><p>{</p><p>a</p><p>i</p><p>k</p><p>}</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>{∑I+1i=1aik=1(k=1,⋯,K);∑K+1k=1aik=1(i=1,⋯,I);aik∈[0,1]} {</p><p>∑</p><p>i</p><p>=</p><p>1</p><p>I</p><p>+</p><p>1</p><p>a</p><p>i</p><p>k</p><p>=</p><p>1</p><p>(</p><p>k</p><p>=</p><p>1</p><p>,</p><p>⋯</p><p>,</p><p>K</p><p>)</p><p>;</p><p>∑</p><p>k</p><p>=</p><p>1</p><p>K</p><p>+</p><p>1</p><p>a</p><p>i</p><p>k</p><p>=</p><p>1</p><p>(</p><p>i</p><p>=</p><p>1</p><p>,</p><p>⋯</p><p>,</p><p>I</p><p>)</p><p>;</p><p>a</p><p>i</p><p>k</p><p>∈</p><p>[</p><p>0</p><p>,</p><p>1</p><p>]</p><p>}</p><p>and</p><p>B={bjl} B</p><p>=</p><p>{</p><p>b</p><p>j</p><p>l</p><p>}</p><p>subject to</p><p>{∑J+1j=1bjl=1(l=1,⋯,L);∑L+1l=1bjl=1(j=1,⋯,J);bjl∈[0,1]} {</p><p>∑</p><p>j</p><p>=</p><p>1</p><p>J</p><p>+</p><p>1</p><p>b</p><p>j</p><p>l</p><p>=</p><p>1</p><p>(</p><p>l</p><p>=</p><p>1</p><p>,</p><p>⋯</p><p>,</p><p>L</p><p>)</p><p>;</p><p>∑</p><p>l</p><p>=</p><p>1</p><p>L</p><p>+</p><p>1</p><p>b</p><p>j</p><p>l</p><p>=</p><p>1</p><p>(</p><p>j</p><p>=</p><p>1</p><p>,</p><p>⋯</p><p>,</p><p>J</p><p>)</p><p>;</p><p>b</p><p>j</p><p>l</p><p>∈</p><p>[</p><p>0</p><p>,</p><p></p><p>1</p><p>]</p><p>}</p><p>It is worth noting that <em>a ik</em> and <em>b jl</em> have real values between 0 and 1, which denote the fuzzy correspondences between landmarks ( ). Also, an extra row (i.e., { <em>a</em> ( <em>I</em> +1) <em>k</em> } or { <em>b</em> ( <em>J</em> +1) <em>1</em> }) and an extra column (i.e., { <em>a</em> ( <em>K</em> +1) } or { <em>b__j(L</em> +1) <em>1</em> }) are added to each correspondence matrix (i.e., <em>A</em> or <em>B</em> ) for handling the outliers. If a landmark cannot find its correspondence, it is regarded as an outlier and the extra entry of this landmark will be set as 1.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>maxA,B,hE(A,B,h)=maxA,B,h{[α∑Ii=1∑Kk=1aikS(xi,yk)+β∑Jj=1∑Ll=1bjlM(uj,vl)]−λ[∑Ii=1∑Kk=1aikD(xi,h(yk))+∑Jj=1∑Ll=1bjlD(uj,h(vl))+∥W(h)∥2]−[τ(∑Ii=1∑Kk=1aiklogaik+∑Jj=1∑Ll=1bjllogbjl)−ζ(∑Ii=1∑Kk=1aik+∑Jj=1∑Ll=1bjl)]} max</p><p>⁡</p><p>A</p><p>,</p><p>B</p><p>,</p><p>h</p><p>E</p><p>(</p><p>A</p><p>,</p><p>B</p><p>,</p><p>h</p><p>)</p><p>=</p><p>max</p><p>⁡</p><p>A</p><p>,</p><p>B</p><p>,</p><p>h</p><p>{</p><p>[</p><p>α</p><p>∑</p><p>i</p><p>=</p><p>1</p><p>I</p><p>∑</p><p>k</p><p>=</p><p>1</p><p>K</p><p>a</p><p>i</p><p>k</p><p>S</p><p>(</p><p>x</p><p>i</p><p>,</p><p>y</p><p>k</p><p>)</p><p>+</p><p>β</p><p>∑</p><p>j</p><p>=</p><p>1</p><p>J</p><p>∑</p><p>l</p><p>=</p><p>1</p><p>L</p><p>b</p><p>j</p><p>l</p><p>M</p><p>(</p><p>u</p><p>j</p><p>,</p><p>v</p><p>l</p><p>)</p><p>]</p><p>−</p><p>λ</p><p>[</p><p>∑</p><p>i</p><p>=</p><p>1</p><p>I</p><p>∑</p><p>k</p><p>=</p><p>1</p><p>K</p><p>a</p><p>i</p><p>k</p><p>D</p><p>(</p><p>x</p><p>i</p><p>,</p><p>h</p><p>(</p><p>y</p><p>k</p><p>)</p><p>)</p><p>+</p><p>∑</p><p>j</p><p>=</p><p>1</p><p>J</p><p>∑</p><p>l</p><p>=</p><p>1</p><p>L</p><p>b</p><p>j</p><p>l</p><p>D</p><p>(</p><p>u</p><p>j</p><p>,</p><p>h</p><p>(</p><p>v</p><p>l</p><p>)</p><p>)</p><p>+</p><p>‖</p><p>W</p><p>(</p><p>h</p><p>)</p><p>‖</p><p>2</p><p>]</p><p>−</p><p>[</p><p>τ</p><p>(</p><p>∑</p><p>i</p><p>=</p><p>1</p><p>I</p><p>∑</p><p>k</p><p>=</p><p>1</p><p>K</p><p>a</p><p>i</p><p>k</p><p>log</p><p>⁡</p><p>a</p><p>i</p><p>k</p><p>+</p><p>∑</p><p>j</p><p>=</p><p>1</p><p>J</p><p>∑</p><p>l</p><p>=</p><p>1</p><p>L</p><p>b</p><p>j</p><p>l</p><p>log</p><p>⁡</p><p>b</p><p>j</p><p>l</p><p>)</p><p>−</p><p>ζ</p><p>(</p><p>∑</p><p>i</p><p>=</p><p>1</p><p>I</p><p>∑</p><p>k</p><p>=</p><p>1</p><p>K</p><p>a</p><p>i</p><p>k</p><p>+</p><p>∑</p><p>j</p><p>=</p><p>1</p><p>J</p><p>∑</p><p>l</p><p>=</p><p>1</p><p>L</p><p>b</p><p>j</p><p>l</p><p>)</p><p>]</p><p>}</p><p>Here, matrixes <em>A</em> and <em>B</em> are the fuzzy correspondences matrixes subject to Eq 10 and 11 , and <em>h</em> denotes the transformation between histologic and MR images. The two terms in the first square bracket denote the similarity between landmarks, where <em>S</em> ( · , · ) and <em>M</em> ( · , · ) are the similarity between boundary landmarks and the similarity between internal landmarks, as defined in Eq 1 and 9 , respectively. The three terms in the second square bracket jointly place smoothness constraints on the transformation <em>h</em> . <em>D</em> ( · , · ) denotes the Euclidean distance between two points, and ‖ <em>W</em> ( <em>h</em> )‖ 2 is a smoothness measurement of <em>h</em> . In our study, because thin plate spline is selected to model the transformation <em>h</em> , the smoothing term is the “bending energy” of the transformation <em>h</em> , for example:</p><p>∥W(h)∥2=∫∫∫[(∂2h∂x2)2+(∂2h∂y2)2+(∂2h∂z2)2+2(∂2h∂x∂y)2+2(∂2h∂x∂z)2+2(∂2h∂y∂z)2]dxdydz ‖</p><p>W</p><p>(</p><p>h</p><p>)</p><p>‖</p><p>2</p><p>=</p><p>∫</p><p>∫</p><p>∫</p><p>[</p><p>(</p><p>∂</p><p>2</p><p>h</p><p>∂</p><p>x</p><p>2</p><p>)</p><p>2</p><p>+</p><p>(</p><p>∂</p><p>2</p><p>h</p><p>∂</p><p>y</p><p>2</p><p>)</p><p>2</p><p>+</p><p>(</p><p>∂</p><p>2</p><p>h</p><p>∂</p><p>z</p><p>2</p><p>)</p><p>2</p><p>+</p><p>2</p><p>(</p><p>∂</p><p>2</p><p>h</p><p>∂</p><p>x</p><p>∂</p><p>y</p><p>)</p><p>2</p><p>+</p><p>2</p><p>(</p><p>∂</p><p>2</p><p>h</p><p>∂</p><p>x</p><p>∂</p><p>z</p><p>)</p><p>2</p><p>+</p><p>2</p><p>(</p><p>∂</p><p>2</p><p>h</p><p>∂</p><p>y</p><p>∂</p><p>z</p><p>)</p><p>2</p><p>]</p><p>d</p><p>x</p><p>d</p><p>y</p><p>d</p><p>z</p><p>The four terms in the third square bracket are used to direct the correspondences matrixes <em>A</em> and <em>B</em> converging to binary ( ). With a higher <em>τ</em> , the correspondences are forced to be more fuzzy and become a factor in “convexifying” the objective function. Although <em>τ</em> is gradually reduced to zero, the fuzzy correspondences become binary ( ).</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/4_1s20S1076633207004461.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/4_1s20S1076633207004461.jpg" alt="Figure 7, Correspondences between internal landmarks. The correspondences between internal landmarks in histologic image (a) and magnetic resonance images (b) are shown by color crosses. Crosses with the same color denote the corresponding internal landmarks." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="data-preparation"><span class="mr-2">Data Preparation</span><a href="#data-preparation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="experiments-to-register-anatomic-structures-of-prostates"><span class="mr-2">Experiments to Register Anatomic Structures of Prostates</span><a href="#experiments-to-register-anatomic-structures-of-prostates" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 1</p><p>Average Distances Between the Prostate Capsule Surfaces in Magnetic Resonance Images and in Warped Histologic Images</p><p>Method 1 (mm) Method 2 (mm) Method 3 (mm) Subject 1 0.92 0.66 0.62 Subject 2 1.02 0.78 0.83 Subject 3 0.97 0.61 0.61 Subject 4 0.95 0.65 0.63 Subject 5 1.03 0.70 0.72 Mean 0.98 0.68 0.68</p><p>Method 1: mutual information based affine registration method. Method 2: method using only boundary landmarks. Method 3: the proposed method.</p><p>Table 2</p><p>Volume Overlay Error Between the Prostate Glands in Magnetic Resonance Images and in Warped Histologic Images</p><p>Method 1 Method 2 Method 3 Subject 1 8.6% 5.8% 5.1% Subject 2 9.3% 6.8% 7.2% Subject 3 7.5% 5.3% 5.3% Subject 4 8.1% 5.0% 5.3% Subject 5 9.3% 7.0% 7.7% Mean 8.6% 6.0% 6.1%</p><p>Method 1: mutual information based affine registration method. Method 2: method using only boundary landmarks. Method 3: the proposed method.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 3</p><p>Average Distances Between Manually and Automatically Labeled Corresponding Landmarks</p><p>Method 1 (mm) Method 2 (mm) Method 3 (mm) Subject 1 1.31 1.03 0.77 Subject 2 1.81 1.05 0.97 Subject 3 1.25 0.97 0.76 Subject 4 1.43 1.09 0.81 Subject 5 1.53 1.03 0.87 Mean 1.47 1.03 0.82</p><p>Method 1: mutual information based affine registration method. Method 2: method using only boundary landmarks. Method 3: the proposed method.</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/5_1s20S1076633207004461.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/RegisteringHistologicandMRImagesofProstateforImagebasedCancerDetection/5_1s20S1076633207004461.jpg" alt="Figure 8, Comparison of warping histologic images to match with magnetic resonance (MR) images by three different registration methods. Two red points and a red region in (a) denote the manually labeled landmarks and cancerous region in an MR image, respectively. For comparison, those red points and the boundary of cancerous region are repeatedly displayed in three warped histological images (b–d) by three registration methods (ie, Methods 1, 2, and 3, respectively). The blue points in each of three warped histologic images (b–d) are the warped landmarks manually labeled in original histologic image, as correspondences to those red landmarks in MR image. The dark region in each warped histologic image denotes the warped version of the manually labeled cancerous region in the histologic image." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="experiments-to-warp-ground-truth-cancerous-region"><span class="mr-2">Experiments to Warp Ground-Truth Cancerous Region</span><a href="#experiments-to-warp-ground-truth-cancerous-region" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 4</p><p>Volume Overlay Percentage Between Manually and Automatically Labeled Cancerous Regions</p><p>Method 1 Method 2 Method 3 Maximum 82.9% 87.5% 88.3% Minimum 55.9% 60.4% 64.1% Average 71.6% 75.5% 79.1%</p><p>Method 1: mutual information based affine registration method. Method 2: method using only boundary landmarks. Method 3: the proposed method.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="conclusions-1"><span class="mr-2">Conclusions</span><a href="#conclusions-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Christens-Barry W.A., Partin A.W.: Quantitative grading of tissue and nuclei in prostate cancer for prognosis prediction. Johns Hopkins Apl Technical Digest 1997; 18: pp. 226-233.</p><li><p>2. Rifkin M., Zerhouni E., Gatsonis C., et. al.: Comparison of magnetic resonance imaging and ultrasonography in staging early prostate cancer. N Engl J Med 1990; 323: pp. 621-626.</p><li><p>3. Ikonen S., Kaerkkaeinen P., Kivisaari L., et. al.: Magnetic resonance imaging of clinically localized prostatic cancer. J Urol 1998; 159: pp. 915-919.</p><li><p>4. Madabhushi A., Feldman M., Metaxas D.N., et. al.: A novel stochastic combination of 3D texture features for automated segmentation of prostatic adenocarcinoma from high resolution MRI.2003. Presented at MICCAI.</p><li><p>5. Chan I., Wells W., Mulkern R.V., et. al.: Detection of prostate cancer by integration of line-scan diffusion, T2-mapping and T2-weighted magnetic resonance imaging; a multichannel statistical classifier. Med Phys 2003; 30: pp. 2390-2398.</p><li><p>6. Zhan Y., Shen D., Zeng J., et. al.: Targeted prostate biopsy using statistical image analysis. IEEE Trans Med Imaging 2007; 26: pp. 779-788.</p><li><p>7. Madabhushi A., Feldman M.D., Metaxas D.N., et. al.: Automated detection of prostatic adenocarcinoma from high-resolution ex vivo MRI. IEEE Trans Med Imaging 2005; 24: pp. 1611-1625.</p><li><p>8. Fix A., Stitzel S., Ridder G., et. al.: MK-801 neurotoxicity in cupric silver-stained sections: Lesion reconstruction by 3-dimensional computer image analysis. Toxicol Pathol 2000; pp. 84-90.</p><li><p>9. Moskalik A., Rubin M., Wojno K.: Analysis of three-dimensional Doppler ultrasonographic quantitative measures for the discrimination of prostate cancer. J Ultrasound Med 2001; 20: pp. 713-722.</p><li><p>10. Chui H., Rangarajan A.: A new point matching algorithm for non-rigid registration. Comp Vision Image Understanding 2003; 89: pp. 114-141.</p><li><p>11. Thompson P.M., Mega M.S., Woods R.P., et. al.: Cortical change in Alzheimer’s disease detected with a disease-specific population-based brain atlas. Cerebr Cortex 2001; 11: pp. 1-16.</p><li><p>12. Shen D.: 4D image warping for measurement of longitudinal brain changes.2004. Presented at Proceedings of the IEEE International Symposium on Biomedical Imaging, Arlington, VA.</p><li><p>13. Fan Y., Shen D., Davatzikos C.: Classification of structural images via high-dimensional image warping, robust feature extraction, and SVM.2005. Presented at MICCAI, Palm Springs, CA.</p><li><p>14. Rouet J.-M., Jacq J.-J., Roux C.: Genetic algorithms for a robust 3-D MR-CT registration. IEEE Trans Inform Technol Biomed 2000; 4: pp. 126-136.</p><li><p>15. Hill D.L.G., Hawkes D.G., Gleeson M.J., et. al.: Accurate frameless registration of MR and CT images of the head: applications in planning surgery and radiation therapy. Radiology 1994; 191: pp. 447-454.</p><li><p>16. Maes F., Collignon A., Vandermeulen D., et. al.: Multimodality image registration by maximization of mutual information. IEEE Trans Med Imaging 1997; 16: pp. 187-198.</p><li><p>17. Collignon A., Vandermeulen D., Suetens P., et. al.: 3D multimodality medical image registration using feature space clustering.Ayache N.1995.Springer-VerlagBerlin, Germany:pp. 195-204.</p><li><p>18. Wachowiak M.P.S., Zheng R., Zurada Y., et. al.: An approach to multimodal biomedical image registration utilizing particle swarm optimization. IEEE Trans Evol Comp 2004; 8: pp. 289-301.</p><li><p>19. Taylor L., Porter B., Nadasdy G., et. al.: Three-dimensional registration of prostate images from histology and ultrasound. Ultrasound Med Biol 2004; 30: pp. 161-168.</p><li><p>20. Jacobs M., Windham J., Soltanian-Zadeh H., et. al.: Registration and warping of magnetic resonance images to histological sections. Med Phys 1999; 26: pp. 1568-1578.</p><li><p>21. Schormann T., Zilles K.: Three-dimensional linear and nonlinear transformations: An integration of light microscopical and MRI data. Human Brain Map 1998; 6: pp. 339-347.</p><li><p>22. d’Aische AdB., Craene M.D., Geets X., et. al.: Efficient multi-modal dense field non-rigid registration: alignment of histological and section images. Med Image Anal 2004; 9: pp. 538-546.</p><li><p>23. Bardinet E., Ourselin S., Dormont D., et. al.: Co-registration of histological, optical and MR data of the human brain.2002. Presented at Medical Image Computing and Computer-Assisted Intervention, Tokyo, Japan.</p><li><p>24. Andronache A., Cattin P., Szekely G.: Adaptive subdivision for hierarchical non-rigid registration of multi-modal images using mutual information.2005. Presented at MICCAI.</p><li><p>25. Lorensen W.E., Cline H.E.: Marching cubes: a high resolution 3D surface reconstruction algorithm. Comp Graphics 1987; 21: pp. 163-169.</p><li><p>26. Shen D., Herskovits E.H., Davatzikos C.: An adaptive-focus statistical shape model for segmentation and shape modeling of 3D brain structures. IEEE Trans Med Imaging 2001; 20: pp. 257-270.</p><li><p>27. Witkin A.: Scale-space filtering: a new approach to multi-scale description.1984. Presented at IEEE International Conference on Acoustics, Speech, and Signal Processing, West Germany.</p><li><p>28. Lindeberg T.: Feature detection with automatic scale selection. Int J Comp Vis 1998; 30: pp. 77-116.</p><li><p>29. Lindeberg T.: Scale-space for discrete signals. IEEE Trans Pattern Anal Machine Intell 1990; 12: pp. 234-254.</p><li><p>30. Pauwels E.J.V.G., Fiddelaers L.J., Moons P., et. al.: An extended class of scale-invariant and recursive scale space filters. IEEE Trans Pattern Anal Machine Intell 1995; 17: pp. 691-701.</p><li><p>31. Lindeberg T.: Scale-space theory: a basic tool for analysing structures at different scales. J Appl Stat 1994; 21: pp. 223-261.</p><li><p>32. Studholme C.H., Hawkes D.L.G.: An overlap invariant entropy measure of 3D medical image alignment. Patt Recogn 1999; 32: pp. 71-86.</p><li><p>33. Hardy R.: Theory and applications of the multiquadric-biharmonic method. Comp Math Application 1990; 19: pp. 163-208.</p><li><p>34. Bookstein F.L.: Principal warps: thin-plate splines and the decomposition of deformations. IEEE Trans Pattern Anal Machine Intell 1989; 11: pp. 567-585.</p><li><p>35. Arad N., Reisfeld D.: Image warping using few anchor points and radial functions. Comp Graphics Forum 1995; 14: pp. 35-46.</p><li><p>36. Davatzikos C., Abraham F., Biros G., et. al.: Correspondence detection in diffusion tensor images.2006. Presented at ISBI, Washington, DC.</p><li><p>37. Xie Z., Farin G.E.: Image registration using hierarchical B-splines. IEEE Trans Visual Comp Graphics 2004; 10: pp. 85-94.</p><li><p>38. Rueckert D., Sonoda L.I., Hayes C., et. al.: Non-rigid registration using free-form deformations: application to breast MR images. IEEE Trans Med Imaging 1999; 18: pp. 712-721.</p><li><p>39. Yang J., Blum R.S., Williams J.P., et. al.: Non-rigid Image registration using geometric features and local salient region features.2006. Presented at IEEE Computer Society Conference on Computer Vision and Pattern Recognition, New York, NY.</p><li><p>40. Jenkinson M., Bannister P.R., Brady J.M., et. al.: Improved optimisation for the robust and accurate linear registration and motion correction of brain images. NeuroImage 2002; 17: pp. 825-841.</p><li><p>41. Zhan Y., Shen D.: Deformable segmentation of 3D ultrasound prostate images using statistical texture matching method. IEEE Trans Med Imaging 2006; 25: pp. 256-272.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-14/'>Volume 14</a>, <a href='/categories/issue-11/'>Issue 11</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Registering%20Histologic%20and%20MR%20Images%20of%20Prostate%20for%20Image-based%20Cancer%20Detection%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fregistering-histologic-and-mr-images-of-prostate-for-image-based-cancer-detection%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Registering%20Histologic%20and%20MR%20Images%20of%20Prostate%20for%20Image-based%20Cancer%20Detection%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fregistering-histologic-and-mr-images-of-prostate-for-image-based-cancer-detection%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fregistering-histologic-and-mr-images-of-prostate-for-image-based-cancer-detection%2F&text=Registering%20Histologic%20and%20MR%20Images%20of%20Prostate%20for%20Image-based%20Cancer%20Detection%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/abstracts-of-funded-national-institutes-of-health-grants/"><div class="card-body"> <em class="small" data-ts="1193850000" data-df="ll" > Oct 31, 2007 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Abstracts of Funded National Institutes of Health Grants</h3><div class="text-muted small"><p> The following abstracts of diagnostic radiology research and training grants funded by the National Institutes of Health (NIH) were awarded to principal investigators (PIs) whose primary appointmen...</p></div></div></a></div><div class="card"> <a href="/posts/academic-technology-transfer-and-radiology/"><div class="card-body"> <em class="small" data-ts="1193850000" data-df="ll" > Oct 31, 2007 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Academic Technology Transfer and Radiology</h3><div class="text-muted small"><p> To date, technology transfer from academia to industry has been strongest in the biotechnology and pharmaceutical sector. The medical imaging and medical device industries have traditionally been s...</p></div></div></a></div><div class="card"> <a href="/posts/advances-in-radiologic-image-analysis-from-miccai-2006/"><div class="card-body"> <em class="small" data-ts="1193850000" data-df="ll" > Oct 31, 2007 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Advances in Radiologic Image Analysis From MICCAI 2006</h3><div class="text-muted small"><p> The 9th International Conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2006, was held in Copenhagen, Denmark, at the Tivoli Concert Hall with satellite workshops and...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/real-time-tracking-and-shape-analysis-of-atrial-septal-defects-in-3d-echocardiography/" class="btn btn-outline-primary" prompt="Older"><p>Real-Time Tracking and Shape Analysis of Atrial Septal Defects in 3D Echocardiography</p></a> <a href="/posts/resident-as-a-teacher/" class="btn btn-outline-primary" prompt="Newer"><p>Resident as a Teacher</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

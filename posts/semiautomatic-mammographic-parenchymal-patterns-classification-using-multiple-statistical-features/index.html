<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Semiautomatic Mammographic Parenchymal Patterns Classification Using Multiple Statistical Features" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/semiautomatic-mammographic-parenchymal-patterns-classification-using-multiple-statistical-features/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/semiautomatic-mammographic-parenchymal-patterns-classification-using-multiple-statistical-features/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2007-11-30T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Semiautomatic Mammographic Parenchymal Patterns Classification Using Multiple Statistical Features" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-07T07:15:32+00:00","datePublished":"2007-11-30T17:00:00+00:00","description":"Rationale and Objectives","headline":"Semiautomatic Mammographic Parenchymal Patterns Classification Using Multiple Statistical Features","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/semiautomatic-mammographic-parenchymal-patterns-classification-using-multiple-statistical-features/"},"url":"https://clinicaltree.github.io/posts/semiautomatic-mammographic-parenchymal-patterns-classification-using-multiple-statistical-features/"}</script><title>Semiautomatic Mammographic Parenchymal Patterns Classification Using Multiple Statistical Features | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Semiautomatic Mammographic Parenchymal Patterns Classification Using Multiple Statistical Features</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Semiautomatic Mammographic Parenchymal Patterns Classification Using Multiple Statistical Features</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1196442000" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Nov 30, 2007 </em> </span> <span> Updated <em class="" data-ts="1680851732" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 7, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Cyril Castella MSc</a> </em>, <em> <a href="">Karen Kinkel MD</a> </em>, <em> <a href="">Miguel P. Eckstein PhD</a> </em>, <em> <a href="">Pierre-Edouard Sottas PhD</a> </em>, <em> <a href="">Francis R. Verdun PhD</a> </em>, <em> <a href="">François O. Bochud PhD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4184 words"> <em>23 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Our project was to investigate a complete methodology for the semiautomatic assessment of digital mammograms according to their density, an indicator known to be correlated to breast cancer risk. The BI-RADS four-grade density scale is usually employed by radiologists for reporting breast density, but it allows for a certain degree of subjective input, and an objective qualification of density has therefore often been reported hard to assess. The goal of this study was to design an objective technique for determining breast BI-RADS density.</p><h2 id="materials-and-methods"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The proposed semiautomatic method makes use of complementary pattern recognition techniques to describe manually selected regions of interest (ROIs) in the breast with 36 statistical features. Three different classifiers based on a linear discriminant analysis or Bayesian theories were designed and tested on a database consisting of 1408 ROIs from 88 patients, using a leave-one-ROI-out technique. Classifications in optimal feature subspaces with lower dimensionality and reduction to a two-class problem were studied as well.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Comparison with a reference established by the classifications of three radiologists shows excellent performance of the classifiers, even though extremely dense breasts continue to remain more difficult to classify accurately. For the two best classifiers, the exact agreement percentages are 76% and above, and weighted κ values are 0.78 and 0.83. Furthermore, classification in lower dimensional spaces and two-class problems give excellent results.</p><h2 id="conclusion"><span class="mr-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The proposed semiautomatic classifiers method provides an objective and reproducible method for characterizing breast density, especially for the two-class case. It represents a simple and valuable tool that could be used in screening programs, training, education, or for optimizing image processing in diagnostic tasks.</p><p>While the etiology of breast cancer remains unclear, many studies have demonstrated a correlation between cancer risk and factors such as age, breastfeeding and pregnancy history, family history of breast cancer, hormonal treatments, genetic factors, and breast density ( ). Breast density as a factor of risk was first investigated by Wolfe ( ), who defined a four-grade density scale on the basis of the patterns and textures observed on mammograms. Later, the BI-RADS (Breast Imaging Reporting Data System) density scale was developed by the American College of Radiology to standardize mammography reporting terminology and assessment and recommendation categories ( ). The BI-RADS density classification was created to inform referring physicians about the decline in sensitivity of mammography with increasing breast density. BI-RADS defines breast density 1 as almost entirely fatty, density 2 as scattered fibroglandular tissue, density 3 as heterogeneously dense tissue and density 4 as extremely dense tissues. It was not intended to serve as a method of measuring breast density percentage, although as per Wolfe’s scale ( ), correlations with this more objective factor do exist ( ). In clinical American and European conditions, the breast density of a given patient is typically evaluated and reported by a radiologist using BI-RADS on the basis of the simultaneous display of two mammograms per breast.</p><p>However, one of the difficulties for correctly assessing breast density is that the BI-RADS density scale definitions are rather subjective. A certain interpretational freedom prevents perfect interobserver and even intraobserver reproducibility ( ). On the other hand, numerous pattern recognition and classification techniques have been developed and can be directly applied to this task ( ). This is why different statistical approaches have been explored in the last few years in order to develop an objective classifier of mammograms according to Wolfe or the BI-RADS scale. These techniques have made use of various pattern recognition parameters to statistically describe the whole breast or part of it: fractal dimension ( ), gray level histogram properties ( ), moments ( ), gray level variations matrices ( ), or maximum response filters ( ). These descriptions have been combined with several general classification algorithms: Bayesian classification ( ), linear discriminant analysis (LDA) ( ), nearest neighbor rules ( ), neural networks, and textons ( ).</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="materials-and-methods-1"><span class="mr-2">Materials and methods</span><a href="#materials-and-methods-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="mammogram-database"><span class="mr-2">Mammogram Database</span><a href="#mammogram-database" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="selection-of-regions-of-interest"><span class="mr-2">Selection of Regions of Interest</span><a href="#selection-of-regions-of-interest" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/SemiautomaticMammographicParenchymalPatternsClassificationUsingMultipleStatisticalFeatures/0_1s20S1076633207004059.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/SemiautomaticMammographicParenchymalPatternsClassificationUsingMultipleStatisticalFeatures/0_1s20S1076633207004059.jpg" alt="Figure 1, Digital mammogram and corresponding manually defined regions of interest." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="statistical-description"><span class="mr-2">Statistical Description</span><a href="#statistical-description" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 1</p><p>Summary of the Texture Analysis Methods and the Corresponding Features</p><p>Analysis Method Statistical Features Gray level histogram standard deviation skewness kurtosis balance Gray level co-occurrence matrices energy entropy cmax contrast homogeneity Primitives matrices short primitive emphasis long primitive emphasis gray level uniformity primitive length uniformity Fractal analysis fractal dimension Neighbourhood gray-tone difference matrix</p><ul><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul><p>The 18 parameters in this table were computed for two scales as described in the text, making a total of 36 features.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="definition-of-gold-standard-from-radiologists-ratings"><span class="mr-2">Definition of Gold Standard From Radiologists’ Ratings</span><a href="#definition-of-gold-standard-from-radiologists-ratings" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="classification-algorithms"><span class="mr-2">Classification Algorithms</span><a href="#classification-algorithms" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="classic-bayesian-classifier-based-on-mahalanobis-distance"><span class="mr-2">Classic Bayesian classifier based on Mahalanobis distance</span><a href="#classic-bayesian-classifier-based-on-mahalanobis-distance" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>ψk(v)=1(2π)NdetKk√⋅exp[−12(v−μk)TK−1k(v−μk)], ψ</p><p>k</p><p>(</p><p>v</p><p>)</p><p>=</p><p>1</p><p>(</p><p>2</p><p>π</p><p>)</p><p>N</p><p>det</p><p>⁡</p><p>K</p><p>k</p><p>⋅</p><p>exp</p><p>⁡</p><p>[</p><p>−</p><p>1</p><p>2</p><p>(</p><p>v</p><p>−</p><p>μ</p><p>k</p><p>)</p><p>T</p><p>K</p><p>k</p><p>−</p><p>1</p><p>(</p><p>v</p><p>−</p><p>μ</p><p>k</p><p>)</p><p>]</p><p>,</p><p>where μ k represents the mean vector of class <em>k</em> and K k is the covariance matrix of vectors in class <em>k</em> :</p><p>μk=1nk∑vi∈Skvi μ</p><p>k</p><p>=</p><p>1</p><p>n</p><p>k</p><p>∑</p><p>v</p><p>i</p><p>∈</p><p>S</p><p>k</p><p>v</p><p>i</p><p>Kk=1nk−1∑vi∈Sk(vi−μk)T(vi−μk) K</p><p>k</p><p>=</p><p>1</p><p>n</p><p>k</p><p>−</p><p>1</p><p>∑</p><p>v</p><p>i</p><p>∈</p><p>S</p><p>k</p><p>(</p><p>v</p><p>i</p><p>−</p><p>μ</p><p>k</p><p>)</p><p>T</p><p>(</p><p>v</p><p>i</p><p>−</p><p>μ</p><p>k</p><p>)</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>p(k∣∣v)=p(v|k)p(k)p(v)=ψk(v)pa(k)∑kψk(v)pa(k) p</p><p>(</p><p>k</p><p>|</p><p>v</p><p>)</p><p>=</p><p>p</p><p>(</p><p>v</p><p>|</p><p>k</p><p>)</p><p>p</p><p>(</p><p>k</p><p>)</p><p>p</p><p>(</p><p>v</p><p>)</p><p>=</p><p>ψ</p><p>k</p><p>(</p><p>v</p><p>)</p><p>p</p><p>a</p><p>(</p><p>k</p><p>)</p><p>∑</p><p>k</p><p>ψ</p><p>k</p><p>(</p><p>v</p><p>)</p><p>p</p><p>a</p><p>(</p><p>k</p><p>)</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>cR=∑4k=1k⋅p(k|v), c</p><p>R</p><p>=</p><p>∑</p><p>k</p><p>=</p><p>1</p><p>4</p><p>k</p><p>⋅</p><p>p</p><p>(</p><p>k</p><p>|</p><p>v</p><p>)</p><p>,</p><p>with c R being rounded to the nearest integer value to obtain the class attributed to the tested sample vector v.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>pa(k)=14, p</p><p>a</p><p>(</p><p>k</p><p>)</p><p>=</p><p>1</p><p>4</p><p>,</p><p>which represents the most conservative a priori assumption.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="naïve-bayesian-classifier"><span class="mr-2">Naïve Bayesian classifier</span><a href="#naïve-bayesian-classifier" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>ψk(vn,k)=1(2π)N√exp[−12vTn,kvn,k], ψ</p><p>k</p><p>(</p><p>v</p><p>n</p><p>,</p><p>k</p><p>)</p><p>=</p><p>1</p><p>(</p><p>2</p><p>π</p><p>)</p><p>N</p><p>exp</p><p>⁡</p><p>[</p><p>−</p><p>1</p><p>2</p><p>v</p><p>n</p><p>,</p><p>k</p><p>T</p><p>v</p><p>n</p><p>,</p><p>k</p><p>]</p><p>,</p><p>where v has been normalized in the same way as training samples of class <em>k</em> to obtain the normalized vector v <em>n,k</em> . The four a posteriori probabilities p( <em>k</em> |v) were then computed with Equation 4 , and the attributed class with Equation 5 .</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>12π√∫−∞pj,kne−t2/2dt=pj,kpj,kmax, 1</p><p>2</p><p>π</p><p>∫</p><p>−</p><p>∞</p><p>p</p><p>n</p><p>j</p><p>,</p><p>k</p><p>e</p><p>−</p><p>t</p><p>2</p><p>/</p><p>2</p><p>d</p><p>t</p><p>=</p><p>p</p><p>j</p><p>,</p><p>k</p><p>p</p><p>max</p><p>⁡</p><p>j</p><p>,</p><p>k</p><p>,</p><p>where <em>p j,k max</em> is the highest value in the original distribution of feature <em>j</em> in class <em>k</em> .</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="linear-discriminant-analysis"><span class="mr-2">Linear discriminant analysis</span><a href="#linear-discriminant-analysis" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>ψk(v)=1(2π)NdetKo√⋅exp[−12(v−μk)TK−1o(v−μk)] ψ</p><p>k</p><p>(</p><p>v</p><p>)</p><p>=</p><p>1</p><p>(</p><p>2</p><p>π</p><p>)</p><p>N</p><p>det</p><p>⁡</p><p>K</p><p>o</p><p>⋅</p><p>exp</p><p>⁡</p><p>[</p><p>−</p><p>1</p><p>2</p><p>(</p><p>v</p><p>−</p><p>μ</p><p>k</p><p>)</p><p>T</p><p>K</p><p>o</p><p>−</p><p>1</p><p>(</p><p>v</p><p>−</p><p>μ</p><p>k</p><p>)</p><p>]</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="averaging-the-individual-rois-classifications"><span class="mr-2">Averaging the individual ROIs classifications</span><a href="#averaging-the-individual-rois-classifications" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="reduction-of-the-features-space-size-and-number-of-classes"><span class="mr-2">Reduction of the features’ space size and number of classes</span><a href="#reduction-of-the-features-space-size-and-number-of-classes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="evaluation-of-the-performance"><span class="mr-2">Evaluation of the performance</span><a href="#evaluation-of-the-performance" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>κ=po−pe1−pe, κ</p><p>=</p><p>p</p><p>o</p><p>−</p><p>p</p><p>e</p><p>1</p><p>−</p><p>p</p><p>e</p><p>,</p><p>where <em>p o</em> is the observed agreement proportion and <em>p e</em> the agreement expected by chance alone. Both are calculated from the confusion matrix and the quadratic weights matrix, and the values of κ stand between −1 and 1 (the minimum value actually depends on <em>p e</em> but is always between −1 and 0). Benchmarks by Landis and Koch ( ) (adjusted by Fleiss et al. [41] for taking the weighting process into account) are commonly used: κ values below 0.4 reflect poor agreement, between 0.4 and 0.6 moderate agreement, while it is substantial between 0.6 and 0.75 and excellent above 0.75. Weighted κ is particularly well adapted to multiclass tasks and when the classes are rather subjectively defined, which is the case for the BI-RADS density scale. The weighting process indeed differentiates between serious (more than one BI-RADS class difference) and slight disagreement (immediate neighbor class choice), and has been chosen as an evaluation parameter in numerous previous works on mammogram classification ( ). Although much more sensitive to differences in class prevalence, the exact agreement proportion was also computed to be able to compare the performance with results from other studies ( ).</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 2</p><p>Radiologist Classifications Compared to the Gold Standard Classification Defined in Text</p><p>Radiologist # 1 Radiologist # 2 Radiologist # 3 Kappa 0.81 ± 0.07 0.88 ± 0.07 0.91 ± 0.08 Exact agreement 77% 89% 89%</p><p>Standard error for weighted κ was computed according to the formula given by Fleiss et al. ( ).</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/SemiautomaticMammographicParenchymalPatternsClassificationUsingMultipleStatisticalFeatures/1_1s20S1076633207004059.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/SemiautomaticMammographicParenchymalPatternsClassificationUsingMultipleStatisticalFeatures/1_1s20S1076633207004059.jpg" alt="Figure 2, Repartition of the 176 breast pairs among BI-RADS density classes. The separation line in the gold standard column indicates the proportion of cases per consensus level: 3/3 (lower part of the column) or 2/3 (upper part)." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 3</p><p>(a) Confusion Matrix Obtained for the Bayesian Classifier Based on Mahalanobis Distance. Results are Averaged Over Mammogram Pairs from the Same View. (b) Same for LDA Classifier</p><p>(a) Gold Standard Bayesian Classifier Density 1 Density 2 Density 3 Density 4 Density 1 14 3 0 0 Density 2 5 30 6 1 Density 3 0 14 86 3 Density 4 0 0 10 4</p><p>(b) Gold Standard LDA Classifier Density 1 Density 2 Density 3 Density 4 Density 1 16 3 0 0 Density 2 3 31 4 1 Density 3 0 13 95 3 Density 4 0 0 3 4</p><p>Table 4</p><p>Weighted κ Values Obtained with the Different Averaging Processes and Classifiers. Exact Agreement is Given in Parenthesis</p><p>Individual ROI Classification Average per Mammogram (4 ROIs) Average per View Type (8 ROIs) Naïve Bayesian 0.50 ± 0.02 (39%) 0.65 ± 0.05 (55%) 0.68 ± 0.07 (60%) Mahalanobis Bayesian 0.58 ± 0.03 (53%) 0.73 ± 0.05 (69%) 0.78 ± 0.07 (76%) LDA 0.71 ± 0.03 (70%) 0.81 ± 0.05 (80%) 0.83 ± 0.08 (83%)</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/SemiautomaticMammographicParenchymalPatternsClassificationUsingMultipleStatisticalFeatures/2_1s20S1076633207004059.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/SemiautomaticMammographicParenchymalPatternsClassificationUsingMultipleStatisticalFeatures/2_1s20S1076633207004059.jpg" alt="Figure 3, ( a ) Weighted κ value as a function of the features space dimensionality. Lines at 0.6 and 0.75 represent the limits for substantial and excellent agreement. ( b ) Corresponding percentage agreement." class="lazyload" data-proofer-ignore></a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/SemiautomaticMammographicParenchymalPatternsClassificationUsingMultipleStatisticalFeatures/3_1s20S1076633207004059.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/SemiautomaticMammographicParenchymalPatternsClassificationUsingMultipleStatisticalFeatures/3_1s20S1076633207004059.jpg" alt="Figure 4, Partition of the optimal bidimensional feature subspace. ( a ) LDA leads to linear borders. ( b ) For Bayesian classifier based on Mahalanobis distance, the borders are conics. For visibility reasons, only 40 to 50 randomly chosen ROIs per density class are shown." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">Discussion</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="conclusion-1"><span class="mr-2">Conclusion</span><a href="#conclusion-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="acknowledgments"><span class="mr-2">Acknowledgments</span><a href="#acknowledgments" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="appendix"><span class="mr-2">Appendix</span><a href="#appendix" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="definition-of-the-statistical-parameters"><span class="mr-2">Definition of the statistical parameters</span><a href="#definition-of-the-statistical-parameters" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="parameters-computed-from-the-gray-level-histogram"><span class="mr-2">Parameters Computed From the Gray Level Histogram</span><a href="#parameters-computed-from-the-gray-level-histogram" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>mean≡x¯=1N∑ixi mean</p><p>≡</p><p>x</p><p>¯</p><p>=</p><p>1</p><p>N</p><p>∑</p><p>i</p><p>x</p><p>i</p><p>standarddev.≡σ=1N−1√(∑i(xi−x¯)2)1/2 standard</p><p>dev</p><p>.</p><p>≡</p><p>σ</p><p>=</p><p>1</p><p>N</p><p>−</p><p>1</p><p>(</p><p>∑</p><p>i</p><p>(</p><p>x</p><p>i</p><p>−</p><p>x</p><p>¯</p><p>)</p><p>2</p><p>)</p><p>1</p><p>/</p><p>2</p><p>skewness=1Nσ3∑i(xi−x¯)3 skewness</p><p>=</p><p>1</p><p>N</p><p>σ</p><p>3</p><p>∑</p><p>i</p><p>(</p><p>x</p><p>i</p><p>−</p><p>x</p><p>¯</p><p>)</p><p>3</p><p>kurtosis=1Nσ4∑i(xi−x¯)4−3 kurtosis</p><p>=</p><p>1</p><p>N</p><p>σ</p><p>4</p><p>∑</p><p>i</p><p>(</p><p>x</p><p>i</p><p>−</p><p>x</p><p>¯</p><p>)</p><p>4</p><p>−</p><p>3</p><p>balance=x70−x¯x¯−x30, balance</p><p>=</p><p>x</p><p>70</p><p>−</p><p>x</p><p>¯</p><p>x</p><p>¯</p><p>−</p><p>x</p><p>30</p><p>,</p><p>where the summations are performed over the N pixels of the ROI, and <em>x p</em> is the gray level yielding to <em>p</em> th percentile of the gray level distribution ( ).</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="gray-level-co-occurrence-matrices-glcm"><span class="mr-2">Gray Level Co-occurrence Matrices (GLCM)</span><a href="#gray-level-co-occurrence-matrices-glcm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>energy(C)=∑i,jC2i,j energy</p><p>(</p><p>C</p><p>)</p><p>=</p><p>∑</p><p>i</p><p>,</p><p>j</p><p>C</p><p>i</p><p>,</p><p>j</p><p>2</p><p>entropy(C)=−∑i,jCi,jlogCi,j entropy</p><p>(</p><p>C</p><p>)</p><p>=</p><p>−</p><p>∑</p><p>i</p><p>,</p><p>j</p><p>C</p><p>i</p><p>,</p><p>j</p><p>log</p><p>⁡</p><p>C</p><p>i</p><p>,</p><p>j</p><p>cmax(C)=maxi,jCi,j c</p><p>max</p><p>(</p><p>C</p><p>)</p><p>=</p><p>max</p><p>⁡</p><p>i</p><p>,</p><p>j</p><p>C</p><p>i</p><p>,</p><p>j</p><p>contrast(C)=∑i,j|i−j|2Ci,j contrast</p><p>(</p><p>C</p><p>)</p><p>=</p><p>∑</p><p>i</p><p>,</p><p>j</p><p>|</p><p>i</p><p>−</p><p>j</p><p>|</p><p>2</p><p>C</p><p>i</p><p>,</p><p>j</p><p>homogeneity(C)=∑i,jCi,j1+|i−j| homogeneity</p><p>(</p><p>C</p><p>)</p><p>=</p><p>∑</p><p>i</p><p>,</p><p>j</p><p>C</p><p>i</p><p>,</p><p>j</p><p>1</p><p>+</p><p>|</p><p>i</p><p>−</p><p>j</p><p>|</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="primitives-matrix-pm"><span class="mr-2">Primitives Matrix (PM)</span><a href="#primitives-matrix-pm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>spe=1Btot∑a∑rBa,rr2 spe</p><p>=</p><p>1</p><p>B</p><p>t</p><p>o</p><p>t</p><p>∑</p><p>a</p><p>∑</p><p>r</p><p>B</p><p>a</p><p>,</p><p>r</p><p>r</p><p>2</p><p>lpe=1Btot∑a∑rBa,rr2 lpe</p><p>=</p><p>1</p><p>B</p><p>t</p><p>o</p><p>t</p><p>∑</p><p>a</p><p>∑</p><p>r</p><p>B</p><p>a</p><p>,</p><p>r</p><p>r</p><p>2</p><p>glu=1Btot∑a(∑rBa,r)2 glu</p><p>=</p><p>1</p><p>B</p><p>t</p><p>o</p><p>t</p><p>∑</p><p>a</p><p>(</p><p>∑</p><p>r</p><p>B</p><p>a</p><p>,</p><p>r</p><p>)</p><p>2</p><p>plu=1Btot∑r(∑aBa,r)2, plu</p><p>=</p><p>1</p><p>B</p><p>t</p><p>o</p><p>t</p><p>∑</p><p>r</p><p>(</p><p>∑</p><p>a</p><p>B</p><p>a</p><p>,</p><p>r</p><p>)</p><p>2</p><p>,</p><p>where <strong>B</strong><em>tot</em> is the sum of the elements of the primitives matrix <strong>B</strong> : Btot=∑a∑rBa,r. B</p><p>t</p><p>o</p><p>t</p><p>=</p><p>∑</p><p>a</p><p>∑</p><p>r</p><p>B</p><p>a</p><p>,</p><p>r</p><p>. Note that <strong>B</strong> could be defined for several directions, but we limited our investigations to one ( ), corresponding to a scan of the image along direction [1,0].</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="fractal-dimension"><span class="mr-2">Fractal Dimension</span><a href="#fractal-dimension" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>L(ε)=λε1−D L</p><p>(</p><p>ε</p><p>)</p><p>=</p><p>λ</p><p>ε</p><p>1</p><p>−</p><p>D</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>A(ε)=λε2−D A</p><p>(</p><p>ε</p><p>)</p><p>=</p><p>λ</p><p>ε</p><p>2</p><p>−</p><p>D</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="neighborhood-gray-tone-difference-matrix-ngtdm"><span class="mr-2">Neighborhood Gray-Tone Difference Matrix (NGTDM)</span><a href="#neighborhood-gray-tone-difference-matrix-ngtdm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>A¯¯¯xk,l=1W−1[∑dm=−d∑dn=−dxk+m,l+n],(m,n)≠(0,0), A</p><p>¯</p><p>x</p><p>k</p><p>,</p><p>l</p><p>=</p><p>1</p><p>W</p><p>−</p><p>1</p><p>[</p><p>∑</p><p>m</p><p>=</p><p>−</p><p>d</p><p>d</p><p>∑</p><p>n</p><p>=</p><p>−</p><p>d</p><p>d</p><p>x</p><p>k</p><p>+</p><p>m</p><p>,</p><p>l</p><p>+</p><p>n</p><p>]</p><p>,</p><p>(</p><p>m</p><p>,</p><p>n</p><p>)</p><p>≠</p><p>(</p><p>0</p><p>,</p><p>0</p><p>)</p><p>,</p><p>where d = 3 is the neighbouring size and W = (2d+1) 2 . Denoting { <em>X i</em> } the set of all pixels with value <em>i</em> in the ROI, the <em>i</em> th entry of the NGTDM is given by:</p><p>s(i)=∑x∈Xi∣∣i−A¯¯¯x∣∣ s</p><p>(</p><p>i</p><p>)</p><p>=</p><p>∑</p><p>x</p><p>∈</p><p>X</p><p>i</p><p>|</p><p>i</p><p>−</p><p>A</p><p>¯</p><p>x</p><p>|</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>coarseness=[ε+∑imaxi=0pis(i)]−1 c</p><p>o</p><p>a</p><p>r</p><p>s</p><p>e</p><p>n</p><p>e</p><p>s</p><p>s</p><p>=</p><p>[</p><p>ε</p><p>+</p><p>∑</p><p>i</p><p>=</p><p>0</p><p>i</p><p>max</p><p>⁡</p><p>p</p><p>i</p><p>s</p><p>(</p><p>i</p><p>)</p><p>]</p><p>−</p><p>1</p><p>contrast′=[1Ng(Ng−1)∑imaxi=0∑jmaxj=0pipj(i−j)2]⋅[1n2∑imaxi=0s(i)] contrast</p><p>′</p><p>=</p><p>[</p><p>1</p><p>N</p><p>g</p><p>(</p><p>N</p><p>g</p><p>−</p><p>1</p><p>)</p><p>∑</p><p>i</p><p>=</p><p>0</p><p>i</p><p>max</p><p>⁡</p><p>∑</p><p>j</p><p>=</p><p>0</p><p>j</p><p>max</p><p>⁡</p><p>p</p><p>i</p><p>p</p><p>j</p><p>(</p><p>i</p><p>−</p><p>j</p><p>)</p><p>2</p><p>]</p><p>·</p><p>[</p><p>1</p><p>n</p><p>2</p><p>∑</p><p>i</p><p>=</p><p>0</p><p>i</p><p>max</p><p>⁡</p><p>s</p><p>(</p><p>i</p><p>)</p><p>]</p><p>complexity=∑imaxi=0∑jmaxj=0|i−j|[pis(i)+pjs(j)]n2(pi+pj),pi&gt;0,pj&gt;0 complexity</p><p>=</p><p>∑</p><p>i</p><p>=</p><p>0</p><p>i</p><p>max</p><p>⁡</p><p>∑</p><p>j</p><p>=</p><p>0</p><p>j</p><p>max</p><p>⁡</p><p>|</p><p>i</p><p>−</p><p>j</p><p>|</p><p>[</p><p>p</p><p>i</p><p>s</p><p>(</p><p>i</p><p>)</p><p>+</p><p>p</p><p>j</p><p>s</p><p>(</p><p>j</p><p>)</p><p>]</p><p>n</p><p>2</p><p>(</p><p>p</p><p>i</p><p>+</p><p>p</p><p>j</p><p>)</p><p>,</p><p>p</p><p>i</p><blockquote></blockquote><p>0</p><p>,</p><p>p</p><p>j</p><blockquote></blockquote><p>0</p><p>strength=∑imaxi=0∑jmaxj=0(pi+pj)(i−j)2ε+∑imaxi=0s(i),pi&gt;0,pj&gt;0, strength</p><p>=</p><p>∑</p><p>i</p><p>=</p><p>0</p><p>i</p><p>max</p><p>⁡</p><p>∑</p><p>j</p><p>=</p><p>0</p><p>j</p><p>max</p><p>⁡</p><p>(</p><p>p</p><p>i</p><p>+</p><p>p</p><p>j</p><p>)</p><p>(</p><p>i</p><p>−</p><p>j</p><p>)</p><p>2</p><p>ε</p><p>+</p><p>∑</p><p>i</p><p>=</p><p>0</p><p>i</p><p>max</p><p>⁡</p><p>s</p><p>(</p><p>i</p><p>)</p><p>,</p><p>p</p><p>i</p><blockquote></blockquote><p>0</p><p>,</p><p>p</p><p>j</p><blockquote></blockquote><p>0</p><p>,</p><p>where pi=|Xi|/∑imaxi=0|Xi| p</p><p>i</p><p>=</p><p>|</p><p>X</p><p>i</p><p>|</p><p>/</p><p>∑</p><p>i</p><p>=</p><p>0</p><p>i</p><p>max</p><p>⁡</p><p>|</p><p>X</p><p>i</p><p>| is the probability of occurrence of gray level <em>i</em> in the ROI, <em>i</em> max the highest gray level and <em>N g</em> the number of different gray levels effectively present in the ROI and ε a small number (10 −12 in our case) to prevent coarseness and strength becoming infinite. The feature representing the contrast given by Equation 30 is called here <em>contrast′</em> , to make a distinction with the contrast derived from the primitives matrices (see Equation 19 ).</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Fitzgibbons P.L., Page D.L., Weaver D., et. al.: Prognostic factors in breast cancer. Arch Pathol Lab Med 2000; 124: pp. 966-978.</p><li><p>2. Ziv E., Smith-Bindman R., Kerlikowske K.: Mammographic breast density and family history of breast cancer. J Natl Cancer Inst 2003; 95: pp. 556-558.</p><li><p>3. Colditz G.A., Hankison S.E., Hunter D.J., et. al.: The use of estrogens and progestins and the risk of breast cancer in postmenopausal women. N Engl J Med 1995; 332: pp. 1589-1593.</p><li><p>4. Kelsey J.L., Gammon M.D., John E.M.: Reproductive factors and breast cancer. Epidemiol Rev 1993; 15: pp. 36-47.</p><li><p>5. Boyd N.F., Byng J.W., Long R.A., et. al.: Quantitative classification of mammographic densities and breast cancer risk: Results from the Canadian National Breast Screening study. J Natl Cancer Inst 1995; 87: pp. 670-675.</p><li><p>6. van Gils C.H., Hendriks J.H., Holland R., et. al.: Changes in mammographic breast density and concomitant changes in breast cancer risk. Eur J Cancer Prev 1999; 8: pp. 509-515.</p><li><p>7. Heine J.J., Malhotra P.: Mammographic tissue, breast cancer risk, serial image analysis, and digital mammography: Part 1. Acad Radiol 2001; 9: pp. 298-316.</p><li><p>8. Wolfe J.N.: Breast patterns as an index of risk for developing breast cancer. AJR Am J Roentgenol 1976; 126: pp. 1130-1137.</p><li><p>9. American College of Radiology (ACR) 2004: ACR Practice Guideline for the performance of screening mammography.2004.</p><li><p>10. Harvey J.A., Bovbjerg V.E.: Quantitative assessment of mammographic breast density: relationship with breast cancer risk. Radiology 2004; 230: pp. 29-41.</p><li><p>11. Brisson J., Diorio C., Mâsse B.: Wolfe’s parenchymal pattern and percentage of the breast with mammographic densities: Redundant or complementary classifications?. Cancer Epidemiol Biomark Prevent 2003; 12: pp. 728-732.</p><li><p>12. Perconti P., Loew M.: Analysis of parenchymal patterns using conspicuous spatial frequency features in mammograms applied to the BI-RADS density rating scheme.2006.</p><li><p>13. Kerlikowske K., Grady D., Barclay J., et. al.: Variability and accuracy in mammographic interpretation using the American College of Radiology Breast Imaging Reporting and Data System. J Natl Cancer Inst 1998; 90: pp. 1801-1809.</p><li><p>14. Berg W.A., Campassi C., Langenberg P., Sexton M.J.: Breast Imaging Reporting and Data System: Inter- and intraobserver variability in feature analysis and final assessment. AJR Am J Roentgenol 2000; 174: pp. 1769-1777.</p><li><p>15. Huo Z., Giger M.L., Wolverton D.E., Zhong W., Cumming S., Olopade O.I.: Computerized analysis of mammographic parenchymal patterns for breast cancer assessment: Feature selection. Med Phys 2000; 27: pp. 4-12.</p><li><p>16. Caldwell C.B., Stappelton S.J., Holdsworth D.W., et. al.: Characterisation of mammographic parenchymal pattern by fractal dimension. Phys Med Biol 1990; 35: pp. 235-247.</p><li><p>17. Byng J.W., Boyd N.F., Fishel E., Jong R.A., Yaffe M.J.: Automated analysis of mammographic densities. Phys Med Biol 1996; 41: pp. 909-923.</p><li><p>18. Bovis K., Singh S.: Classification of mammographic breast density using a combined classifier paradigm. Proceedings of the 4th International Workshop on Digital Mammography 2002; pp. 177-180.</p><li><p>19. Zhou C., Chan H.P., Petrick N., et. al.: Computerized image analysis: Estimation of breast density on mammograms. Med Phys 2001; 28: pp. 1056-1569.</p><li><p>20. Tahoces P.G., Correa J., Souto M., Gómez L., Vidal J.J.: Computer-aided diagnosis: The classification of mammographic breast parenchymal patterns. Phys Med Biol 1995; 40: pp. 103-117.</p><li><p>21. Karssemeijer N.: Automated classification of parenchymal patterns in mammograms. Phys Med Biol 1998; 43: pp. 365-378.</p><li><p>22. Petroudi S., Kadir T., Brady M.: Automatic classification of mammographic parenchymal patterns: A statistical approach. Proc IEEE Int Conf Eng Med Biol 2003; pp. 798-801.</p><li><p>23. Vedantham S., Karellas A., Suryanarayanan S., et. al.: Full breast digital mammography with an amorphous silicon-based flat panel detector: Physical characteristics of a clinical prototype. Med Phys 2000; 27: pp. 558-567.</p><li><p>24. Burgess A.: On the noise variance of a digital mammography system. Med Phys 2004; 31: pp. 1987-1995.</p><li><p>25. Muller S.: Full-field digital mammography designed as a complete system. Eur J Radiol 1999; 31: pp. 25-34.</p><li><p>26. Hemdal B., Andersson I., Grahn A., et. al.: Can the average glandular dose in routine digital mammography screening be reduced?. Radiat Protect Dosimetry 2005; 114: pp. 383-388.</p><li><p>27. Li H., Giger M.L., Olopade O.I., Margolis A., Lan L., Chinander M.R.: Computerized texture analysis of mammographic parenchymal patterns of digitized mammograms. Acad Radiol 2005; 12: pp. 863-873.</p><li><p>28. Sonka M., Hlavak V., Boyle R.: Image processing.2nd ed.1999.Brooks/ColePacific Grove, CA</p><li><p>29. Tuceryan M., Jain A.K.: Texture analysis.Chen C.H.Pau L.F.Wang P.The Handbook of Pattern Recognition and Computer Vision.1998.World Scientific PublishingRiver Edge, NJ:</p><li><p>30. Haralick R.M., Shanmugam K., Dinstein I.: Textural features for image classification. IEEE Trans Syst Manage Cybern 1973; 3: pp. 610-662.</p><li><p>31. Lundhal T., Ohley W.J., Kunklinski W.S., Williams D.O., Gewirtz H., Most A.S.: Analysis and interpolation of angiographic images by use of fractals. Proceedings of IEEE Conference on Computers in Cardiology 1985; pp. 355-358.</p><li><p>32. Amadasun M., King R.: Textural features corresponding to textural properties. IEEE Trans Syst Manage Cybern 1989; 19: pp. 1264-1274.</p><li><p>33. Fukunaga K.: Introduction to Statistical Pattern Recognition.2nd ed.1990.Academic PressSan Diego, CA</p><li><p>34. Chabat F., Guang-Zhong Y., Mansell D.M.: Obstructive lung diseases: Texture classification for differentiation at CT. Radiology 2003; 228: pp. 871-877.</p><li><p>35. Friedman N., Geiger D., Goldszmidt M.: Bayesian network classifier. Machine Learning 1997; 29: pp. 131-163.</p><li><p>36. Domingos P., Pazzani M.J.: On the optimality of the simple Bayesian classifier under zero-one loss. Machine Learning 1997; 29: pp. 103-130.</p><li><p>37. 2004.MathWorksNatick, MA</p><li><p>38. Nasri M., El Hitmy M.: Algorithme génétique et Critère de la Trace pour l’Optimisation du vecteur Attribut: Application à la Classification Supervisée des Images de Textures.2002.</p><li><p>39. Yeom S., Javidi B.: Three-dimensional distortion-tolerant object recognition using integral imaging. Optics Express 2004; 12: pp. 5795-5809.</p><li><p>40. Barrett H.H., Myers K.J.: Foundations of Image Science.2004.WileyHoboken, NJ</p><li><p>41. Fleiss J.L., Levin B., Paik M.C.: Statistical Rates and Proportions.3rd ed.2003.WileyHoboken, NJ</p><li><p>42. Ker M.: Issues in the use of kappa. Invest Radiol 1991; 26: pp. 78-83.</p><li><p>43. Kundel H.L.: Measurement of Observer Agreement. Radiology 2003; 228: pp. 303-308.</p><li><p>44. Kraemer H.C.: Extension of the kappa coefficient. Biometrics 1980; 36: pp. 207-216.</p><li><p>45. Kraemer H.C., Periyakoil V.S., Noda A.: Kappa coefficients in medical research.D’Agostino R.B.2004.WileyHoboken, NJ:</p><li><p>46. Landis J.R., Koch G.G.: The measurement of observer agreement for categorical data. Biometrics 1973; 33: pp. 671-679.</p><li><p>47. Petroudi S., Brady M.: Proceedings of the 8th International Workshop on Digital Mammography.Proceedings of the 8th International Workshop on Digital Mammography.2006.SpringerBerlin/Heidelberg:pp. 609-615.</p><li><p>48. Mandelbrot B.B.: The Fractal Geometry of Nature.1982.WH FreemanSan Francisco, CA</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-14/'>Volume 14</a>, <a href='/categories/issue-12/'>Issue 12</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Semiautomatic%20Mammographic%20Parenchymal%20Patterns%20Classification%20Using%20Multiple%20Statistical%20Features%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fsemiautomatic-mammographic-parenchymal-patterns-classification-using-multiple-statistical-features%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Semiautomatic%20Mammographic%20Parenchymal%20Patterns%20Classification%20Using%20Multiple%20Statistical%20Features%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fsemiautomatic-mammographic-parenchymal-patterns-classification-using-multiple-statistical-features%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fsemiautomatic-mammographic-parenchymal-patterns-classification-using-multiple-statistical-features%2F&text=Semiautomatic%20Mammographic%20Parenchymal%20Patterns%20Classification%20Using%20Multiple%20Statistical%20Features%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/abstracts-of-funded-national-institutes-of-health-grants-december/"><div class="card-body"> <em class="small" data-ts="1196442000" data-df="ll" > Nov 30, 2007 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Abstracts of Funded National Institutes of Health Grants (December)</h3><div class="text-muted small"><p></p></div></div></a></div><div class="card"> <a href="/posts/computer-aided-diagnosis-scheme-for-detection-of-lacunar-infarcts-on-mr-images/"><div class="card-body"> <em class="small" data-ts="1196442000" data-df="ll" > Nov 30, 2007 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Computer-Aided Diagnosis Scheme for Detection of Lacunar Infarcts on MR Images</h3><div class="text-muted small"><p> Rationale and Objectives The detection and management of asymptomatic lacunar infarcts on magnetic resonance (MR) images are important tasks for radiologists to ensure the prevention of severe cer...</p></div></div></a></div><div class="card"> <a href="/posts/congresses-conferences-meetings-and-seminars/"><div class="card-body"> <em class="small" data-ts="1196442000" data-df="ll" > Nov 30, 2007 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Congresses, Conferences, Meetings, and Seminars</h3><div class="text-muted small"><p> In the last couple of years, pedagogy has spawned a new phrase: virtual congresses . Several of these already are in operation with favorable responses. And several others are committed and in prod...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/phase-sensitive-inversion-recovery-single-shot-balanced-steady-state-free-precession-for-detection-o/" class="btn btn-outline-primary" prompt="Older"><p>Phase-Sensitive Inversion Recovery Single-Shot Balanced Steady-State Free Precession for Detection of Myocardial Infarction During a Single Breathhold</p></a> <a href="/posts/the-bookshelf/" class="btn btn-outline-primary" prompt="Newer"><p>The bookshelf</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

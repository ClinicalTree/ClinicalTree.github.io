<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Application of Threshol d-bias Independent Analysis to Eye-tracking and FROC Data" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/application-of-threshol-d-bias-independent-analysis-to-eye-tracking-and-froc-data/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/application-of-threshol-d-bias-independent-analysis-to-eye-tracking-and-froc-data/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2012-11-30T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Application of Threshol d-bias Independent Analysis to Eye-tracking and FROC Data" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-10T02:43:55+00:00","datePublished":"2012-11-30T17:00:00+00:00","description":"Rationale and Objectives","headline":"Application of Threshol d-bias Independent Analysis to Eye-tracking and FROC Data","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/application-of-threshol-d-bias-independent-analysis-to-eye-tracking-and-froc-data/"},"url":"https://clinicaltree.github.io/posts/application-of-threshol-d-bias-independent-analysis-to-eye-tracking-and-froc-data/"}</script><title>Application of Threshol d-bias Independent Analysis to Eye-tracking and FROC Data | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Application of Threshol d-bias Independent Analysis to Eye-tracking and FROC Data</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Application of Threshol d-bias Independent Analysis to Eye-tracking and FROC Data</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1354294800" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Nov 30, 2012 </em> </span> <span> Updated <em class="" data-ts="1681094635" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 10, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Dev P. Chakraborty PhD</a> </em>, <em> <a href="">Hong-Jun Yoon PhD</a> </em>, <em> <a href="">Claudia Mello-Thoms MS PhD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2602 words"> <em>14 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Studies of medical image interpretation have focused on either assessing radiologists’ performance using, for example, the receiver operating characteristic (ROC) paradigm, or assessing the interpretive process by analyzing their eye-tracking (ET) data. Analysis of ET data has not benefited from threshold-bias independent figures of merit (FOMs) analogous to the area under the receiver operating characteristic (ROC) curve. The aim was to demonstrate the feasibility of such FOMs and to measure the agreement between FOMs derived from free-response ROC (FROC) and ET data.</p><h2 id="methods"><span class="mr-2">Methods</span><a href="#methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Eight expert breast radiologists interpreted a case set of 120 two-view mammograms while eye-position data and FROC data were continuously collected during the interpretation interval. Regions that attract prolonged (&gt;800 ms) visual attention were considered to be virtual marks, and ratings based on the dwell and approach-rate (inverse of time-to-hit) were assigned to them. The virtual ratings were used to define threshold-bias independent FOMs in a manner analogous to the area under the trapezoidal alternative FROC (AFROC) curve (0 = worst, 1 = best). Agreement at the case level (0.5 = chance, 1 = perfect) was measured using the jackknife and 95% confidence intervals (CI) for the FOMs and agreement were estimated using the bootstrap.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The AFROC mark-ratings’ FOM was largest at 0.734 (CI 0.65–0.81) followed by the dwell at 0.460 (0.34–0.59) and then by the approach-rate FOM 0.336 (0.25–0.46). The differences between the FROC mark-ratings’ FOM and the perceptual FOMs were significant ( <em>P</em> &lt; .05). All pairwise agreements were significantly better then chance: ratings vs. dwell 0.707 (0.63–0.88), dwell vs. approach-rate 0.703 (0.60–0.79) and rating vs. approach-rate 0.606 (0.53–0.68). The ratings vs. approach-rate agreement was significantly smaller than the dwell vs. approach-rate agreement ( <em>P</em> = .008).</p><h2 id="conclusions"><span class="mr-2">Conclusions</span><a href="#conclusions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Leveraging current methods developed for analyzing observer performance data could complement current ways of analyzing ET data and lead to new insights.</p><h2 id="introduction"><span class="mr-2">Introduction</span><a href="#introduction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Observer performance measurements in radiology involve collecting ratings, usually one per image as in the receiver operating characteristic (ROC) paradigm , or one per perceived suspicious region as in the free-response receiver operating characteristic (FROC) paradigm . The rating, which could be an integer or continuous variable, represents a decision about how confident the observer is in the presence of abnormality in the image (for ROC) or at the location of the perceived suspicious region (for FROC). The analysis of observer performance data, to which Professor Charles E. Metz has made seminal contributions, uses a figure of merit (FOM), such as the area under the ROC curve (AUC), which rewards/penalizes correct/incorrect decisions in a manner commensurate with their ratings . For example, in the ROC paradigm, high-rated abnormal images and low-rated normal images are rewarded more than intermediate-rated images; and low-rated abnormal images and high-rated normal images are penalized more than intermediate-rated images. Likewise, a FROC FOM rewards high-rated lesions and unmarked normal images while penalizing high rated marks on normal images. In either paradigm, the FOM depends on reader skill and on the difficulty of the cases but is independent of threshold-bias inherent in an observer’s usage of the rating scale.</p><p>Threshold-bias can be thought of as how conservative or liberal the observer is in using the rating scale: a conservative observer tends to be more reluctant to give high ratings, whereas the liberal observer is less reluctant. Two observers may use the ratings scale quite differently, yet in ROC analysis they could yield identical AUCs. ROC analysis eliminates threshold-bias by measuring the differential ability of the ratings to correctly classify diseased and nondiseased images. Threshold-bias independence is an important advantage of ROC/FROC area-based FOMs over sensitivity-specificity analysis . As an example, consider the study conducted to evaluate the effectiveness of screening mammography by estimating the variability in radiologists’ ability to detect breast cancer. Fifty accredited mammography centers were randomly sampled from across the United States. One hundred eight radiologists from these centers gave blinded interpretation to the same set of 79 randomly selected screening mammograms. Ground truth for these women had been established either by biopsy or by 2-year follow-up. The observed range of sensitivity was at least 40% and the range of false positive fraction was at least 45%. The study shows that a large part of the variability in sensitivity and specificity is due to the radiologists’ variable thresholds for reporting disease. Once this is accounted for, the variability of the AUC measure, representing the intrinsic variability in diagnostic abilities of the mammographers, is only 11%.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="materials-and-methods"><span class="mr-2">Materials and methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="selection-of-observers-cases-and-ground-truth"><span class="mr-2">Selection of Observers, Cases, and Ground Truth</span><a href="#selection-of-observers-cases-and-ground-truth" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="froc-and-et-data-collection"><span class="mr-2">FROC and ET Data Collection</span><a href="#froc-and-et-data-collection" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ApplicationofThresholdbiasIndependentAnalysistoEyetrackingandFROCData/0_1s20S1076633212004643.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ApplicationofThresholdbiasIndependentAnalysistoEyetrackingandFROCData/0_1s20S1076633212004643.jpg" alt="Figure 1, Schematic of the data collection and processing to obtain real and virtual marks: the radiologists interpreted the images using a two-monitor workstation. Concurrently, and for the duration of the interpretation, an ASL eye-position tracking system determined the line-of-gaze. The ASL fixation and clustering algorithms are described in the text. The proximity criterion, defined as 2.5° of visual angle, is the maximum distance between a lesion center and a mark for the mark to be considered an LL (correct localization). Nonlesion localizations are all other marks. ASL, Applied Sciences Laboratory; NL, non-lesion localization; LL, lesion localization." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="study-protocol"><span class="mr-2">Study Protocol</span><a href="#study-protocol" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p>1. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>2. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>3. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="eye-position-data-clustering"><span class="mr-2">Eye-position Data Clustering</span><a href="#eye-position-data-clustering" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ApplicationofThresholdbiasIndependentAnalysistoEyetrackingandFROCData/1_1s20S1076633212004643.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ApplicationofThresholdbiasIndependentAnalysistoEyetrackingandFROCData/1_1s20S1076633212004643.jpg" alt="Figure 2, Example of (a) small clusters in yellow ; (b) big-clusters, before threshold, in green ; and (c) big clusters, after applying the 800 ms threshold, in blue . The green diamond symbol marks the location where search started, whereas the red cross symbol indicates the locations marked by the radiologist as containing a malignant lesion. The small yellow dots mark the raw eye-position data. The red circles mark the true locations of the lesions in the two views." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p>1. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>2. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="measures-of-visual-attention"><span class="mr-2">Measures of Visual Attention</span><a href="#measures-of-visual-attention" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p>1. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>2. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="generalized-ratings-fom-agreement-and-confidence-intervals"><span class="mr-2">Generalized Ratings, FOM, Agreement, and Confidence Intervals</span><a href="#generalized-ratings-fom-agreement-and-confidence-intervals" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 1</p><p>Summary of the Average Numbers of Physical FROC NL and LL Marks per Image and Virtual ET NL and LL Marks for Individual Readers Split between NOR and ABN Cases</p><p>Reader Physical FROC Marks Virtual ET Marks NL LL NL LL NOR ABN NOR ABN 1 0.607 0.305 0.831 3.557 2.695 0.864 2 1.098 1.034 0.695 5.852 4.898 0.695 3 0.574 0.881 0.627 4.738 5.475 0.797 4 0.541 0.797 0.678 3.475 2.831 0.831 5 2.311 3.237 0.814 6.230 7.000 0.831 6 0.770 1.017 0.780 2.328 2.814 0.627 7 1.082 1.017 0.678 2.820 2.831 0.593 8 0.230 0.542 0.627 0.672 0.797 0.644 Average 0.902 1.104 0.716 3.709 3.667 0.735</p><p>ABN, abnormal; ET, eye tracking; FROC, free-response receiver operating characteristic; LL, lesion localizations; NL, nonlesion localizations; NOR, normal.</p><p>On normal images only NL marks are possible but on abnormal images both NL and LL marks are possible. The final row lists the averages of the corresponding columns.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 2</p><p>Summary of the Average Ratings, Dwells, and Approach-rates per Image for the Individual Readers, Split between NOR and ABN Cases, and between NLs and LLs</p><p>Reader Rating R Dwell D (s) Approach-rate A (s −1 ) NL LL NL LL NL LL NOR ABN NOR ABN NOR ABN 1 1.649 2.833 2.918 2.131 2.109 4.701 0.684 0.725 0.907 2 1.851 2.164 3.073 3.524 3.481 5.334 0.488 0.525 1.186 3 1.657 2.212 3.324 2.338 2.463 4.210 0.581 0.414 1.106 4 1.242 2.085 3.275 2.435 3.230 6.699 0.675 0.470 1.270 5 1.291 2.199 3.104 3.464 3.799 8.251 0.541 0.394 1.054 6 3.277 3.933 4.130 2.617 2.863 5.626 0.697 0.581 0.903 7 1.742 3.100 3.600 3.499 3.331 3.638 0.780 0.894 0.835 8 1.500 2.625 3.459 2.464 3.569 6.193 0.894 0.870 1.664 Average 1.776 2.644 3.361 2.842 3.286 6.276 0.796 0.690 1.185</p><p>ABN, abnormal; ET, eye tracking; FROC, free-response receiver operating characteristic; LL, lesion localizations; NL, nonlesion localizations; NOR, normal.</p><p>The final row lists the averages of the corresponding columns.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 3</p><p>FOM Values</p><p>Reader Rating Dwell Approach-rateR R D D A A 1 0.806 0.577 0.263 2 0.632 0.221 0.220 3 0.723 0.433 0.303 4 0.753 0.551 0.408 5 0.703 0.445 0.249 6 0.795 0.498 0.364 7 0.692 0.280 0.244 8 0.764 0.678 0.635 Average (95% CI) 0.734 (0.65–0.81) 0.460 (0.34–0.59) 0.336 (0.25–0.46)</p><p>FOM, figure of merit; FROC, free-response receiver operating characteristic.</p><p>The ratings FOM was largest, followed by the dwell, and then by the approach rate. The differences between the FROC mark ratings FOM and the perceptual FOMs were significant ( <em>P</em> &lt; .05). The last row lists the average over all readers and the bootstrap 95% confidence interval.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 4</p><p>Agreements Values</p><p>Reader Rating vs. Dwell Dwell vs. Approach-rate Rating vs. Approach-rateΓRD Γ</p><p>R</p><p>D ΓDA Γ</p><p>D</p><p>A ΓRA Γ</p><p>R</p><p>A 1 0.808 0.583 0.592 2 0.550 0.683 0.533 3 0.683 0.675 0.592 4 0.817 0.692 0.608 5 0.617 0.558 0.542 6 0.708 0.733 0.608 7 0.675 0.717 0.575 8 0.800 0.983 0.800 Average (95% CI) 0.707 (0.63, 0.88) 0.703 (0.60, 0.79) 0.606 (0.53, 0.68)</p><p>All pairwise agreements were significantly better then chance. The ratings vs. approach-rate agreement was significantly smaller than the dwell vs. approach-rate agreement ( <em>P</em> = .008). The last row lists the average over all readers and the bootstrap 95% confidence interval (CI).</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">Discussion</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="conclusions-1"><span class="mr-2">Conclusions</span><a href="#conclusions-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="appendix-1"><span class="mr-2">Appendix 1</span><a href="#appendix-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="figures-of-merit-derived-from-froc-and-eye-tracking-data"><span class="mr-2">Figures of Merit Derived from FROC and Eye-tracking Data</span><a href="#figures-of-merit-derived-from-froc-and-eye-tracking-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="notation"><span class="mr-2">Notation</span><a href="#notation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="figures-of-merit"><span class="mr-2">Figures-of-merit</span><a href="#figures-of-merit" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>X,j=1NNNA∑NNk1=1∑NAk2=1ψ(maxl1(xjk11l11),maxl2(xjk22l22)) X</p><p>,</p><p>j</p><p>=</p><p>1</p><p>N</p><p>N</p><p>N</p><p>A</p><p>∑</p><p>k</p><p>1</p><p>=</p><p>1</p><p>N</p><p>N</p><p>∑</p><p>k</p><p>2</p><p>=</p><p>1</p><p>N</p><p>A</p><p>ψ</p><p>(</p><p>m</p><p>a</p><p>x</p><p>l</p><p>1</p><p>(</p><p>x</p><p>j</p><p>k</p><p>1</p><p>1</p><p>l</p><p>1</p><p>1</p><p>)</p><p>,</p><p>m</p><p>a</p><p>x</p><p>l</p><p>2</p><p>(</p><p>x</p><p>j</p><p>k</p><p>2</p><p>2</p><p>l</p><p>2</p><p>2</p><p>)</p><p>)</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="appendix-2"><span class="mr-2">Appendix 2</span><a href="#appendix-2" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="measuring-agreement-between-pairs-of-figures-of-merit"><span class="mr-2">Measuring Agreement between Pairs of Figures-of-merit</span><a href="#measuring-agreement-between-pairs-of-figures-of-merit" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>∗k=K−(K−1)(k) k</p><p>∗</p><p>=</p><p>K</p><p>−</p><p>(</p><p>K</p><p>−</p><p>1</p><p>)</p><p>(</p><p>k</p><p>)</p><p>Here K=NN+NA K</p><p>=</p><p>N</p><p>N</p><p>+</p><p>N</p><p>A is the total number of cases, is the figure of merit using all cases, (k) (</p><p>k</p><p>) is the figure of merit when case <em>k</em> is removed (jackknifed) from the analysis and <em>k</em> runs from 1 to <em>K</em> .</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Δ∗k=∗k−∗∙ Δ</p><p>k</p><p>∗</p><p>=</p><p>k</p><p>∗</p><p>−</p><p>•</p><p>∗</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>ΓXX’=∑Jj=1∑Kk=1ψ(0,Δ∗X,jkΔ∗X’,jk)JK Γ</p><p>X</p><p>X</p><p>’</p><p>=</p><p>∑</p><p>j</p><p>=</p><p>1</p><p>J</p><p>∑</p><p>k</p><p>=</p><p>1</p><p>K</p><p>ψ</p><p>(</p><p>0</p><p>,</p><p>Δ</p><p>X</p><p>,</p><p>j</p><p>k</p><p>∗</p><p>Δ</p><p>X</p><p>’</p><p>,</p><p>j</p><p>k</p><p>∗</p><p>)</p><p>J</p><p>K</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>ΓXX’,j=∑Kk=1ψ(0,Δ∗X,jkΔ∗X’,jk)K Γ</p><p>X</p><p>X</p><p>’</p><p>,</p><p>j</p><p>=</p><p>∑</p><p>k</p><p>=</p><p>1</p><p>K</p><p>ψ</p><p>(</p><p>0</p><p>,</p><p>Δ</p><p>X</p><p>,</p><p>j</p><p>k</p><p>∗</p><p>Δ</p><p>X</p><p>’</p><p>,</p><p>j</p><p>k</p><p>∗</p><p>)</p><p>K</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="confidence-intervals-for-figures-of-merit-and-agreement"><span class="mr-2">Confidence Intervals for Figures of Merit and Agreement</span><a href="#confidence-intervals-for-figures-of-merit-and-agreement" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Metz C.E.: Basic principles of ROC analysis. Semin Nucl Med 1978; 8: pp. 283-298.</p><li><p>2. Metz C.E.: ROC methodology in radiologic imaging. Investig Radiol 1986; 21: pp. 720-733.</p><li><p>3. Bunch P.C., Hamilton J.F., Sanderson G.K., et. al.: A free-response approach to the measurement and characterization of radiographic-observer performance. J Appl Photogr Eng 1978; 4: pp. 166-171.</p><li><p>4. Chakraborty D.P.: New developments in observer performance methodology in medical imaging. Semin Nucl Med 2011; 41: pp. 401-418.</p><li><p>5. Chakraborty D.P., Berbaum K.S.: Observer studies involving detection and localization: Modeling, analysis and validation. Med Phys 2004; 31: pp. 2313-2330.</p><li><p>6. Begg C.B.: Biases in the assessment of diagnostic tests. Stat Med 1987; 6: pp. 411-423.</p><li><p>7. Beam C.A., Layde P.M., Sullivan D.C.: Variability in the interpretation of screening mammograms by US radiologists. Findings from a national sample. Arch Intern Med 1996; 156: pp. 209-213.</p><li><p>8. Krupinski E.A., Nodine C.F.: Gaze duration predicts the locations of missed lesions in mammography.Gale A.G.Astley S.M.Dance D.R. et. al.Digital mammography: proceedings of the 2nd International Workshop on Digital Mammography.1994.Elsevier Science B.V.Amsterdam, The Netherlands:pp. 399-403.</p><li><p>9. Kundel H.L., Nodine C.F., Krupinski E.A.: Computer-displayed eye position as a visual aid to pulmonary nodule interpretation. Investig Radiol 1990; 25: pp. 890-896.</p><li><p>10. Nodine C., Mello-Thoms C., Kundel H., et. al.: Time course of perception and decision making during mammographic interpretation. AJR Am J Roentgenol 2002; 179: pp. 917-923.</p><li><p>11. Nodine C.F.: Recording and analyzing eye-position data using a microcomputer workstation. Behav Res Methods Instruments Computers 1992; 24: pp. 475-485.</p><li><p>12. Hillstrom A.: Repetition effects in visual search. Percept Psychophys 2000; 2: pp. 800-817.</p><li><p>13. Kundel H.L., Nodine C.F., Carmody D.: Visual scanning, pattern recognition and decision-making in pulmonary nodule detection. Invest Radiol 1978; 13: pp. 175-181.</p><li><p>14. Kundel H.L., Nodine C.F., Krupinski E.A., et. al.: Using gaze-tracking data and mixture distribution analysis to support a holistic model for the detection of cancers on mammograms. Acad Radiol 2008; 15: pp. 881-886.</p><li><p>15. Mello-Thoms C., Hardesty L.A., Sumkin J.H., et. al.: Effects of lesion conspicuity on visual search in mammogram reading. Acad Radiol 2005; 12: pp. 830-840.</p><li><p>16. Hanley J.A.: The robustness of the “binormal” assumptions used in fitting ROC curves. Med Decis Making 1988; 8: pp. 197-203.</p><li><p>17. Chakraborty D.P.: ROC Curves predicted by a model of visual search. Phys Med Biol 2006; 51: pp. 3463-3482.</p><li><p>18. Chakraborty D.P.: A search model and figure of merit for observer data acquired according to the free-response paradigm. Phys Med Biol 2006; 51: pp. 3449-3462.</p><li><p>19. Yoon H.J., Zheng B., Sahiner B., et. al.: Evaluating computer-aided detection algorithms. Med Phys 2007; 34: pp. 2024-2038.</p><li><p>20. Hanley J.A., Hajian-Tilaki K.O.: Sampling variability of nonparametric estimates of the areas under receiver operating characteristic curves: an update. Acad Radiol 1997; 4: pp. 49-58.</p><li><p>21. Chakraborty D.P., Hagood T.M., Ryan J., et. al.: Quantifying the clinical relevance of a laboratory observer performance paradigm. Br J Radiol 2012; 85: pp. 1287-1302.</p><li><p>22. Chakraborty D.P.: Measuring agreement between ratings interpretations and binary clinical interpretations of images: a simulation study of methods for quantifying the clinical relevance of an observer performance paradigm. Phys Med Biol 2012; 57: pp. 2873-2904.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-19/'>Volume 19</a>, <a href='/categories/issue-12/'>Issue 12</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Application%20of%20Threshol%20d-bias%20Independent%20Analysis%20to%20Eye-tracking%20and%20FROC%20Data%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fapplication-of-threshol-d-bias-independent-analysis-to-eye-tracking-and-froc-data%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Application%20of%20Threshol%20d-bias%20Independent%20Analysis%20to%20Eye-tracking%20and%20FROC%20Data%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fapplication-of-threshol-d-bias-independent-analysis-to-eye-tracking-and-froc-data%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fapplication-of-threshol-d-bias-independent-analysis-to-eye-tracking-and-froc-data%2F&text=Application%20of%20Threshol%20d-bias%20Independent%20Analysis%20to%20Eye-tracking%20and%20FROC%20Data%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/an-analytic-expression-for-the-binormal-partial-area-under-the-roc-curve/"><div class="card-body"> <em class="small" data-ts="1354294800" data-df="ll" > Nov 30, 2012 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>An Analytic Expression for the Binormal Partial Area under the ROC Curve</h3><div class="text-muted small"><p> Rationale and Objectives The partial area under the receiver operating characteristic (ROC) curve (pAUC) is a useful summary measure for diagnostic studies. Unlike most summary measures that are f...</p></div></div></a></div><div class="card"> <a href="/posts/applications-of-roc-analysis-in-medical-research/"><div class="card-body"> <em class="small" data-ts="1354294800" data-df="ll" > Nov 30, 2012 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Applications of ROC Analysis in Medical Research</h3><div class="text-muted small"><p> With the growing focus on comparative effectiveness research and personalized medicine, receiver-operating characteristic analysis can continue to play an important role in health care decision mak...</p></div></div></a></div><div class="card"> <a href="/posts/charles-e-metz-phd/"><div class="card-body"> <em class="small" data-ts="1354294800" data-df="ll" > Nov 30, 2012 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Charles E. Metz, PhD</h3><div class="text-muted small"><p> Charles Edgar Metz, professor of radiology and a member of the Committee on Medical Physics at the University of Chicago, died from pancreatic cancer on July 4 at his home in Burr Ridge. He was 69 ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/an-analytic-expression-for-the-binormal-partial-area-under-the-roc-curve/" class="btn btn-outline-primary" prompt="Older"><p>An Analytic Expression for the Binormal Partial Area under the ROC Curve</p></a> <a href="/posts/applications-of-roc-analysis-in-medical-research/" class="btn btn-outline-primary" prompt="Newer"><p>Applications of ROC Analysis in Medical Research</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

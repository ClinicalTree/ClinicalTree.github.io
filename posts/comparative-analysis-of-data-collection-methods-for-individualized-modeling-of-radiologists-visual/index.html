<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Comparative Analysis of Data Collection Methods for Individualized Modeling of Radiologists’ Visual Similarity Judgments in Mammograms" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/comparative-analysis-of-data-collection-methods-for-individualized-modeling-of-radiologists-visual/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/comparative-analysis-of-data-collection-methods-for-individualized-modeling-of-radiologists-visual/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2013-10-31T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Comparative Analysis of Data Collection Methods for Individualized Modeling of Radiologists’ Visual Similarity Judgments in Mammograms" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-10T02:43:55+00:00","datePublished":"2013-10-31T17:00:00+00:00","description":"Rationale and Objectives","headline":"Comparative Analysis of Data Collection Methods for Individualized Modeling of Radiologists’ Visual Similarity Judgments in Mammograms","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/comparative-analysis-of-data-collection-methods-for-individualized-modeling-of-radiologists-visual/"},"url":"https://clinicaltree.github.io/posts/comparative-analysis-of-data-collection-methods-for-individualized-modeling-of-radiologists-visual/"}</script><title>Comparative Analysis of Data Collection Methods for Individualized Modeling of Radiologists' Visual Similarity Judgments in Mammograms | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Comparative Analysis of Data Collection Methods for Individualized Modeling of Radiologists' Visual Similarity Judgments in Mammograms</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Comparative Analysis of Data Collection Methods for Individualized Modeling of Radiologists' Visual Similarity Judgments in Mammograms</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1383238800" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Oct 31, 2013 </em> </span> <span> Updated <em class="" data-ts="1681094635" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 10, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Georgia Tourassi PhD</a> </em>, <em> <a href="">Hong-Jun Yoon PhD</a> </em>, <em> <a href="">Songhua Xu PhD</a> </em>, <em> <a href="">Garnetta Morin-Ducote MD</a> </em>, <em> <a href="">Kathy Hudson MD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2250 words"> <em>12 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>We conducted an observer study to investigate how the data collection method affects the efficacy of modeling individual radiologists’ judgments regarding the perceptual similarity of breast masses on mammograms.</p><h2 id="materials-and-methods"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Six observers of varying experience levels in breast imaging were recruited to assess the perceptual similarity of mammographic masses. The observers’ subjective judgments were collected using (i) a rating method, (ii) a preference method, and (iii) a hybrid method combining rating and ranking. Personalized user models were developed with the collected data to predict observers’ opinions. The relative efficacy of each data collection method was assessed based on the classification accuracy of the resulting user models.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The average accuracy of the user models derived from data collected with the hybrid method was 55.5 ± 1.5%. The models were significantly more accurate ( <em>P</em> &lt; .0005) than those derived from the rating (45.3 ± 3.5%) and the preference (40.8 ± 5%) methods. On average, the rating data collection method was significantly faster than the other two methods ( <em>P</em> &lt; .0001). No time advantage was observed between the preference and the hybrid methods.</p><h2 id="conclusions"><span class="mr-2">Conclusions</span><a href="#conclusions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>A hybrid method combining rating and ranking is an intuitive and efficient way for collecting subjective similarity judgments to model human perceptual opinions with a higher accuracy than other, more commonly used data collection methods.</p><p>Collecting people’s opinions regarding the visual similarity of images is a critical building block for developing content-based image retrieval (CBIR) systems . In recent years, CBIR has been proposed in clinical imaging to enhance clinical decision support and training systems with visually similar cases retrieved from a reference image library, thus emulating the evidence-based clinical paradigm . The reliability of the developed CBIR technology is closely tied to image similarity metrics that correlate highly with human perceptual opinions. The development and validation of such metrics depend on the number and diversity of medical images presented to radiologists during the data collection process, which is a rather time-consuming step. Moreover, CBIR systems often disregard human perception subjectivity and embrace a generalized modeling approach to reproduce the consensus opinion of several radiologists. Relevance feedback techniques have been adopted in CBIR to capture human perception subjectivity by providing personalized fine-tuning of the image retrieval step. Still, this is work in progress in medical imaging .</p><p>The topic of perceptual subjectivity has been attracting attention in general and for radiological applications in particular with compounding evidence that the notion of visual similarity is highly subjective. Most studies use a rating-based data collection method wherein radiologists are asked to use a fixed rating scale (either continuous or discrete) to record their opinions regarding the similarity of image pairs. The rating method is well accepted in psychometric and user studies . Among its main limitations are user inconsistencies in applying a numerical scale across multiple cases and personal biases due to internal cognitive processes and individual personality traits, which often result in people using only part of the rating scale . To the best of our knowledge, there has been only one study in radiology reporting relatively good agreement between continuous scoring versus discrete scoring, but the participating radiologists were more consistent using discrete scoring rather than continuous scoring .</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="materials-and-methods-1"><span class="mr-2">Materials and methods</span><a href="#materials-and-methods-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="image-database"><span class="mr-2">Image Database</span><a href="#image-database" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComparativeAnalysisofDataCollectionMethodsforIndividualizedModelingofRadiologistsVisualSimilarityJudgmentsinMammograms/0_1s20S1076633213003486.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComparativeAnalysisofDataCollectionMethodsforIndividualizedModelingofRadiologistsVisualSimilarityJudgmentsinMammograms/0_1s20S1076633213003486.jpg" alt="Figure 1, The 40 masses selected for the study. The masses are shown in random order." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="data-collection-method"><span class="mr-2">Data Collection Method</span><a href="#data-collection-method" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="rating-method"><span class="mr-2">Rating method</span><a href="#rating-method" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComparativeAnalysisofDataCollectionMethodsforIndividualizedModelingofRadiologistsVisualSimilarityJudgmentsinMammograms/1_1s20S1076633213003486.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComparativeAnalysisofDataCollectionMethodsforIndividualizedModelingofRadiologistsVisualSimilarityJudgmentsinMammograms/1_1s20S1076633213003486.jpg" alt="Figure 2, Screenshot of the iPad GUI developed for the rating method. Zoomed-in viewing of a mass pair is allowed before the user reports his opinion by scrolling the scoring bar. After a user makes an initial score, he can also review the zoomed-in viewing and adjust the score." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="preference-method"><span class="mr-2">Preference method</span><a href="#preference-method" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComparativeAnalysisofDataCollectionMethodsforIndividualizedModelingofRadiologistsVisualSimilarityJudgmentsinMammograms/2_1s20S1076633213003486.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComparativeAnalysisofDataCollectionMethodsforIndividualizedModelingofRadiologistsVisualSimilarityJudgmentsinMammograms/2_1s20S1076633213003486.jpg" alt="Figure 3, Screenshot of the iPad GUI developed for the preference method. Zoomed-in viewing of a mass pair is allowed before and after the user reports his opinion by selecting one of the four options." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="hybrid-method"><span class="mr-2">Hybrid method</span><a href="#hybrid-method" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComparativeAnalysisofDataCollectionMethodsforIndividualizedModelingofRadiologistsVisualSimilarityJudgmentsinMammograms/3_1s20S1076633213003486.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComparativeAnalysisofDataCollectionMethodsforIndividualizedModelingofRadiologistsVisualSimilarityJudgmentsinMammograms/3_1s20S1076633213003486.jpg" alt="Figure 4, Screenshot of the iPad GUI developed for the hybrid method. For scoring, the user must tap on the radial line connecting the query/central mass and a periphery mass. The line connection changes color to emphasize the mass pair that the user is expected to evaluate. By tapping on a peripheral mass, the user may have zoomed-in viewing of the specific mass pair (i.e., the central and the selected peripheral mass)." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="observer-study"><span class="mr-2">Observer Study</span><a href="#observer-study" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="user-modeling"><span class="mr-2">User Modeling</span><a href="#user-modeling" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="performance-evaluation"><span class="mr-2">Performance Evaluation</span><a href="#performance-evaluation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 1</p><p>Time Requirements Per Data Collection Protocol</p><p>Data Collection Method Data Collection Time Expert 1 Expert 2 Resident 1 Resident 2 Resident 3 Resident 4 Rating Total (min) 13.3 ± 0.7 12.9 ± 1.8 8.0 ± 0.4 7.4 ± 0.6 7.0 ± 0.4 7.9 ± 0.6 Per case (sec) 8.0 ± 4.1 7.8 ± 10.3 4.8 ± 2.4 4.4 ± 3.5 4.2 ± 2.2 4.8 ± 3.4 Preference Total (min) 15.4 ± 1.0 14.0 ± 1.1 15.4 ± 0.8 8.0 ± 0.4 11.1 ± 0.7 9.7 ± 0.5 Per case (sec) 9.2 ± 5.8 8.4 ± 7.1 9.2 ± 5.4 4.8 ± 2.4 6.7 ± 4.0 5.8 ± 3.3 Hybrid Total (min) ∗ 13.3 ± 1.5 8.3 ± 0.5 9.4 ± 0.5 13.6 ± 1.2 16.8 ± 1.0 Per case (sec) 41.2 ± 11.4 40.0 ± 22.3 24.9 ± 7.2 28.2 ± 7.2 40.7 ± 16.4 50.4 ± 12.8</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 2</p><p>Classification Accuracy of Individualized User Models Predicting Observers’ Preference Opinions from Data Collected with the Three Methods Respectively</p><p>Observer Rating Method Preference Method Hybrid Method Expert 1 42.5 ± 1.8% (random forest) 32 ± 4.6% (bagging) 54 ± 3.4% (random forest) Expert 2 45.1 ± 1.8% (random forest) 47 ± 5.0% (SVM) 58 ± 3.5% (bagging) Resident 1 44.7 ± 1.9% (bagging) 41 ± 4.7% (Adaboost) 55 ± 3.6% (SVM) Resident 2 43.7 ± 1.9% (random forest) 41 ± 4.9% (random forest) 56 ± 3.8% (random forest) Resident 3 52.2 ± 1.9% (random forest) 40 ± 4.2% (PART) 54 ± 3.3% (random forest) Resident 4 43.7 ± 1.9% (rotation forest) 44 ± 5.2% (Bayesian net) 56 ± 3.4% (bagging)</p><p>Accuracy percentage is reported for the best performing classifiers (listed in parentheses). SMV, Support Vector Machine.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 3</p><p>Classification Accuracy of Individualized User Models Derived with the Same Amount of Data for all Three Data Collection Methods</p><p>Observer Rating Method Preference Method Hybrid Method Expert 1 34.6 ± 4.7% 32 ± 4.6% 45.8 ± 5.0% Expert 2 34.8 ± 4.8% 47 ± 5.0% 48.7 ± 4.9% Resident 1 36.0 ± 4.8% 41 ± 4.7% 46.4 ± 4.9% Resident 2 36.3 ± 4.7% 41 ± 4.9% 53.5 ± 4.9% Resident 3 38.0 ± 4.8% 40 ± 4.2% 48.0 ± 5.0% Resident 4 35.2 ± 4.7% 44 ± 5.2% 52.7 ± 4.9%</p><p>Accuracy percentage is reported for the best performing classifiers.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">Discussion</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="acknowledgment"><span class="mr-2">Acknowledgment</span><a href="#acknowledgment" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Tourassi G.D.: Current status of computerized decision support systems in mammography.Silverman B.G.Jain A.Ichalkaranje A. et. al.Intelligent paradigms for healthcare enterprises (studies in fuzziness and soft computing).2005.Springer-VerlagBerlin, Germany:pp. 173-208.</p><li><p>2. Tourassi G.D.: Computer-assisted radiology. In: Wiley encyclopedia of biomedical engineering.2006.Wiley &amp; SonsHoboken, NJ</p><li><p>3. Müller H., Michoux N., Bandon D., et. al.: A review of content-based image retrieval systems in medical applications-clinical benefits and future directions. Int J Med Inform 2004; 73: pp. 1-23.</p><li><p>4. Müller H., Rosset A., Garcia A., et. al.: Informatics in radiology (INFORAD): benefits of content-based visual data access in radiology. Radiographics 2005; 25: pp. 849-858.</p><li><p>5. Rocchio J.: Relevance feedback in information retrieval.Salton G.The smart retrieval system: experiments in automatic document processing.1971.Prentice-HallEnglewood Cliffs, NJ:pp. 313-323.</p><li><p>6. Salton G., Buckley C.: Improving retrieval performance by relevance feedback. J Am Soc Inform Sci 1990; 41: pp. 288-297.</p><li><p>7. Wu K., Yap K.H.: Content-based image retrieval using fuzzy perceptual feedback. Multimed Tools Appl 2007; 32: pp. 235-251.</p><li><p>8. Tourassi G.D., Floyd C.E.: Computer-assisted diagnosis of mammographic masses using an information-theoretic image retrieval scheme with BIRADS-based relevance feedback. SPIE Medical Imaging 2004; 5370: pp. 810-816.</p><li><p>9. de Azevedo-Marques P.M., Rosa N.A., Traina A.J.M., et. al.: Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge. Int J Comput Assist Radiol Surg 2008; 3: pp. 123-130.</p><li><p>10. Oh J.H., Yang Y., El Naqa I.: Adaptive learning for relevance feedback: application to digital mammography. Med Phys 2010; 37: pp. 4432-4444.</p><li><p>11. Cho H.C., Hadjiiski L., Sahiner B., et. al.: Interactive content-based image retrieval (CBIR) computer-aided diagnosis (CADx) system for ultrasound breast masses using relevance feedback. SPIE Med Imaging 2012; 8315: pp. 831509-1-831509-7.</p><li><p>12. Sanchez D., Chamorro-Martinez J., Vila M.A.: Modeling subjectivity in visual perception of orientation for image retrieval. Inform Process Manag 2003; 39: pp. 251-266.</p><li><p>13. Zhang R., Zhang Z.: Addressing CBIR efficiency, effectiveness, and retrieval subjectivity simultaneously.Proceedings of the 5th ACM SIGMM International Workshop on Multimedia Information Retrieval.2003.ACM PressNew York City, New York:pp. 71-78.</p><li><p>14. Wu K., Yap K.A.: Perceptual subjectivity notion in interactive content-based image retrieval systems.Tan Y.P.Yap K.H.Wang L.Intelligent multimedia processing with soft computing.2005.SpringerBerlin/Heidelberg, Germany:pp. 55-73.</p><li><p>15. Mazurowski M.A., Harrawood B.P., Zurada J.M., et. al.: Toward perceptually driven image retrieval in mammography: a pilot observer study to assess visual similarity of masses. SPIE Med Imaging 2008; 6917: pp. 69170I.</p><li><p>16. Sahiner B., Hadjiiski L.M., Chan H.P., et. al.: Inter- and intra-observer variability in radiologists’ assessment of mass similarity on mammograms. SPIE Med Imaging 2009; 7263: pp. 726315.</p><li><p>17. Muramatsu C., Li Q., Schmidt R., et. al.: Experimental determination of subjective similarity for pairs of clustered microcalcifications on mammograms: observer study results. Med Phys 2006; 33: pp. 3460-3468.</p><li><p>18. Hadjiiski L., Cho H.C., Chan H.P., et. al.: Inter-and intra-observer variability of radiologists evaluating CBIR systems.Maidment A.D.A.Bakic P.R.Gavenonis S.Breast imaging.2012.SpringerBerlin/Heidelberg, Germany:pp. 482-489.</p><li><p>19. Muramatsu C., Li Q., Schmidt R., et. al.: Investigation of psychophysical measure for evaluation of similar images for mammographic masses: preliminary results. Med Phys 2005; 32: pp. 2295-2304.</p><li><p>20. Muramatsu C., Li Q., Schmidt R., et. al.: Determination of similarity measures for pairs of mass lesions on mammograms by use of BI-RADS lesion descriptors and image features. Acad Radiol 2009; 16: pp. 443-449.</p><li><p>21. Muramatsu C., Nishimura K., Endo T., et. al.: Representation of lesion similarity by use of multidimensional scaling for breast masses on mammograms. J Digit Imaging 2013; pp. 1-8.</p><li><p>22. Cho H.C., Hadjiiski L., Sahiner B., et. al.: Similarity evaluation in a content-based image retrieval (CBIR) CADx system for characterization of breast masses on ultrasound images. Med Phys 2011; 38: pp. 1820-1831.</p><li><p>23. Stevens S.S.: On the theory of scales of measurement. Science 1946; 103: pp. 677-680.</p><li><p>24. Chan J.C.: Response-order effects in Likert-type scales. Educ Psychol Meas 1991; 51: pp. 531-540.</p><li><p>25. Miller M.D., Linn R.L., Gronlund N.E.: Measurement and assessment in teaching.2009.Merrill/PearsonUpper Saddle River, NJ</p><li><p>26. Viswanathan M.: Measurement of individual differences in preference for numerical information. J Appl Psychol 1993; 78: pp. 741-752.</p><li><p>27. Nishikawa R.M., Yang Y., Huo D., et. al.: Observers’ ability to judge the similarity of clustered calcifications on mammograms. SPIE Med Imaging 2004; 5372: pp. 192-198.</p><li><p>28. Tognetti S, Garbarino M, Bonarini A, et al. Modeling enjoyment preference from physiological responses in a car racing game. IEEE Conference on Computational Intelligence and Games 2010; 321–328.</p><li><p>29. Yannakakis G.N., Hallam J., Lund H.H.: Entertainment capture through heart rate activity in physical interactive playgrounds. User Model User-Adap. Special Issue: Affective Modeling and Adaptation 2008; 18: pp. 207-243.</p><li><p>30. Yannakakis G.N.: Preference learning for affective modeling. Proceedings of the Int Conf on Affective Computing and Intelligent Interaction 2009; pp. 126-131.</p><li><p>31. Xu S., Hudson K., Bradley Y., et. al.: Predictive modeling of human perception subjectivity: feasibility study of mammographic lesion similarity. SPIE 2012; 8318: 83180M-83180M-9</p><li><p>32. Kumazawa S., Muramatsu C., Li Q., et. al.: An investigation of radiologists’ perception of lesion similarity: observations with paired breast masses on mammograms and paired lung nodules on CT images. Acad Radiol 2008; 15: pp. 887-894.</p><li><p>33. Muramatsu C., Li Q., Schmidt R.A., et. al.: Determination of subjective similarity for pairs of masses and pairs of clustered micro-calcifications on mammograms: comparison of similarity ranking scores and absolute similarity ratings. Med Phys 2007; 34: pp. 2890-2895.</p><li><p>34. Heath M., Bowyer K., Kopans D., et. al.: Current status of the Digital Database for Screening Mammography.Digital mammography.1998.Kluwer Academic Publishers Available at: http://marathon.csee.usf.edu/Mammography/Database.html5</p><li><p>35. Stone D., Jarrett C., Woodroffe M., et. al.: User interface design and evaluation.2005.Morgan KaufmannLondon, UK</p><li><p>36. Gonzalez R.C., Woods R.E., Eddins S.L.: Digital image processing using MATLAB.2004.Prentice HallUpper Saddle River, NJ</p><li><p>37. Haralick R.M., Shanmugam K., Dinstein I.: Textural features for image classification. IEEE T Syst Man Cyb 1973; Smc-3: pp. 610-621.</p><li><p>38. Haralick R.M., Shapiro L.G.: Computer and robot vision.1991.Addison-WesleyBoston, MA</p><li><p>39. Hall M., Frank E., Holmes G., et. al.: The WEKA data mining software: an update. ACM SIGKDD Explorations Newsletter 2009; 11: pp. 10-18.</p><li><p>40. Bouckaert RR, Frank E, Hal M, et al. WEKA manual for version 3-7-8, 2013. Available at: http://www.cs.waikato.ac.nz/ml/weka/documentation.html . Accessed July 21, 2013.</p><li><p>41. Long L.R., Antani S., Deserno T.M., et. al.: Content-based image retrieval in medicine: retrospective assessment, state of the art, and future directions. Int J Healthc Inf Syst Inform 2009; 4: pp. 1-16.</p><li><p>42. Azevedo-Marques P.M.D., Rangayyan R.M.: Content-based retrieval of medical images: landmarking, indexing, and relevance feedback. Synth Lect Biomed Eng 2013; 8: pp. 1-143.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-20/'>Volume 20</a>, <a href='/categories/issue-11/'>Issue 11</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Comparative%20Analysis%20of%20Data%20Collection%20Methods%20for%20Individualized%20Modeling%20of%20Radiologists'%20Visual%20Similarity%20Judgments%20in%20Mammograms%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fcomparative-analysis-of-data-collection-methods-for-individualized-modeling-of-radiologists-visual%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Comparative%20Analysis%20of%20Data%20Collection%20Methods%20for%20Individualized%20Modeling%20of%20Radiologists'%20Visual%20Similarity%20Judgments%20in%20Mammograms%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fcomparative-analysis-of-data-collection-methods-for-individualized-modeling-of-radiologists-visual%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fcomparative-analysis-of-data-collection-methods-for-individualized-modeling-of-radiologists-visual%2F&text=Comparative%20Analysis%20of%20Data%20Collection%20Methods%20for%20Individualized%20Modeling%20of%20Radiologists'%20Visual%20Similarity%20Judgments%20in%20Mammograms%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/accuracy-of-axillary-lymph-node-staging-in-breast-cancer-patients/"><div class="card-body"> <em class="small" data-ts="1383238800" data-df="ll" > Oct 31, 2013 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Accuracy of Axillary Lymph Node Staging in Breast Cancer Patients</h3><div class="text-muted small"><p> Purpose To compare magnetic resonance imaging (MRI) and ultrasound (US) for axillary lymph node (LN) staging in breast cancer patients in an observer-performance study. Materials and Methods An ...</p></div></div></a></div><div class="card"> <a href="/posts/accurate-detection-of-metabolically-active-brown-and-white-adipose-tissues-with-computed-tomogra/"><div class="card-body"> <em class="small" data-ts="1383238800" data-df="ll" > Oct 31, 2013 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Accurate Detection of Metabolically Active “Brown” and “White” Adipose Tissues with Computed Tomography</h3><div class="text-muted small"><p> Background Adipose tissues (AT) are highly metabolically active complex endocrine organs and are classified into white (WAT) and brown AT (BAT) with proinflammatory and anti-inflammatory character...</p></div></div></a></div><div class="card"> <a href="/posts/analysis-of-dominant-factors-affecting-fatigue-caused-by-soft-copy-reading/"><div class="card-body"> <em class="small" data-ts="1383238800" data-df="ll" > Oct 31, 2013 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Analysis of Dominant Factors Affecting Fatigue Caused by Soft-Copy Reading</h3><div class="text-muted small"><p> Rationale and Objectives The aim of this study was to analyze the dominant factors affecting fatigue caused by soft-copy reading to identify a method for decreasing fatigue in clinical practice. ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/chest-imaging-case-atlas/" class="btn btn-outline-primary" prompt="Older"><p>Chest Imaging Case Atlas</p></a> <a href="/posts/comparison-of-chest-dual-energy-subtraction-digital-tomosynthesis-and-dual-energy-subtraction-radiog/" class="btn btn-outline-primary" prompt="Newer"><p>Comparison of Chest Dual-energy Subtraction Digital Tomosynthesis and Dual-energy Subtraction Radiography for Detection of Pulmonary Nodules</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

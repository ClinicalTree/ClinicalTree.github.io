<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Using Gaze-tracking Data and Mixture Distribution Analysis to Support a Holistic Model for the Detection of Cancers on Mammograms" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/using-gaze-tracking-data-and-mixture-distribution-analysis-to-support-a-holistic-model-for-the-detec/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/using-gaze-tracking-data-and-mixture-distribution-analysis-to-support-a-holistic-model-for-the-detec/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2008-06-30T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Using Gaze-tracking Data and Mixture Distribution Analysis to Support a Holistic Model for the Detection of Cancers on Mammograms" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-07T07:15:32+00:00","datePublished":"2008-06-30T17:00:00+00:00","description":"Rationale and Objectives","headline":"Using Gaze-tracking Data and Mixture Distribution Analysis to Support a Holistic Model for the Detection of Cancers on Mammograms","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/using-gaze-tracking-data-and-mixture-distribution-analysis-to-support-a-holistic-model-for-the-detec/"},"url":"https://clinicaltree.github.io/posts/using-gaze-tracking-data-and-mixture-distribution-analysis-to-support-a-holistic-model-for-the-detec/"}</script><title>Using Gaze-tracking Data and Mixture Distribution Analysis to Support a Holistic Model for the Detection of Cancers on Mammograms | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Using Gaze-tracking Data and Mixture Distribution Analysis to Support a Holistic Model for the Detection of Cancers on Mammograms</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Using Gaze-tracking Data and Mixture Distribution Analysis to Support a Holistic Model for the Detection of Cancers on Mammograms</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1214845200" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jun 30, 2008 </em> </span> <span> Updated <em class="" data-ts="1680851732" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 7, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Harold L. Kundel MD</a> </em>, <em> <a href="">Calvin F. Nodine PhD</a> </em>, <em> <a href="">Elizabeth A. Krupinski PhD</a> </em>, <em> <a href="">Claudia Mello-Thoms MSEE PhD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1885 words"> <em>10 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Use data collected independently at three institutions to compare time to first fixate the true lesion in searching for cancers on mammograms. Examine the fit of the results to a holistic model of visual perception.</p><h2 id="materials-and-methods"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The time required to first fixate a cancer on a mammogram was extracted from 400 eye-tracking records collected independently from three institutions. The time was used as an indicator of the initial perception of cancer. The distribution of first fixation times was partitioned into two normally distributed components using mixture distribution analysis. The true-positive fraction of each component was calculated.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>About 57% of the cancers had a 95% chance of being fixated in the first second of viewing. The remainder took longer (range, 1.0 to 15.2 seconds). The true-positive fraction was larger for the lesions hit immediately for most of the readers (TPF = 0.63 vs. 0.52, F = 5.88, <em>P</em> = .02) in 68% (13/19) of the readers.</p><h2 id="conclusions"><span class="mr-2">Conclusions</span><a href="#conclusions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The initial detection occurs before visual scanning and, therefore, must be the result of a parallel “global” analysis of the image resulting in an initial holistic, gestalt-like perception. The development of expertise in medical image analysis may consist of a shift in the recognition mechanism from scan-look-detect to look-detect-scan.</p><p>A previous gaze-tracking study of mammographers, mammography fellows, and radiology residents searching mammograms for cancer showed that more than half of the cancers fixated by the observers were visually inspected within 1.1 seconds of the onset of viewing ( ). This result was attributed to a global response that synthesizes a complete perception and identifies perturbations in the image. The gaze is then directed to the perturbations, and local features are analyzed using input from the high-resolution central vision performing, what we term “checking fixations.” After a covert task-based decision is made about the nature of a perturbation (eg, is it a cancer or not), the eyes are either moved to another location based on information from the global response or begin a more general discovery scanning of the image. Discovery scanning can be cognitively determined. For example, a scan path can be geometric when the target abnormality is very small and seemingly randomly positioned like microcalcifications on a mammogram or it can be anatomic when the target is a rib fracture. During discovery scanning, there is continued input from the peripheral retina and the scan path can be interrupted by checking fixations. Additionally, perturbations that are considered to be target locations are revisited resulting in increased dwell time ( ) on locations that will be reported as positive and scored as either true or false positive. After discovery and checking is completed, overt decisions are made. As a result of the complicated search process, the decision time is usually longer than the discovery time and the total scan path can be very complicated and difficult to analyze.</p><p>The emphasis on global response as opposed to serial scanning with local feature analysis is the reason that this model for scene perception is characterized as gestalt-like or holistic. The controversy over the perceptual relationships between objects and their component features has a long history in psychology and philosophy that has been reviewed by Kimchi ( ). Search models were largely based on studies of response time ( ), but doubt was cast on the validity of the models by the development of practical methods for recording eye position during the performance of search tasks ( ).</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="materials-and-methods-1"><span class="mr-2">Materials and methods</span><a href="#materials-and-methods-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="the-three-eye-position-datasets"><span class="mr-2">The Three Eye Position Datasets</span><a href="#the-three-eye-position-datasets" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="site-a"><span class="mr-2">Site A</span><a href="#site-a" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="site-b"><span class="mr-2">Site B</span><a href="#site-b" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="site-c"><span class="mr-2">Site C</span><a href="#site-c" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 1</p><p>The Composition of the Datasets Used in the Study</p><p>Performance Site A B C Total cancer cases in test set 20 9 30 Mammogram views CC <em>and</em> MLO CC <em>or</em> MLO CC <em>and</em> MLO Reader prompted to report Malignant only Benign and malignant Malignant only Readers 9 6 4 Available eye-position records 300 54 89 Total first fixation times used in the analysis 259 53 88</p><p>CC, craniocaudal; MLO, mediolateral oblique.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/UsingGazetrackingDataandMixtureDistributionAnalysistoSupportaHolisticModelfortheDetectionofCancersonMammograms/0_1s20S1076633208000858.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/UsingGazetrackingDataandMixtureDistributionAnalysistoSupportaHolisticModelfortheDetectionofCancersonMammograms/0_1s20S1076633208000858.jpg" alt="Figure 1, The histogram of the time to first hit a cancer data from site A and the two theoretical distributions calculated by the mixture distribution analysis." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>e−(y−μ1)22σ21p12π√σ1+e−(y−μ2)22σ22p22π√σ2. e</p><p>-</p><p>(</p><p>y</p><p>-</p><p>μ</p><p>1</p><p>)</p><p>2</p><p>2</p><p>σ</p><p>1</p><p>2</p><p>p</p><p>1</p><p>2</p><p>π</p><p>σ</p><p>1</p><p>+</p><p>e</p><p>-</p><p>(</p><p>y</p><p>-</p><p>μ</p><p>2</p><p>)</p><p>2</p><p>2</p><p>σ</p><p>2</p><p>2</p><p>p</p><p>2</p><p>2</p><p>π</p><p>σ</p><p>2</p><p>.</p><p>The expectation maximization algorithm is used to find optimal values for the parameters (μ, σ, and p) of each component ( ). Starting values for each component distribution were estimated using the k-means clustering algorithm. The maximum number of iterations of the expectation maximization algorithm was set at 1,000, although each dataset converged in less than 200 iterations. The confidence intervals of the proportions were estimated using a bootstrap technique.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>PctFx=CancersFirstFixatedTotalCancersinTestSet×100. P</p><p>c</p><p>t</p><p>F</p><p>x</p><p>=</p><p>C</p><p>a</p><p>n</p><p>c</p><p>e</p><p>r</p><p>s</p><p>F</p><p>i</p><p>r</p><p>s</p><p>t</p><p>F</p><p>i</p><p>x</p><p>a</p><p>t</p><p>e</p><p>d</p><p>T</p><p>o</p><p>t</p><p>a</p><p>l</p><p>C</p><p>a</p><p>n</p><p>c</p><p>e</p><p>r</p><p>s</p><p>i</p><p>n</p><p>T</p><p>e</p><p>s</p><p>t</p><p>S</p><p>e</p><p>t</p><p>×</p><p>100</p><p>.</p><p>The true-positive percentage (PctTP) in each component was calculated for each reader as</p><p>PctTPirs=TPirsTPirs+FNirs×100 P</p><p>c</p><p>t</p><p>T</p><p>P</p><p>i</p><p>r</p><p>s</p><p>=</p><p>T</p><p>P</p><p>i</p><p>r</p><p>s</p><p>T</p><p>P</p><p>i</p><p>r</p><p>s</p><p>+</p><p>F</p><p>N</p><p>i</p><p>r</p><p>s</p><p>×</p><p>100</p><p>where <em>i</em> is the component number (1 or 2) assigned to the trial by Emmix, <em>r</em> is the reader, and <em>s</em> is the site. The PctTP for each site was analyzed for readers and components using an analysis of variance.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 2</p><p>The Results of the Mixture Distribution Analysis on the Time Required to First Fixate a Cancer</p><p>Fast Component 1 Slow Component 2 Site_n_ Mean time (95% CI) Proportion (95% CI) Mean time (95% CI) Proportion (95% CI) A 259 0.71 (0.65–0.76) 0.57 (0.50–0.65) 4.36 (3.81–4.90) 0.42 (0.35–0.50) B 53 0.62 (0.54–0.69) 0.64 (0.33–0.89) 1.44 (1.15–1.73) 0.36 (0.10–0.67) C 88 0.75 (0.62–0.88) 0.42 (0.26–0.54) 5.46 (4.73–6.18) 0.57 (0.46–0.74) All 400 0.72 (0.69–0.77) 0.57 (0.51–0.63) 4.75 (4.48–5.02) 0.42 (0.37–0.49)</p><p>CI, confidence interval.</p><p>The times are given in seconds.</p><p>Table 3</p><p>The Percentage of All Cancers First Fixated (PctFx) and the Percent of True Positives (PctTP) in Each Component Given as the Mean and 95% Confidence Intervals for the Readers at Each Performance Site and for All of the Readers Combined</p><p>Fast Component Slow Component Site Readers PctFx PctTP PctFx PctTP A 9 62 (60–63) 68 (63–74) 38 (37–40) 39 (34–44) B 6 67 (61–73) 68 (65–71) 33 (27–39) 63 (52–73) C 4 46 (38–56) 44 (32–56) 54 (44–64) 65 (62–68) All 19 60 (58–62) 63 (61–65) 40 (38–42) 52 (49–55)</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">Discussion</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Kundel H.L., Nodine C.F., Conant E.F., et. al.: Holistic component of image perception in mammogram interpretation: Gaze-tracking study. Radiology 2007; 242: pp. 396-402.</p><li><p>2. Krupinski E.A., Nodine C.F., Kundel H.L.: Enhancing recognition of lesions in radiographic images using perceptual feedback. Opt Engineer 1998; 37: pp. 813-818.</p><li><p>3. Kimchi R.: Relative dominance of holistic and component properties in the perceptual organization of visual objects.Peterson M.A.Rhodes G.Perception of faces, objects, and scenes: analytic and holistic processes.2003.Oxford University PressOxford:pp. 235-268.</p><li><p>4. Luce R.D.: Response times: their role in inferring elementary mental organization.1986.Oxford University PressNew York</p><li><p>5. Wolfe J.M.: What can 1 million trials tell us about visual search?. Psychol Sci 1998; 9: pp. 33-39.</p><li><p>6. Kundel H.L., Nodine C.F., Carmody D.P.: Visual scanning, pattern recognition, and decision making in pulmonary nodule detection. Invest Radiol 1978; 13: pp. 175-181.</p><li><p>7. Llewellyn-Thomas E.: Search behavior.Tuddenham W.J.Radiol Clin N Am.1969.WB SaundersPhiladelphia:pp. 403-417.</p><li><p>8. Chase W., Simon H.: Perception in chess. Cog Psych 1973; 4: pp. 55-81.</p><li><p>9. Kundel H.L., Nodine C.F.: Interpreting chest radiographs without visual search. Radiology 1975; 116: pp. 527-532.</p><li><p>10. Swensson R.G.: A two-stage detection model applied to skilled visual search by radiologists. Perception Psychophys 1980; 27: pp. 11-16.</p><li><p>11. Oestmann J.W., Greene R., Kushner D.C., et. al.: Lung lesions: correlation between viewing time and detection. Radiology 1988; 166: pp. 451-453.</p><li><p>12. Hu C.H., Kundel H.L., Nodine C.F., et. al.: Searching for bone fractures: a comparison with pulmonary nodule search. Acad Radiol 1994; 1: pp. 25-32.</p><li><p>13. Williams L.G.: Studies of extrafoveal discrimination and detection.Visual search.1973.National Academy of SciencesWashington, DC:pp. 77-92.</p><li><p>14. Nodine C.F., Kundel H.L., Toto L.C., et. al.: Recording and analyzing eye-position data using a microcomputer workstation. Beh Res Meth Inst Comp 1992; 24: pp. 475-485.</p><li><p>15. Krupinski E.A.: Visual search of mammographic images: influence of lesion subtlety. Acad Radiol 2005; 12: pp. 965-969.</p><li><p>16. Mello-Thoms C., Hardesty L., Sumkin J., et. al.: Effects of lesion conspicuity on visual search in mammogram reading. Acad Radiol 2005; 12: pp. 830-840.</p><li><p>17. Wolfram Research, Inc: Mathematica, Version 5.1.2004. Champaign, IL</p><li><p>18. The University of Queensland, Australia: EMMIX. http:// www.maths.uq.edu.au Accessed June 1, 2006</p><li><p>19. McLachlan G., Peel D.: Finite mixture models.2000.John Wiley &amp; Sons, IncNew York</p><li><p>20. Yarbus A.L.: Eye movements and vision.1967.Plenum PressNew York</p><li><p>21. McConkie G.W., Underwood N.R., Zola D., et. al.: Some temporal characteristics of processing during reading. J Exp Psychol Hum Perc Perform 1985; 11: pp. 168-182.</p><li><p>22. Wallis G., Bulthoff H.: Learning to recognize objects. Trends Cog Sci 1999; 3: pp. 22-31.</p><li><p>23. Peterson M.A., Rhodes G.: Perception of faces, objects and scenes.2003.Oxford University PressOxford</p><li><p>24. Navon D.: Forest before trees: the precedence of global features in visual perception. Cog Psych 1977; 9: pp. 353-383.</p><li><p>25. Myles-Worsley M., Johnston W.A., Simons M.A.: The influence of expertise on X-ray image processing. J Exp Psychol Learn Mem Cogn 1988; 14: pp. 553-557.</p><li><p>26. Schyns P.D., Gosselin F.: Diagnostic use of scale information for componential and holistic recognition.Peterson M.A.Rhodes G.Perception of faces, objects and scenes.2003.Oxford University PressOxford:pp. 120-145.</p><li><p>27. Wood B.P.: Visual expertise. Radiology 1999; 211: pp. 1-3.</p><li><p>28. Sowden P.T., Davies I.R.L., Roling P.: Perceptual learning of the detection of features in X-ray image: a functional role for improvements in adults’ visual sensitivity?. J Exp Psychol Human Percept Performance 2000; 26: pp. 379-390.</p><li><p>29. Charness N., Krampe R., Mayr U.: The role of practice and coaching in entrepreneurial skill domains: an international comparison of life-span chess skill acquisition.Ericsson K.A.The road to excellence.1996.Lawrence Erlbaum AssociatesMahwah NJ:pp. 51-80.</p><li><p>30. Smith-Bindman R., Chu P., Miglioretti D.L., et. al.: Physician predictors of mammographic accuracy. J Nat Cancer Ins 2005; 97: pp. 358-367.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-15/'>Volume 15</a>, <a href='/categories/issue-7/'>Issue 7</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Using%20Gaze-tracking%20Data%20and%20Mixture%20Distribution%20Analysis%20to%20Support%20a%20Holistic%20Model%20for%20the%20Detection%20of%20Cancers%20on%20Mammograms%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fusing-gaze-tracking-data-and-mixture-distribution-analysis-to-support-a-holistic-model-for-the-detec%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Using%20Gaze-tracking%20Data%20and%20Mixture%20Distribution%20Analysis%20to%20Support%20a%20Holistic%20Model%20for%20the%20Detection%20of%20Cancers%20on%20Mammograms%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fusing-gaze-tracking-data-and-mixture-distribution-analysis-to-support-a-holistic-model-for-the-detec%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fusing-gaze-tracking-data-and-mixture-distribution-analysis-to-support-a-holistic-model-for-the-detec%2F&text=Using%20Gaze-tracking%20Data%20and%20Mixture%20Distribution%20Analysis%20to%20Support%20a%20Holistic%20Model%20for%20the%20Detection%20of%20Cancers%20on%20Mammograms%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/abstracts-of-funded-national-institutes-of-health-grants/"><div class="card-body"> <em class="small" data-ts="1214845200" data-df="ll" > Jun 30, 2008 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Abstracts of Funded National Institutes of Health Grants</h3><div class="text-muted small"><p> The following abstracts of diagnostic radiology research and training grants funded by the National Institutes of Health (NIH) were awarded to principal investigators (PIs) whose primary appointmen...</p></div></div></a></div><div class="card"> <a href="/posts/an-investigation-of-radiologists-perception-of-lesion-similarity/"><div class="card-body"> <em class="small" data-ts="1214845200" data-df="ll" > Jun 30, 2008 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>An Investigation of Radiologists' Perception of Lesion Similarity</h3><div class="text-muted small"><p> Rationale and Objectives We conducted an observer study to investigate whether radiologists can judge similarities in pairs of breast masses and lung nodules consistently and reproducibly. Materi...</p></div></div></a></div><div class="card"> <a href="/posts/computer-aided-diagnosis-for-the-differentiation-of-malignant-from-benign-thyroid-nodules-on-ultraso/"><div class="card-body"> <em class="small" data-ts="1214845200" data-df="ll" > Jun 30, 2008 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Computer-Aided Diagnosis for the Differentiation of Malignant from Benign Thyroid Nodules on Ultrasonography</h3><div class="text-muted small"><p> Rationale and Objectives We sought to evaluate the diagnostic performance of an artificial neural network (ANN) and binary logistic regression (BLR) in differentiating malignant from benign thyroi...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/use-of-radiologic-imaging-to-enhance-physical-diagnosis-in-struction-in-the-preclinical-curriculum/" class="btn btn-outline-primary" prompt="Older"><p>Use of Radiologic Imaging to Enhance Physical Diagnosis In struction in the Preclinical Curriculum</p></a> <a href="/posts/what-factors-affect-the-discrepancy-rate-between-preliminary-resident-interpretations-of-neuroimagin/" class="btn btn-outline-primary" prompt="Newer"><p>What Factors Affect the Discrepancy Rate Between Preliminary Resident Interpretations of Neuroimaging Studies and the Final Attending Interpretation?</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Using Convolutional Neural Networks for Enhanced Capture of Breast Parenchymal Complexity Patterns Associated with Breast Cancer Risk" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/using-convolutional-neural-networks-for-enhanced-capture-of-breast-parenchymal-complexity-patterns-a/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/using-convolutional-neural-networks-for-enhanced-capture-of-breast-parenchymal-complexity-patterns-a/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2018-07-31T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Using Convolutional Neural Networks for Enhanced Capture of Breast Parenchymal Complexity Patterns Associated with Breast Cancer Risk" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-10T03:59:08+00:00","datePublished":"2018-07-31T17:00:00+00:00","description":"Rationale and Objectives","headline":"Using Convolutional Neural Networks for Enhanced Capture of Breast Parenchymal Complexity Patterns Associated with Breast Cancer Risk","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/using-convolutional-neural-networks-for-enhanced-capture-of-breast-parenchymal-complexity-patterns-a/"},"url":"https://clinicaltree.github.io/posts/using-convolutional-neural-networks-for-enhanced-capture-of-breast-parenchymal-complexity-patterns-a/"}</script><title>Using Convolutional Neural Networks for Enhanced Capture of Breast Parenchymal Complexity Patterns Associated with Breast Cancer Risk | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Using Convolutional Neural Networks for Enhanced Capture of Breast Parenchymal Complexity Patterns Associated with Breast Cancer Risk</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Using Convolutional Neural Networks for Enhanced Capture of Breast Parenchymal Complexity Patterns Associated with Breast Cancer Risk</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1533056400" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jul 31, 2018 </em> </span> <span> Updated <em class="" data-ts="1681099148" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 10, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Aimilia Gastounioti PhD</a> </em>, <em> <a href="">Andrew Oustimov MPH</a> </em>, <em> <a href="">Meng-Kang Hsieh MS</a> </em>, <em> <a href="">Lauren Pantalone BS</a> </em>, <em> <a href="">Emily F. Conant MD</a> </em>, <em> <a href="">Despina Kontos PhD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2340 words"> <em>13 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>We evaluate utilizing convolutional neural networks (CNNs) to optimally fuse parenchymal complexity measurements generated by texture analysis into discriminative meta-features relevant for breast cancer risk prediction.</p><h2 id="materials-and-methods"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>With Institutional Review Board approval and Health Insurance Portability and Accountability Act compliance, we retrospectively analyzed “For Processing” contralateral digital mammograms (GE Healthcare 2000D/DS) from 106 women with unilateral invasive breast cancer and 318 age-matched controls. We coupled established texture features (histogram, co-occurrence, run-length, structural), extracted using a previously validated lattice-based strategy, with a multichannel CNN into a hybrid framework in which a multitude of texture feature maps are reduced to meta-features predicting the case or control status. We evaluated the framework in a randomized split-sample setting, using the area under the curve (AUC) of the receiver operating characteristic (ROC) to assess case-control discriminatory capacity. We also compared the framework to CNNs directly fed with mammographic images, as well as to conventional texture analysis, where texture feature maps are summarized via simple statistical measures that are then used as inputs to a logistic regression model.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Strong case-control discriminatory capacity was demonstrated on the basis of the meta-features generated by the hybrid framework (AUC = 0.90), outperforming both CNNs applied directly to raw image data (AUC = 0.63, <em>P</em> &lt; .05) and conventional texture analysis (AUC = 0.79, <em>P</em> &lt; .05).</p><h2 id="conclusions"><span class="mr-2">Conclusions</span><a href="#conclusions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Our results suggest that informative interactions between patterns exist in texture feature maps derived from mammographic images, which can be extracted and summarized via a multichannel CNN architecture toward leveraging the associations of textural measurements to breast cancer risk.</p><h2 id="introduction"><span class="mr-2">Introduction</span><a href="#introduction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The stratification of breast cancer risk levels is becoming increasingly important and is rapidly evolving beyond the “one-size-fits-all” approach in breast cancer screening to personalized regimens tailored by individual risk profiling . Starting from the pioneering work of Wolfe , studies have consistently shown an association of the breast parenchymal complexity (ie, the distribution of fatty and dense tissues) on breast images with levels of breast cancer risk. In particular, full-field digital mammography (FFDM), which is routinely used for breast cancer screening , has demonstrated substantial potential in providing novel quantitative imaging biomarkers related to breast cancer risk. Mammographic density is one of the strongest risk factors for breast cancer , while studies increasingly support significant associations of breast cancer risk with mammographic texture descriptors , which reflect more refined, localized characteristics of the breast parenchymal pattern.</p><p>In early studies investigating the role of mammographic texture in breast cancer risk assessment , textural measurements have been estimated within a single region of interest (ROI) in the breast. In an attempt to provide more granular texture estimates, more recent studies have proposed sampling the parenchymal tissue through the entire breast for subsequent texture analysis . For instance, in a recently proposed lattice-based strategy , each texture descriptor is calculated within multiple nonoverlapping local square ROIs through the breast, and texture measurements are then averaged over the breast regions sampled by the lattice. In a preliminary case-control evaluation , the lattice-based texture features were shown to outperform state-of-the-art features extracted from the retroareolar or central breast region, thereby suggesting that enhanced capture of the heterogeneity in the parenchymal texture within the breast may also improve the associations of texture measures with breast cancer risk. However, by averaging regional texture values, important information about the overall parenchymal tissue complexity might be still missed and, therefore, an improved fusion approach, which retains richer information about texture variability over the breast, might leverage the potential of such granular texture measurements provided by multiple ROIs.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="materials-and-methods-1"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="study-dataset"><span class="mr-2">Study Dataset</span><a href="#study-dataset" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="image-acquisition"><span class="mr-2">Image Acquisition</span><a href="#image-acquisition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="revealing-meta-features-of-breast-parenchymal-complexity"><span class="mr-2">Revealing Meta-features of Breast Parenchymal Complexity</span><a href="#revealing-meta-features-of-breast-parenchymal-complexity" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/UsingConvolutionalNeuralNetworksforEnhancedCaptureofBreastParenchymalComplexityPatternsAssociatedwithBreastCancerRisk/0_1s20S1076633218300072.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/UsingConvolutionalNeuralNetworksforEnhancedCaptureofBreastParenchymalComplexityPatternsAssociatedwithBreastCancerRisk/0_1s20S1076633218300072.jpg" alt="Figure 1, Hybrid framework workflow: Employing multichannel convolutional neural networks to fuse texture feature maps into case-control discriminative meta-features." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>TABLE 1</p><p>Parenchymal Texture Feature Maps (TFMs) Extracted From Each Digital Mammogram of the Study Dataset</p><p>Gray-level histogram TFM1 5th Percentile TFM2 5th Mean TFM3 95th Percentile TFM4 95th Mean TFM5 Entropy TFM6 Kurtosis TFM7 Max TFM8 Mean TFM9 Min TFM10 Sigma TFM11 Skewness TFM12 Sum Co-occurrence TFM13 Contrast TFM14 Correlation TFM15 Homogeneity TFM16 Energy TFM17 Entropy TFM18 Inverse difference moment TFM19 Cluster shade Run-length TFM20 Short-run emphasis TFM21 Long-run emphasis TFM22 Gray-level nonuniformity TFM23 Run-length nonuniformity TFM24 Run percentage TFM25 Low gray-level run emphasis TFM26 High gray-level run emphasis Structural TFM27 Edge-enhancing index TFM28 Box-counting fractal dimension TFM29 Local binary pattern</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="comparative-evaluation"><span class="mr-2">Comparative Evaluation</span><a href="#comparative-evaluation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/UsingConvolutionalNeuralNetworksforEnhancedCaptureofBreastParenchymalComplexityPatternsAssociatedwithBreastCancerRisk/1_1s20S1076633218300072.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/UsingConvolutionalNeuralNetworksforEnhancedCaptureofBreastParenchymalComplexityPatternsAssociatedwithBreastCancerRisk/1_1s20S1076633218300072.jpg" alt="Figure 2, Design of comparative evaluation experiments: Evaluating the case-control discriminatory capacity of ( a ) conventional texture analysis and ( b ) convolutional neural networks applied directly to the original images." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/UsingConvolutionalNeuralNetworksforEnhancedCaptureofBreastParenchymalComplexityPatternsAssociatedwithBreastCancerRisk/2_1s20S1076633218300072.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/UsingConvolutionalNeuralNetworksforEnhancedCaptureofBreastParenchymalComplexityPatternsAssociatedwithBreastCancerRisk/2_1s20S1076633218300072.jpg" alt="Figure 3, Case-control classification outcomes of the hybrid framework: Probabilities (with 95% confidence limits) of test images to belong to a cancer case as predicted by the hybrid approach vs corresponding ground-truth labels (1: Case, 0: Control)." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>TABLE 2</p><p>Texture Features Selected by Elastic Net Regression</p><p><em>b__P</em> Value 95% CI TFM13_mean −0.59 .013 [−1.05, −0.12] TFM17_mean 0.03 .897 [−0.44, 0.50] TFM19_mean −0.69 .001 [−1.08, −0.29] TFM22_mean −1.31 .395 [−4.34, 1.71] TFM23_mean 0.76 .582 [−1.96, 3.48] TFM24_mean −0.14 .602 [−0.64, 0.37] TFM28_mean 1.07 .437 [−1.62, 3.75] TFM29_mean 0.05 .944 [−1.34, 1.44] TFM11_std 0.24 .642 [−0.79, 1.28] TFM15_std 0.52 .031 [0.05, 1.00] TFM22_std 0.14 .483 [−0.25, 0.53] TFM28_std −0.54 .002 [−0.87, −0.20]</p><p>For each feature, the logistic regression coefficient ( <em>b</em> ), the <em>P</em> value, and 95% confidence interval (CI) for <em>b</em> are provided.</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/UsingConvolutionalNeuralNetworksforEnhancedCaptureofBreastParenchymalComplexityPatternsAssociatedwithBreastCancerRisk/3_1s20S1076633218300072.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/UsingConvolutionalNeuralNetworksforEnhancedCaptureofBreastParenchymalComplexityPatternsAssociatedwithBreastCancerRisk/3_1s20S1076633218300072.jpg" alt="Figure 4, Comparative evaluation results: The hybrid approach, that is, texture analysis followed by multichannel CNNs, (AUC = 0.90) compared to conventional parenchymal texture analysis (AUC = 0.79) or single-channel CNNs applied directly to the original images (AUC = 0.63). AUC, area under the receiver operating characteristic curve; CNNs: convolutional neural networks." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">Discussion</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="acknowledgments"><span class="mr-2">Acknowledgments</span><a href="#acknowledgments" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="appendix"><span class="mr-2">Appendix</span><a href="#appendix" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="descriptions-of-texture-features"><span class="mr-2">Descriptions of Texture Features</span><a href="#descriptions-of-texture-features" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Onega T., Beaber E.F., Sprague B.L., et. al.: Breast cancer screening in an era of personalized regimens: a conceptual model and National Cancer Institute initiative for risk-based and preference-based approaches at a population level. Cancer 2014; 120: pp. 2955-2964.</p><li><p>2. Siu A.L.: Screening for breast cancer: US Preventive Services Task Force recommendation statement. Ann Intern Med 2016; 164: pp. 279-296.</p><li><p>3. Wolfe J.N.: Breast patterns as an index for developing breast cancer. AJR Am J Roentgenol 1976; 126: pp. 1130-1137.</p><li><p>4. McDonald E.S., Clark A.S., Tchou J., et. al.: Clinical diagnosis and management of breast cancer. J Nucl Med 2016; 57: pp. 9S-16S.</p><li><p>5. Ng K.-H., Lau S.: Vision 20/20: mammographic breast density and its clinical applications. Med Phys 2015; 42: pp. 7059-7077.</p><li><p>6. McCormack V.A., dos Santos Silva I.: Breast density and parenchymal patterns as markers of breast cancer risk: a meta-analysis. Cancer Epidemiol Biomarkers Prev 2006; 15: pp. 1159-1169.</p><li><p>7. Gastounioti A., Conant E.F., Kontos D.: Beyond breast density: a review on the advancing role of parenchymal texture analysis in breast cancer risk assessment. Breast Cancer Res 2016; 18: pp. 91.</p><li><p>8. Wang C., Brentnall A.R., Cuzick J., et. al.: A novel and fully automated mammographic texture analysis for risk prediction: results from two case-control studies. Breast Cancer Res 2017; 19: pp. 114.</p><li><p>9. Winkel R.R., Nielsen M., Petersen K., et. al.: Mammographic density and structural features can individually and jointly contribute to breast cancer risk assessment in mammography screening: a case-control study. BMC Cancer 2016; 16: pp. 414.</p><li><p>10. Li H., Giger M.L., Lan L., et. al.: Comparative analysis of image-based phenotypes of mammographic density and parenchymal patterns in distinguishing between BRCA1/2 cases, unilateral cancer cases, and controls. J Med Imaging 2014; 1: pp. 031009.</p><li><p>11. Häberle L., Wagner F., Fasching P.A., et. al.: Characterizing mammographic images by using generic texture features. Breast Cancer Res 2012; 14: pp. R59.</p><li><p>12. Manduca A., Carston M.J., Heine J.J., et. al.: Texture features from mammographic images and risk of breast cancer. Cancer Epidemiol Biomarkers Prev 2009; 18: pp. 837-845. PubMed PMID 19258482</p><li><p>13. Li H., Giger M.L., Olopade O.I., et. al.: Computerized texture analysis of mammographic parenchymal patterns of digitized mammograms. Acad Radiol 2005; 12: pp. 863-873.</p><li><p>14. Torres-Mejia G., De Stavola B., Allen D.S., et. al.: Mammographic features and subsequent risk of breast cancer: a comparison of qualitative and quantitative evaluations in the Guernsey prospective studies. Cancer Epidemiol Biomarkers Prev 2005; 14: pp. 1052-1059. PubMed PMID 15894652</p><li><p>15. Zheng Y., Keller B.M., Ray S., et. al.: Parenchymal texture analysis in digital mammography: a fully automated pipeline for breast cancer risk assessment. Med Phys 2015; 42: pp. 4149-4160.</p><li><p>16. Sun W., Tseng T.-L.B., Qian W., et. al.: Using multiscale texture and density features for near-term breast cancer risk analysis. Med Phys 2015; 42: pp. 2853-2862.</p><li><p>17. Keller B.M., Oustimov A., Wang Y., et. al.: Parenchymal texture analysis in digital mammography: robust texture feature identification and equivalence across devices. J Med Imaging 2015; 2: pp. 024501.</p><li><p>18. LeCun Y., Bengio Y., Hinton G.: Deep learning. Nature 2015; 521: pp. 436-444.</p><li><p>19. Bengio Y.: Learning deep architectures for AI. Found Trends Mach Learn 2009; 2: pp. 1-127.</p><li><p>20. Shin H.-C., Roth H.R., Gao M., et. al.: Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning. IEEE Trans Med Imaging 2016; 35: pp. 1285-1298.</p><li><p>21. Litjens G., Kooi T., Bejnordi B.E., et. al.: A survey on deep learning in medical image analysis. arXiv preprint arXiv:1702057472017.</p><li><p>22. Samala R.K., Chan H.P., Hadjiiski L., et. al.: Mass detection in digital breast tomosynthesis: deep convolutional neural network with transfer learning from mammography. Med Phys 2016; 43: pp. 6654-6666.</p><li><p>23. Kooi T., Litjens G., van Ginneken B., et. al.: Large scale deep learning for computer aided detection of mammographic lesions. Med Image Anal 2017; 35: pp. 303-312.</p><li><p>24. Huynh B.Q., Li H., Giger M.L.: Digital mammographic tumor classification using transfer learning from deep convolutional neural networks. J Med Imaging 2016; 3: pp. 034501.</p><li><p>25. Samala R.K., Chan H.-P., Hadjiiski L.M., et. al.: Multi-task transfer learning deep convolutional neural network: application to computer-aided diagnosis of breast cancer on mammograms. Phys Med Biol 2017; 62: pp. 8894-8908.</p><li><p>26. Kallenberg M., Petersen K., Nielsen M., et. al.: Unsupervised deep learning applied to breast density segmentation and mammographic risk scoring. IEEE Trans Med Imaging 2016; 35: pp. 1322-1331.</p><li><p>27. Li H., Giger M.L., Huynh B.Q., et. al.: Deep learning in breast cancer risk assessment: evaluation of convolutional neural networks on a clinical dataset of full-field digital mammograms. Journal of Medical Imaging 2017; 4: p.041304</p><li><p>28. Geras K.J., Wolfson S., Kim S., et. al.: High-resolution breast cancer screening with multi-view deep convolutional neural networks. arXiv preprint arXiv:1703070472017.</p><li><p>29. Keller B.M., Chen J., Daye D., et. al.: Preliminary evaluation of the publicly available Laboratory for Individualized Breast Radiodensity Assessment (LIBRA) software tool: comparison of fully automated area and volumetric density measures in a case-control study with digital mammography. Breast Cancer Res 2015; 17: pp. 1-17.</p><li><p>30. Chen X., Moschidis E., Taylor C., et. al.: Breast cancer risk analysis based on a novel segmentation framework for digital mammograms.Medical Image Computing and Computer-Assisted Intervention—MICCAI 2014.2014.SpringerCham:pp. 536-543.</p><li><p>31. Eng A., Gallant Z., Shepherd J., et. al.: Digital mammographic density and breast cancer risk: a case-control study of six alternative density assessment methods. Breast Cancer Res 2014; 16: pp. 439.</p><li><p>32. Keller B.M., Nathan D.L., Wang Y., et. al.: Estimation of breast percent density in raw and processed full field digital mammography images via adaptive fuzzy c-means clustering and support vector machine segmentation. Med Phys 2012; 39: pp. 4903-4917.</p><li><p>33. LeCun Y., Bottou L., Bengio Y., et. al.: Gradient-based learning applied to document recognition. P IEEE 1998; 86: pp. 2278-2324.</p><li><p>34. LeCun Y., Boser B., Denker J.S., et. al.: Backpropagation applied to handwritten zip code recognition. Neural Comput 1989; 1: pp. 541-551.</p><li><p>35. Prechelt L.: Early stopping—but when? Neural networks: tricks of the trade.2012.SpringerBerlin, Heidelbergpp. 53-67.</p><li><p>36. DeLong E.R., DeLong D.M., Clarke-Pearson D.L.: Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach. Biometrics 1988; 44: pp. 837-845.</p><li><p>37. Zou H., Hastie T.: Regularization and variable selection via the elastic net. J R Stat Soc Series B Stat Methodol 2005; 67: pp. 301-320.</p><li><p>38. Dieleman S., Schlüter J., Raffel C., et. al.: Lasagne: a lightweight library to build and train neural networks in Theano. Available at https://lasagne.readthedocs.io/en/latest/</p><li><p>39. Glorot X., Bengio Y.: Understanding the difficulty of training deep feedforward neural networks.2010.AISTATSChia Laguna Resort, Sardinia, Italy</p><li><p>40. Gastounioti A., Oustimov A., Keller B.M., et. al.: Breast parenchymal patterns in processed versus raw digital mammograms: a large population study toward assessing differences in quantitative measures across image representations. Med Phys 2016; 43: pp. 5862-5877.</p><li><p>41. Bergstra J., Bengio Y.: Random search for hyper-parameter optimization. J Mach Learn Res 2012; 13: pp. 281-305.</p><li><p>42. Materka A., Strzelecki M.: Texture analysis methods—a review. Technical University of Lodz, Institute of Electronics, COST B11 report, Brussels1998. 9–11</p><li><p>43. Haralick R.M., Shanmugam K., Dinstein I.H.: Textural features for image classification. IEEE Trans Syst Man Cybern 1973; pp. 610-621.</p><li><p>44. Galloway M.M.: Texture analysis using gray level run lengths. Comput Graph Image Process 1975; 4: pp. 172-179.</p><li><p>45. Chu A., Sehgal C.M., Greenleaf J.F.: Use of gray value distribution of run lengths for texture analysis. Pattern Recognit Lett 1990; 11: pp. 415-419.</p><li><p>46. Weickert J.: Coherence-enhancing diffusion filtering. Int J Comput Vis 1999; 31: pp. 111-127.</p><li><p>47. Ojala T., Pietikäinen M., Mäenpää T.: Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. IEEE Trans Pattern Anal Mach Intell 2002; 24: pp. 971-987.</p><li><p>48. Caldwell C.B., Stapleton S.J., Holdsworth D.W., et. al.: Characterisation of mammographic parenchymal pattern by fractal dimension. Phys Med Biol 1990; 35: pp. 235-247.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-25/'>Volume 25</a>, <a href='/categories/issue-8/'>Issue 8</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Using%20Convolutional%20Neural%20Networks%20for%20Enhanced%20Capture%20of%20Breast%20Parenchymal%20Complexity%20Patterns%20Associated%20with%20Breast%20Cancer%20Risk%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fusing-convolutional-neural-networks-for-enhanced-capture-of-breast-parenchymal-complexity-patterns-a%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Using%20Convolutional%20Neural%20Networks%20for%20Enhanced%20Capture%20of%20Breast%20Parenchymal%20Complexity%20Patterns%20Associated%20with%20Breast%20Cancer%20Risk%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fusing-convolutional-neural-networks-for-enhanced-capture-of-breast-parenchymal-complexity-patterns-a%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fusing-convolutional-neural-networks-for-enhanced-capture-of-breast-parenchymal-complexity-patterns-a%2F&text=Using%20Convolutional%20Neural%20Networks%20for%20Enhanced%20Capture%20of%20Breast%20Parenchymal%20Complexity%20Patterns%20Associated%20with%20Breast%20Cancer%20Risk%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/adaptive-iterative-dose-reduction-3d-integrated-with-automatic-tube-current-modulation-for-ct-corona/"><div class="card-body"> <em class="small" data-ts="1533056400" data-df="ll" > Jul 31, 2018 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Adaptive Iterative Dose Reduction 3D Integrated with Automatic Tube Current Modulation for CT Coronary Artery Calcium Quantification</h3><div class="text-muted small"><p> Rationale and Objectives We aimed to evaluate integrated adaptive iterative dose reduction 3D (AIDR 3D) algorithm in automatic tube current modulation (ATCM) for the quantification of coronary art...</p></div></div></a></div><div class="card"> <a href="/posts/artificial-intelligence-and-radiology-have-rumors-of-the-radiologist-s-demise-been-greatly-exaggera/"><div class="card-body"> <em class="small" data-ts="1533056400" data-df="ll" > Jul 31, 2018 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Artificial Intelligence and Radiology Have Rumors of the Radiologist's Demise Been Greatly Exaggerated?</h3><div class="text-muted small"><p> Artificial intelligence is a rapidly evolving computerized technology affecting multiple aspects of our lives. It is predicted that artificial intelligence will lead to a fundamental change in prac...</p></div></div></a></div><div class="card"> <a href="/posts/bridging-the-gap/"><div class="card-body"> <em class="small" data-ts="1533056400" data-df="ll" > Jul 31, 2018 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Bridging the Gap</h3><div class="text-muted small"><p> Rationale and Objectives Women make up half of American medical school graduates, but remain underrepresented among radiologists. This study sought to determine whether workforce gender disparitie...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/synthesized-mammography/" class="btn btn-outline-primary" prompt="Older"><p>Synthesized Mammography</p></a> <a href="/posts/utility-of-clinical-parameters-and-multiparametric-mri-as-predictive-factors-for-differentiating-ute/" class="btn btn-outline-primary" prompt="Newer"><p>Utility of Clinical Parameters and Multiparametric MRI as Predictive Factors for Differentiating Uterine Sarcoma From Atypical Leiomyoma</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

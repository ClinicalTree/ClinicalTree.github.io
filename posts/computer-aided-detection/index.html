<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Computer-Aided Detection" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/computer-aided-detection/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/computer-aided-detection/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2010-10-31T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Computer-Aided Detection" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-07T07:15:32+00:00","datePublished":"2010-10-31T17:00:00+00:00","description":"Rationale and Objectives","headline":"Computer-Aided Detection","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/computer-aided-detection/"},"url":"https://clinicaltree.github.io/posts/computer-aided-detection/"}</script><title>Computer-Aided Detection | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Computer-Aided Detection</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Computer-Aided Detection</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1288544400" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Oct 31, 2010 </em> </span> <span> Updated <em class="" data-ts="1680851732" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 7, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Bin Zheng PhD</a> </em>, <em> <a href="">Xingwei Wang PhD</a> </em>, <em> <a href="">Dror Lederman PhD</a> </em>, <em> <a href="">Jun Tan PhD</a> </em>, <em> <a href="">David Gur Sc.D.</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2470 words"> <em>13 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Lesion conspicuity is typically highly correlated with visual difficulty for lesion detection, and computer-aided detection (CAD) has been widely used as a “second reader” in mammography. Hence, increasing CAD sensitivity in detecting subtle cancers without increasing false-positive rates is important. The aim of this study was to investigate the effect of training database case selection on CAD performance in detecting low-conspicuity breast masses.</p><h2 id="materials-and-methods"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>A full-field digital mammographic image database that included 525 cases depicting malignant masses was randomly partitioned into three subsets. A CAD scheme was applied to detect all initially suspected mass regions and compute region conspicuity. Training samples were iteratively selected from two of the subsets. Four types of training data sets—(1) one including all available true-positive mass regions in the two subsets (“all”), (2) one including 350 randomly selected mass regions (“diverse”), (3) one including 350 high-conspicuity mass regions (“easy”), and (4) one including 350 low-conspicuity mass regions (“difficult”)—were assembled. In each training data set, the same number of randomly selected false-positive regions as the true-positives were also included. Two classifiers, an artificial neural network (ANN) and a <em>k</em> -nearest neighbor (KNN) algorithm, were trained using each of the four training data sets and tested on all suspected regions in the remaining data set. Using a threefold cross-validation method, the performance changes of the CAD schemes trained using one of the four training data sets were computed and compared.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>CAD initially detected 1025 true-positive mass regions depicted on 507 cases (97% case-based sensitivity) and 9569 false-positive regions (3.5 per image) in the entire database. Using the all training data set, CAD achieved the highest overall performance on the entire testing database. However, CAD detected the highest number of low-conspicuity masses when the difficult training data set was used for training. Results did agree for both ANN-based and KNN-based classifiers in all tests. Compared to the use of the all training data set, the sensitivity of the schemes trained using the difficult data set decreased by 8.6% and 8.4% for the ANN and KNN algorithm on the entire database, respectively, but the detection of low-conspicuity masses increased by 7.1% and 15.1% for the ANN and KNN algorithm at a false-positive rate of 0.3 per image.</p><h2 id="conclusions"><span class="mr-2">Conclusions</span><a href="#conclusions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>CAD performance depends on the size, diversity, and difficulty level of the training database. To increase CAD sensitivity in detecting subtle cancer, one should increase the fraction of difficult cases in the training database rather than simply increasing the training data set size.</p><p>Computer-aided detection (CAD) systems for mammography have been widely used in the clinical practice when interpreting screening breast examinations. CAD systems process digitized or digital mammograms and mark on the images detected suspected regions for masses and microcalcification clusters. The “second reader” approach emphasizes that radiologists should first read and interpret mammograms without CAD, followed by review of CAD results, in particular as related to regions that perhaps were missed and/or underestimated in importance, prior to making a final diagnostic decision. A number of studies have assessed the impact of using CAD on radiologists’ performance, but the results have remained somewhat inconclusive and perhaps even controversial to date . In general, CAD detects more cancers associated with microcalcification clusters than radiologists (ie, 22 vs 15 [2]) but has lower sensitivity in detecting malignant masses than radiologists (ie, 18 vs 26 [2] and 86 vs 105 [5]). Thus, reported cancer detection rates show primarily an increase in the detection of additional microcalcification clusters . When testing the performance of commercial CAD systems on different types of cases, several tendencies were reported, in that CAD performance typically decreases with increases in breast tissue density and decreases in lesion size . As a result, CAD results were found to be relatively highly correlated with radiologists’ visual detection; namely, masses that were missed by radiologists were more likely to be also missed by CAD .</p><p>Regardless of the different machine-learning (computerized) classifiers being used, CAD performance depends on specific selection of training and testing data sets. Several studies have used computer-generated (simulated) databases to predict the effect, if any, of database selection on CAD performance and reported a substantially possible bias if CAD was trained with a small data set and/or used a large number of features . Other studies used actual image data to investigate the relationship between CAD performance and database selection. One study investigated the dependence of CAD performance on the “difficulty” of the testing data sets. At a false-positive rate of 1 per image, the sensitivity levels of a preoptimized CAD scheme were 26%, 74%, and 100% on three testing data sets with different difficulty levels . Two studies investigated CAD performance changes as a function of the training data set size when applied to a fixed (independent) testing data set. One reported a performance increase (area under the receiver-operating characteristic curve) from 0.724 to 0.836 as the size of the training data set increased from 50 to 500 , and the other reported that CAD performance increased from 0.715 to 0.874 as the training database size increased from 630 to approximately 2000 and then reached a plateau as training database size increased to 3150 . Other studies also independently trained two CAD schemes, one using masses depicted on “current” examinations on which the masses were detected by radiologists (an “easy” data set) and one using the masses depicted on “prior” examinations on which the masses were missed (or not reported) by the radiologists during the original interpretation but were considered “visible” during a retrospective review (a “difficult” data set). Both studies demonstrated that combining the two schemes improved overall CAD performance .</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="materials-and-methods-1"><span class="mr-2">Materials and methods</span><a href="#materials-and-methods-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="image-database"><span class="mr-2">Image Database</span><a href="#image-database" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="cad-scheme"><span class="mr-2">CAD Scheme</span><a href="#cad-scheme" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>d(yT,xi)=∑14r=1[fr(yT)−fr(xi)]2−−−−−−−−−−−−−−−−−−−√. d</p><p>(</p><p>y</p><p>T</p><p>,</p><p>x</p><p>i</p><p>)</p><p>=</p><p>∑</p><p>r</p><p>=</p><p>1</p><p>14</p><p>[</p><p>f</p><p>r</p><p>(</p><p>y</p><p>T</p><p>)</p><p>−</p><p>f</p><p>r</p><p>(</p><p>x</p><p>i</p><p>)</p><p>]</p><p>2</p><p>.</p><p>The smaller the distance, the higher the degree of “similarity” between any two regions being compared. The KNN-generated detection score is computed as follows:</p><p>PTP=∑Ni=1wTPi∑Ni=1wTPi+∑Mj=1wFPj, P</p><p>TP</p><p>=</p><p>∑</p><p>i</p><p>=</p><p>1</p><p>N</p><p>w</p><p>i</p><p>TP</p><p>∑</p><p>i</p><p>=</p><p>1</p><p>N</p><p>w</p><p>i</p><p>TP</p><p>+</p><p>∑</p><p>j</p><p>=</p><p>1</p><p>M</p><p>w</p><p>j</p><p>FP</p><p>,</p><p>where wi=1d(yT,xi)2 w</p><p>i</p><p>=</p><p>1</p><p>d</p><p>(</p><p>y</p><p>T</p><p>,</p><p>x</p><p>i</p><p>)</p><p>2 (a distance weight); wTPi w</p><p>i</p><p>TP and wFPj w</p><p>j</p><p>FP are the distance weights for true-positive ( <em>i</em> ) and false-positive ( <em>j</em> ) regions, respectively; <em>N</em> is the number of verified true-positive (TP) mass regions; <em>M</em> is the number of CAD-generated false-positive (FP) regions, and <em>N</em> + <em>M</em> = 15.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="cad-performance-assessment"><span class="mr-2">CAD Performance Assessment</span><a href="#cad-performance-assessment" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 1</p><p>The Three Data Partitions (Subsets) Generated from the Original Full-Field Digital Mammographic Image Database</p><p>Data Subset (Partition) Variable 1 2 3 Number of cases 175 175 175 Number of images 836 836 1060 Number of true-positive mass regions 342 342 341 Number of false-positive regions 2766 2989 3814</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 2</p><p>Distribution of Normalized Conspicuity Levels for CAD-generated TP and FP Regions</p><p>Conspicuity Level Variable Low Moderate High Total Conspicuity ( <em>C</em> ) value 0 ≤ <em>C</em> &lt; 0.33 0.33 ≤ <em>C</em> &lt; 0.67 0.67 ≤ <em>C</em> ≤ 1.0 0 ≤ <em>C</em> ≤ 1.0 Number of TPs 325 (31.7%) 528 (51.5%) 172 (16.8%) 1025 Number of FPs 6734 (70.3%) 2608 (27.3%) 227 (2.4%) 9569</p><p>CAD, computer-aided detection; FP, false-positive; TP, true-positive.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComputerAidedDetection/0_1s20S107663321000317X.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComputerAidedDetection/0_1s20S107663321000317X.jpg" alt="Figure 1, Two region-based free-response receiver-operating characteristic–type performance curves generated by the artificial neural network (ANN)–based and k -nearest neighbor (KNN)–based computer-aided detection schemes when trained using the all training data set." class="lazyload" data-proofer-ignore></a></p><p>Table 3</p><p>Region-based CAD Performance Levels on the Entire Database (Normalized Areas Under FROC Curves and Standard Deviations) for the ANN-based and KNN-based Classifiers That Were Independently Trained by Each of the Four Training Data Sets</p><p>Training Dataset All Diverse Easy Difficult CAD using ANN 0.864 ± 0.005 0.814 ± 0.007 0.816 ± 0.007 0.808 ± 0.007 CAD using KNN algorithm 0.854 ± 0.006 0.817 ± 0.007 0.821 ± 0.006 0.821 ± 0.006</p><p>ANN, artificial neural network; CAD, computer-aided detection; FROC, free-response receiver-operating characteristic; <em>KNN</em> , k-nearest neighbor.</p><p>Data are expressed as mean ± standard deviation.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 4</p><p>Number of TP Mass Regions Detected by ANN-based CAD at a False-positive Rate of 0.3 per Image</p><p>Conspicuity Level Low Moderate High Total Initially detected TP ROIs 325 528 172 1025 Training data set All 122 (37.5%) 390 (73.9%) 164 (95.3%) 676 (66.0%) Diverse 109 (33.5%) 363 (68.8%) 156 (90.7%) 628 (61.3%) Easy 3 (0.9%) 369 (69.9%) 161 (93.6%) 533 (52.0%) Difficult 145 (44.6%) 330 (62.5%) 113 (65.7%) 588 (57.4%)</p><p>ANN, artificial neural network; CAD, computer-aided detection; ROI, region of interest; TP, true-positive.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 5</p><p>Number of TP Mass Regions Detected by KNN-based CAD at a False-positive Rate of 0.3 per Image</p><p>Conspicuity Level Low Moderate High Total Initially detected TP ROIs 325 528 172 1025 Training data set All 84 (25.8%) 355 (67.2%) 163 (94.7%) 602 (58.7%) Diverse 96 (29.5%) 371 (70.3%) 153 (90.0%) 620 (60.5%) Easy 26 (8.0%) 363 (68.8%) 165 (95.9%) 554 (54.0%) Difficult 133 (40.9%) 315 (59.7%) 68 (39.5%) 516 (50.3%)</p><p>CAD, computer-aided detection; KNN, <em>k</em> -nearest neighbor; ROI, region of interest; TP, true-positive.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComputerAidedDetection/1_1s20S107663321000317X.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ComputerAidedDetection/1_1s20S107663321000317X.jpg" alt="Figure 2, Region-based sensitivity levels in detecting low-conspicuity mass regions at a false-positive of 0.3 per image. The eight computer-aided detection schemes include two classifiers (an artificial neural network [ANN] and a k -nearest neighbor [KNN] algorithm) that were independently trained by each of the four training data sets." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">Discussion</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="conclusions-1"><span class="mr-2">Conclusions</span><a href="#conclusions-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Nishikawa R.M., Kallergi M.: Computer-aided detection, in its present form, is not an effective aid for screening mammography. Med Phys 2006; 33: pp. 811-814.</p><li><p>2. Freer T.M., Ulissey M.J.: Screening mammography with computer-aided detection: prospective study of 12,860 patients in a community breast center. Radiology 2001; 220: pp. 781-786.</p><li><p>3. Gur D., Sumkin J.H., Rockette H.E., et. al.: Changes in breast cancer detection and mammography recall rates after the introduction of a computer-aided detection system. J Natl Cancer Inst 2004; 96: pp. 185-190.</p><li><p>4. Khoo L.A., Taylor P., Given-Wilson R.M.: Computer-aided detection in the United Kingdom National Breast Screening Programme: prospective study. Radiology 2005; 237: pp. 444-449.</p><li><p>5. Morton M.J., Whaley D.H., Brandt K.R., et. al.: Screening mammograms: Interpretation with computer-aided detection—prospective evaluation. Radiology 2006; 239: pp. 375-383.</p><li><p>6. Fenton J.J., Taplin S.H., Carney P.A., et. al.: Influence of computer-aided detection on performance of screening mammography. N Engl J Med 2007; 356: pp. 1399-1409.</p><li><p>7. Obenauer S., Sohns C., Werner C., et. al.: Impact of breast density on computer-aided detection in full-field digital mammography. J Digit Imaging 2006; 19: pp. 258-263.</p><li><p>8. Sadaf A, Crystal P, Scaranelo A, et al. Performance of computer-aided detection applied to full-field digital mammography in detection of breast cancers. Eur J Radiol. In press.</p><li><p>9. Gur D., Stalder J.S., Hardesty L.A., et. al.: Computer-aided detection performance in mammographic examination of masses: assessment. Radiology 2004; 223: pp. 418-423.</p><li><p>10. Kupinski M.A., Giger M.L.: Feature selection with limited datasets. Med Phys 1999; 26: pp. 2176-2182.</p><li><p>11. Chan H.P., Sahiner B., Wagner R.F., et. al.: Classifier design for computer-aided diagnosis: effects of finite sample size on the mean performance of classical and neural network classifiers. Med Phys 1999; 26: pp. 2654-2668.</p><li><p>12. Sahiner B., Chan H.P., Hadjiiski L.: Classifier performance prediction for computer-aided diagnosis using a limited dataset. Med Phys 2008; 35: pp. 1559-1570.</p><li><p>13. Nishikawa R.M., Giger M.L., Doi K., et. al.: Effect of case selection on the performance of computer-aided detection schemes. Med Phys 1994; 21: pp. 265-269.</p><li><p>14. Zheng B., Chang Y.H., Good W.F., et. al.: Adequacy testing of training set sample sizes in the development o f a computer-assisted diagnosis scheme. Acad Radiol 1997; 4: pp. 497-502.</p><li><p>15. Park S.C., Sulkthankar R., Mummert L., et. al.: Optimization of reference library used in content-based medical image retrieval scheme. Med Phys 2007; 34: pp. 4331-4339.</p><li><p>16. Zheng B., Good W.F., Armfield D.R., et. al.: Performance change of a mammographic CAD scheme optimized using most recent and prior image database. Acad Radiol 2003; 10: pp. 233-238.</p><li><p>17. Wei J., Chan H.P., Sahiner B., et. al.: Dual system approach to computer-aided detection of breast masses on mammograms. Med Phys 2006; 33: pp. 4157-4168.</p><li><p>18. Kundel H.L., Revesz G.: Lesion conspicuity, structure noise, and film reader error. AJR Am J Roentgenol 1976; 126: pp. 1233-1238.</p><li><p>19. Revesz G., Kundel H.L.: Psychophysical studies of detection errors in chest radiology. Radiology 1977; 123: pp. 559-562.</p><li><p>20. Revesz G., Kundel H.L., Toto L.C.: Densitometric measurements of lung nodules on the chest radiographs. Invest Radiol 1981; 16: pp. 201-205.</p><li><p>21. Zheng B., Chang Y.H., Good W.F., et. al.: Performance gain in computer-assisted detection schemes by averaging scores generated from artificial neural networks with adaptive filtering. Med Phys 2001; 28: pp. 2302-2308.</p><li><p>22. Zheng B., Chang Y.H., Gur D.: Computerized detection of masses in digitized mammograms using single-image segmentation and a multilayer topographic feature analysis. Acad Radiol 1995; 2: pp. 959-966.</p><li><p>23. Mitchell T.M.: Machine Learning.1997.WCB/McGraw-HillBoston</p><li><p>24. Park S.C., Pu J., Zheng B.: Improving performance of computer-aided detection scheme by combining results from two machine learning classifiers. Acad Radiol 2009; 16: pp. 266-274.</p><li><p>25. Zheng B., Lu A., Hardesty L.A., et. al.: A method to improve visual similarity of breast masses for an interactive computer-aided diagnosis environment. Med Phys 2006; 33: pp. 111-117.</p><li><p>26. Yoon H.J., Zheng B., Sahiner S., et. al.: Evaluating computer-aided detection algorithms. Med Phys 2007; 34: pp. 2024-2034.</p><li><p>27. The J.S., Schilling K.J., Hoffmeister J.W., et. al.: Detection of breast cancer with full-field digital mammography and computer-aided detection. AJR Am J Roentgenol 2009; 192: pp. 337-340.</p><li><p>28. Li Q.: Reliable evaluation of performance level for computer-aided diagnostic scheme. Acad Radiol 2007; 14: pp. 985-991.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-17/'>Volume 17</a>, <a href='/categories/issue-11/'>Issue 11</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Computer-Aided%20Detection%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fcomputer-aided-detection%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Computer-Aided%20Detection%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fcomputer-aided-detection%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fcomputer-aided-detection%2F&text=Computer-Aided%20Detection%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/a-s-urvey-of-clinical-research-coordinators-in-the-cooperative-group-setting-of-the-american-college/"><div class="card-body"> <em class="small" data-ts="1288544400" data-df="ll" > Oct 31, 2010 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>A S urvey of Clinical Research Coordinators in the Cooperative Group Setting of the American College of Radiology Imaging Network (ACRIN)</h3><div class="text-muted small"><p> Rationale and Objectives As one of the newest cooperative groups funded by the National Cancer Institute in 1999, the American College of Radiology Imaging Network (ACRIN) is interested in conduct...</p></div></div></a></div><div class="card"> <a href="/posts/automatic-segmentation-of-cerebrospinal-fluid-white-and-gray-matter-in-unenhanced-computed-tomograp/"><div class="card-body"> <em class="small" data-ts="1288544400" data-df="ll" > Oct 31, 2010 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Automatic Segmentation of Cerebrospinal Fluid, White and Gray Matter in Unenhanced Computed Tomography Images</h3><div class="text-muted small"><p> Rationale and Objectives Although segmentation algorithms for cerebrospinal fluid (CSF), white matter (WM), and gray matter (GM) on unenhanced computed tomographic (CT) images exist, there is no c...</p></div></div></a></div><div class="card"> <a href="/posts/comparison-of-gadofosveset-trisodium-and-gadobenate-dimeglumine-during-time-resolved-thoracic-mr-ang/"><div class="card-body"> <em class="small" data-ts="1288544400" data-df="ll" > Oct 31, 2010 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Comparison of Gadofosveset Trisodium and Gadobenate Dimeglumine During Time-Resolved Thoracic MR Angiography at 3T</h3><div class="text-muted small"><p> Rationale and Objectives Gadofosveset trisodium is a blood-pool contrast agent (BPA) that shows a less pronounced r1 relaxivity advantage over gadobenate dimeglumine at 3T than at 1.5T. However, t...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/comparison-of-gadofosveset-trisodium-and-gadobenate-dimeglumine-during-time-resolved-thoracic-mr-ang/" class="btn btn-outline-primary" prompt="Older"><p>Comparison of Gadofosveset Trisodium and Gadobenate Dimeglumine During Time-Resolved Thoracic MR Angiography at 3T</p></a> <a href="/posts/dieting/" class="btn btn-outline-primary" prompt="Newer"><p>Dieting</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

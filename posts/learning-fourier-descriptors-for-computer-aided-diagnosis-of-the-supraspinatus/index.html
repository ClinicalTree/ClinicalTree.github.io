<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Learning Fourier Descriptors for Computer-Aided Diagnosis of the Supraspinatus" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/learning-fourier-descriptors-for-computer-aided-diagnosis-of-the-supraspinatus/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/learning-fourier-descriptors-for-computer-aided-diagnosis-of-the-supraspinatus/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2010-07-31T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Learning Fourier Descriptors for Computer-Aided Diagnosis of the Supraspinatus" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-07T07:15:32+00:00","datePublished":"2010-07-31T17:00:00+00:00","description":"Rationale and Objectives","headline":"Learning Fourier Descriptors for Computer-Aided Diagnosis of the Supraspinatus","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/learning-fourier-descriptors-for-computer-aided-diagnosis-of-the-supraspinatus/"},"url":"https://clinicaltree.github.io/posts/learning-fourier-descriptors-for-computer-aided-diagnosis-of-the-supraspinatus/"}</script><title>Learning Fourier Descriptors for Computer-Aided Diagnosis of the Supraspinatus | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Learning Fourier Descriptors for Computer-Aided Diagnosis of the Supraspinatus</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Learning Fourier Descriptors for Computer-Aided Diagnosis of the Supraspinatus</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1280595600" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jul 31, 2010 </em> </span> <span> Updated <em class="" data-ts="1680851732" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 7, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Oliver van Kaick MSc</a> </em>, <em> <a href="">Ghassan Hamarneh PhD</a> </em>, <em> <a href="">Aaron D. Ward PhD</a> </em>, <em> <a href="">Mark Schweitzer MD</a> </em>, <em> <a href="">Hao Zhang PhD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3087 words"> <em>17 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Supraspinatus muscle disorders are frequent and debilitating, resulting in pain and a limited range of shoulder motion. The gold standard for diagnosis involves an invasive surgical procedure. As part of a proposed clinical workflow for noninvasive computer-aided diagnosis (CAD) of the condition of the supraspinatus, we present a method to classify three-dimensional shapes of the muscle into relevant pathology groups, based on magnetic resonance (MR) images.</p><h2 id="materials-and-methods"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>We obtained MR images of the shoulder from 72 patients, separated into five pathology groups. The imaging protocol ensures that the supraspinatus is consistently oriented relative to the MR imaging plane for each scan. Next, we compute the Fourier coefficients of two-dimensional contours lying on parallel imaging planes and integrate the corresponding frequency components across all contours. To classify the shapes, we learn the Fourier coefficients that best distinguish the different classes.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>We show that our method leads to significant improvement when compared to previous work. We are able to distinguish between normal shapes and shapes that possess a pathology with an accuracy of almost 100%. Moreover, we can differentiate between the different pathology groups with an average accuracy of 86%.</p><h2 id="conclusion"><span class="mr-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>We confirm that analyzing the three-dimensional shape of the muscle has potential as a form of diagnosis reinforcement to assess the condition of the supraspinatus. Moreover, our proposed descriptor based on Fourier coefficients is able to distinguish the different pathology groups with accuracies higher than those obtained by previous work, indicating its potential application to support a system for CAD of the supraspinatus.</p><p>The supraspinatus muscle originates from the supraspinatus fossa of the scapula and runs along the top of the shoulder blade. This muscle is part of the rotator cuff, which is a group of muscles and tendons responsible for shoulder movement and stabilization. Disorders affecting the rotator cuff can cause pain and reduce patient mobility , and their occurrence is frequent, with a reported rate of 30% of individuals older than 60 years of age in a cadaveric study . Supraspinatus disorders involving tendon tearing can be accompanied by muscle retraction, atrophy, or both. The standard procedure for the diagnosis of rotator cuff disorders is shoulder arthroscopy, which is a surgery involving the insertion of an optical camera. However, diagnosis based on magnetic resonance (MR) images is a preferred noninvasive alternative. Additionally, the impact of a supraspinatus tendon tear on the overall body of the muscle has prognostic value and is visible on MR images, but is not visible during arthroscopy .</p><p>The long-term goal of our research is to develop a tool for noninvasive computer-aided diagnosis (CAD) of the supraspinatus, based on three-dimensional (3D) shapes extracted from MR images. The realization of this goal would lead to several important benefits and results. First, CAD can be helpful to provide a second opinion or to serve as a form of diagnosis reinforcement for the physician; it can also be valuable when other clinical data (eg, palpation or range-of-motion exams in the context of musculoskeletal disorders) do not provide a clear indication of the pathology. Second, understanding the relationship between shape and pathology can be helpful in providing evidence for etiological or epidemiological studies. Last, the impact of a torn tendon on the shape of the supraspinatus, which has prognostic significance, can be assessed more accurately by analyzing the 3D shape of the muscle. We are therefore motivated to perform an automated analysis of the 3D shape of the supraspinatus, which would allow us to improve on the diagnosis based on two-dimensional (2D) MR images or even shoulder arthroscopy. Previous work concluded that the shape of the supraspinatus is helpful in the diagnosis of rotator cuff disorders, but a more effective shape analysis procedure is necessary to achieve a pathology classification with 100% accuracy . From a computational viewpoint, our goal is: given a set of shapes and their diagnoses (which were determined by a physician), learn the relationship between the shape of the supraspinatus and its pathologies, and employ such a relationship in CAD.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="APKAICLNFGBCWWYGVIZQ" class="popup img-link "><img data-src="https://d1niluoi1dd30v.cloudfront.net/10766332/S1076633210X00071/S1076633210001868/gr1.jpg?Signature=WXx6A6n1sCQONJxu0Hwizbx%7EXylTji7yxFd3b5stqc3eWLqQmkRU9B7jAf3mCE-x%7EQa-g3ng6CCdr9My-bs3M96Plrn8e-nNk%7Et0pV7zxE-0UBAyNBTtxO4VElifI8tFqebyJx0U3zIbuRIBlQ%7EeN%7EfNGRTPfevFZdGznnHbc-8_&amp;Expires=1669558895&amp;Key-Pair-Id=APKAICLNFGBCWWYGVIZQ" alt="" class="lazyload" data-proofer-ignore></a>Open full size image</p><p>Figure 1</p><p>Input to the representation used in this work. <strong>(a)</strong> Magnetic resonance (MR) images of the shoulder of a patient are acquired (only one image is shown). <strong>(b)</strong> The three-dimensional shape of the supraspinatus muscle is segmented from the MR images. <strong>(c)</strong> The final shape of the muscle is captured as a set of two-dimensional (2D) contours (only three contours are shown for illustration purposes).</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="materials-and-methods-1"><span class="mr-2">Materials and methods</span><a href="#materials-and-methods-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 1</p><p>Pathology Groups Considered in the Study</p><p>Pathology Abbreviation Number of Shapes No pathology (normal) N 14 Tear T 19 Tear and atrophy TA 13 Tear and retraction TR 15 Tear and atrophy and retraction TAR 11</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/LearningFourierDescriptorsforComputerAidedDiagnosisoftheSupraspinatus/0_1s20S1076633210001868.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/LearningFourierDescriptorsforComputerAidedDiagnosisoftheSupraspinatus/0_1s20S1076633210001868.jpg" alt="Figure 2, Proposed method: starting from the segmented muscle, the Fourier transform is applied to each individual contour (only three contours are shown for illustration purposes). The resulting normalized coefficients c i are integrated for all the contours, yielding a vector of descriptors F . The vector is then partitioned into sets φ i and the best combination of sets is selected according to a classifier. The set size is 2 in this example for illustration purposes only. 2D: two-dimensional." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="descriptor-computation"><span class="mr-2">Descriptor Computation</span><a href="#descriptor-computation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="contour-decomposition"><span class="mr-2">Contour decomposition</span><a href="#contour-decomposition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>fk=∑N−1n=0xnexp(−2πiNkn), f</p><p>k</p><p>=</p><p>∑</p><p>n</p><p>=</p><p>0</p><p>N</p><p>−</p><p>1</p><p>x</p><p>n</p><p>exp</p><p>(</p><p>−</p><p>2</p><p>π</p><p>i</p><p>N</p><p>k</p><p>n</p><p>)</p><p>,</p><p>where <em>k</em> ∈ in [0, 1, …, N–1] and <strong>f</strong> is a vector of complex coefficients. The Fourier transform decomposes a signal into a set of frequency components that provide a complete, coarse-to-fine description of the signal. The coefficient <strong>f</strong> <em>k</em> corresponds to the amount of frequency <em>k</em> that is present in the original signal. The frequencies <em>k</em> are increasing multiples of the sampling frequency.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="obtaining-invariance"><span class="mr-2">Obtaining invariance</span><a href="#obtaining-invariance" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>s1fks1fl=s2fks2fl,∀k, s</p><p>1</p><p>f</p><p>k</p><p>s</p><p>1</p><p>f</p><p>l</p><p>=</p><p>s</p><p>2</p><p>f</p><p>k</p><p>s</p><p>2</p><p>f</p><p>l</p><p>,</p><p>∀</p><p>k</p><p>,</p><p>where <strong>f</strong> <em>l</em> is a specific non-zero component. Because we discard the DC-components (set | <strong>f</strong> <em>0</em> | to zero), we use the first frequency components | <strong>f</strong> <em>1</em> | for the previously mentioned scale normalization. Therefore, the normalized coefficients are given by ck=|fk|/|f1| c</p><p>k</p><p>=</p><p>|f</p><p>k</p><p>|</p><p>/</p><p>|f</p><p>1</p><p>| , where |f1|=maxl|fl1| |f</p><p>1</p><p>|</p><p>=</p><p>max</p><p>l</p><p>|f</p><p>1</p><p>l</p><p>| , with flk f</p><p>k</p><p>l denoting the coefficient associated to frequency <em>k</em> for contour <em>l</em> in the muscle.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="final-descriptor"><span class="mr-2">Final descriptor</span><a href="#final-descriptor" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>F=(∑lcl1,∑lcl2,…,∑lclN−1) F</p><p>=</p><p>(</p><p>∑</p><p>l</p><p>c</p><p>1</p><p>l</p><p>,</p><p>∑</p><p>l</p><p>c</p><p>2</p><p>l</p><p>,</p><p>.</p><p>.</p><p>.</p><p>,</p><p>∑</p><p>l</p><p>c</p><p>N</p><p>−</p><p>1</p><p>l</p><p>)</p><p>The descriptor component <strong>F</strong> <em>k</em> (referred to simply as <em>component</em> hereafter), indicates the total contribution of frequency <em>k</em> to the shape, measured on slices along a specific axis. The resolution within each slice is between 0.3 and 0.6 mm, so the frequencies analyzed are multiples of the sampling frequency, ie k106 k</p><p>10</p><p>6 to k103 k</p><p>10</p><p>3 cycles/mm. Because the contours lie on planes aligned in a consistent direction in all shapes and they are described by rotation-, translation-, and scale-invariant components, the final descriptor <strong>F</strong> is coherent across different shapes and hence the need to establish point correspondence is avoided. The descriptor implicitly captures the 3D shape of the muscle by recording the changes in scale between the contours of a given muscle and also the variations in the shapes of the contours at different frequencies. These frequency variations are integrated for all the contours in the muscle.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="descriptor-selection-and-classification"><span class="mr-2">Descriptor Selection and Classification</span><a href="#descriptor-selection-and-classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="partitioning-and-set-combination"><span class="mr-2">Partitioning and set combination</span><a href="#partitioning-and-set-combination" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>distH(A,B)=maxa∈Aminb∈Bdist(a, b) dis</p><p>t</p><p>H</p><p>(</p><p>A</p><p>,</p><p>B</p><p>)</p><p>=</p><p>max</p><p>a</p><p>∈</p><p>A</p><p>min</p><p>b</p><p>∈</p><p>B</p><p>dist</p><p>(a, b)</p><p>where <em>A</em> and <em>B</em> are two contours, <em>a</em> and <em>b</em> are vertices on the contours, and dist(a,b) is the Euclidean distance between two vertices.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="classification"><span class="mr-2">Classification</span><a href="#classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="multiclass-scenario"><span class="mr-2">Multiclass scenario</span><a href="#multiclass-scenario" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>δ=argmaxi∑j,j≠ipij, δ</p><p>=</p><p>arg</p><p>max</p><p>i</p><p>∑</p><p>j</p><p>,</p><p>j</p><p>≠</p><p>i</p><p>p</p><p>i</p><p>j</p><p>,</p><p>where <em>p ij</em> is the posterior probability that the shape belongs to class <em>i</em> according to the classifier trained to distinguish between classes <em>i</em> and <em>j</em> . In this work, 1 &lt; <em>i</em> &lt; 5 and 1 &lt; <em>j</em> &lt; 5.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Rij=TPijTPij+FNij,Pij=TPijTPij+FPij,andFij=2RijPijRij+Pij. R</p><p>i</p><p>j</p><p>=</p><p>T</p><p>P</p><p>i</p><p>j</p><p>T</p><p>P</p><p>i</p><p>j</p><p>+</p><p>F</p><p>N</p><p>i</p><p>j</p><p>,</p><p>P</p><p>i</p><p>j</p><p>=</p><p>T</p><p>P</p><p>i</p><p>j</p><p>T</p><p>P</p><p>i</p><p>j</p><p>+</p><p>F</p><p>P</p><p>i</p><p>j</p><p>,</p><p>and</p><p>F</p><p>i</p><p>j</p><p>=</p><p>2</p><p>R</p><p>i</p><p>j</p><p>P</p><p>i</p><p>j</p><p>R</p><p>i</p><p>j</p><p>+</p><p>P</p><p>i</p><p>j</p><p>.</p><p>When considering only two classes, we have that the recall R <em>ij</em> is also known as the <em>sensitivity</em> for class <em>i</em> , whereas the recall R <em>ji</em> is the <em>specificity</em> for class <em>i</em> . Moreover, the F-measure is a way of combining into a single number the recall and precision values. Because we are performing pairwise classification, we compute the average of the F-measure for the two classes involved, denoting it as Fij¯¯¯¯=(Fij+Fji)/2 F</p><p>i</p><p>j</p><p>¯</p><p>=</p><p>(</p><p>F</p><p>i</p><p>j</p><p>+</p><p>F</p><p>j</p><p>i</p><p>)</p><p>/</p><p>2 . An assessment of the overall classification is given by the G-mean, which is the geometric mean of recall values for all classes. It is formally defined as</p><p>G=(∏Ki=1∏Kj=1,j≠iRij)1/(K(K−1)), G</p><p>=</p><p>(</p><p>∏</p><p>i</p><p>=</p><p>1</p><p>K</p><p>∏</p><p>j</p><p>=</p><p>1</p><p>,</p><p>j</p><p>≠</p><p>i</p><p>K</p><p>R</p><p>i</p><p>j</p><p>)</p><p>1</p><p>/</p><p>(</p><p>K</p><p>(</p><p>K</p><p>−</p><p>1</p><p>)</p><p>)</p><p>,</p><p>where <em>K</em> is the number of classes.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="pairwise-classification"><span class="mr-2">Pairwise Classification</span><a href="#pairwise-classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 2</p><p>Accuracy (Aij) Results for Pairwise Classification</p><p>G G Opt F N T TA TR N T TA TR N T TA TR T 70 79 100 TA 81 72 85 81 100 84 TR 79 44 82 90 65 82 97 82 89 TAR 76 73 50 73 88 73 67 73 100 87 92 81</p><p>Improvements in relation to G are marked with red color. Please refer to Table 1 for the meaning of the row and column labels.</p><p>Table 3</p><p>Recall (R ij ) Results for Pairwise Classification</p><p>G Opt F N T TA TR TAR N T TA TR TAR N 64 93 93 93 100 100 100 100 T 89 95 68 79 100 95 89 89 TA 77 62 62 54 100 69 92 100 TR 87 60 100 100 93 73 87 87 TAR 82 64 82 36 100 82 82 73</p><p>Improvements in relation to G Opt are marked with red color. Please refer to Table 1 for the meaning of the row and column labels.</p><p>Table 4</p><p>Precision (P ij ) Results for Pairwise Classification</p><p>G Opt F N T TA TR TAR N T TA TR TAR N 82 81 87 87 100 100 93 100 T 77 78 68 79 100 82 81 89 TA 91 89 100 78 100 90 86 87 TR 93 60 75 68 100 85 93 81 TAR 90 64 60 100 100 82 100 80</p><p>Improvements in relation to G Opt are marked with red color. Please refer to Table 1 for the meaning of the row and column labels.</p><p>Table 5</p><p>Average F-measure (F ij ) and G-mean Results for Pairwise Classification</p><p>G Opt F N T TA TR N T TA TR T 77 100 TA 85 79 100 83 TR 90 64 81 97 82 89 TAR 88 71 66 67 100 86 91 80 G-mean = 75 G-mean = 90</p><p>Improvements in relation to G Opt are marked with red color. Please refer to Table 1 for the meaning of the row and column labels.</p><p>Table 6</p><p>Area under ROC Curve (AUC ij ) Results for Pairwise Classification</p><p>G Opt F N T TA TR N T TA TR T 79 100 TA 93 78 100 81 TR 95 75 83 99 81 88 TAR 87 75 81 72 100 87 96 82</p><p>Improvements in relation to G Opt are marked with red color. Please refer to Table 1 for the meaning of the row and column labels.</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/LearningFourierDescriptorsforComputerAidedDiagnosisoftheSupraspinatus/1_1s20S1076633210001868.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/LearningFourierDescriptorsforComputerAidedDiagnosisoftheSupraspinatus/1_1s20S1076633210001868.jpg" alt="Figure 3, ROC curves for the pairwise classifiers. The red curve denotes the global descriptors (G Opt ), while the blue curve denotes the proposed method (F): (a) N × T, (b) N × TA, (c) N × TR, (d) N × TAR, (e) T × TA, (f) T × TR." class="lazyload" data-proofer-ignore></a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/LearningFourierDescriptorsforComputerAidedDiagnosisoftheSupraspinatus/2_1s20S1076633210001868.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/LearningFourierDescriptorsforComputerAidedDiagnosisoftheSupraspinatus/2_1s20S1076633210001868.jpg" alt="Figure 4, Receiver operating characteristic curves for the pairwise classifiers. The red curve denotes the global descriptors (G Opt ), whereas the blue curve denotes the proposed method (F): (a) T × TAR, (b) TA × TR, (c) TA × TAR, (d) TR × TAR. T: tendon tear; TAR: tendon tear with muscle atrophy and tendon retraction; TA: tendon tear and muscle atrophy; TR: tendon tear and tendon retraction." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="multiclass-scenario-1"><span class="mr-2">Multiclass Scenario</span><a href="#multiclass-scenario-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="robustness-to-misalignments"><span class="mr-2">Robustness to Misalignments</span><a href="#robustness-to-misalignments" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/LearningFourierDescriptorsforComputerAidedDiagnosisoftheSupraspinatus/3_1s20S1076633210001868.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/LearningFourierDescriptorsforComputerAidedDiagnosisoftheSupraspinatus/3_1s20S1076633210001868.jpg" alt="Figure 5, Evaluation of the robustness of the method to misalignments in the data: the black solid line shows the average accuracy for all the pairwise classifiers, whereas the blue dotted lines show the minimum and maximum accuracy among all the pairwise classifiers. We can see that, although the accuracy generally decreases for large angles, the minimum accuracy is still higher than 75% for misalignments created with rotations of up to 10°." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="timing"><span class="mr-2">Timing</span><a href="#timing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">Discussion</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="pairwise-classification-1"><span class="mr-2">Pairwise Classification</span><a href="#pairwise-classification-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="multiclass-scenario-2"><span class="mr-2">Multiclass Scenario</span><a href="#multiclass-scenario-2" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="robustness-to-misalignments-1"><span class="mr-2">Robustness to Misalignments</span><a href="#robustness-to-misalignments-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="selected-descriptors"><span class="mr-2">Selected Descriptors</span><a href="#selected-descriptors" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="conclusion-and-future-work"><span class="mr-2">Conclusion and future work</span><a href="#conclusion-and-future-work" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Fuchs S., Chylarecki C., Langenbrinck A.: Incidence and symptoms of clinically manifest rotator cuff lesions. Int J Sports Med 1999; 20: pp. 201-205.</p><li><p>2. Lehman C., Cuomo F., Kummer F.J., et. al.: The incidence of full thickness rotator cuff tears in a large cadaveric population. Bull Hosp Jt Dis 1995; 54: pp. 30-31.</p><li><p>3. Zanetti M., Gerber C., Hodler J.: Quantitative assessment of the muscles of the rotator cuff with magnetic resonance imaging. Invest Radiol 1998; 33: pp. 163-170.</p><li><p>4. Morag Y., Jacobson J.A., Miller B., et. al.: MR imaging of rotator cuff injury: what the clinician needs to know. Radiographics 2006; 26: pp. 1045-1065.</p><li><p>5. Ward A., Hamarneh G., Ashry R., et. al.: 3D shape analysis of the supraspinatus muscle: a clinical study of the relationship between shape and pathology. Acad Radiol 2007; 14: pp. 1229-1241.</p><li><p>6. Ashburner J., Csernansk J.G., Davatzikos C., et. al.: Computer-assisted imaging to assess brain structure in healthy and diseased brains. Lancet Neurol 2003; 2: pp. 79-88.</p><li><p>7. Wang L., Swank J.S., Glick I.E., et. al.: Changes in hippocampal volume and shape across time distinguish dementia of the Alzheimer type from healthy aging. NeuroImage 2003; 20: pp. 667-682.</p><li><p>8. Gutman B., Wang Y., Lui L.M., et. al.: Hippocampal surface analysis using spherical harmonic function applied to surface conformal mapping. Int Conf Pattern Recognition 2006; 3: pp. 964-967.</p><li><p>9. Chung M.K., Nacewicz B.M., Wang S., et. al.: Amygdala surface modeling with weighted spherical harmonics. Lect Notes Computer Sci 2008; 5128: pp. 177-184.</p><li><p>10. Nain D., Styner M., Niethammer M., et. al.: Statistical shape analysis of brain structures using spherical wavelets. Int Symp Biomed Imaging 2007; 1: pp. 209-212.</p><li><p>11. Wang S., Chung M.K., Dalton K.M., et. al.: Automated diagnosis of autism using Fourier series expansion of corpus callosum boundary. Human Brain Mapping Conf 2007; 1:</p><li><p>12. Chen S.Y.Y., Lestrel P.E., Kerr W.J.S., et. al.: Describing shape changes in the human mandible using elliptical Fourier functions. Eur J Orthodont 2000; 22: pp. 205-216.</p><li><p>13. Tsai A., Wells W.M., Warfield S.K., et. al.: An EM algorithm for shape classification based on level sets. Med Image Anal 2005; 9: pp. 491-502.</p><li><p>14. Heimann T., Meinzer H.- P.: Statistical shape models for 3D medical image segmentation: a review. Med Image Anal 2009; 13: pp. 543-563.</p><li><p>15. Gotsman C., Gu X., Sheffer A.: Fundamentals of spherical parameterization for 3D meshes. ACM Trans Graphics (Proc. SIGGRAPH) 2003; 22: pp. 358-363.</p><li><p>16. Staib H., Duncan J.S.: Boundary finding with parametrically deformable models. Trans Patt Anal Machine Intell 1992; 14: pp. 1061-1075.</p><li><p>17. Hamarneh G., Gustavsson T.: Statistically constrained snake deformations. Proc Int Conf Syst Man Cybernetics 2000; 3: pp. 1610-1615.</p><li><p>18. Lehtinen J.T., Tingart M.J., Apreleva M., et. al.: Practical assessment of rotator cuff muscle volumes using shoulder MI. Acta Orthop Scand 2003; 74: pp. 722-729.</p><li><p>19. Tingart M.J., Apreleva M., Lehtinen J.T., et. al.: Shoulder magnetic resonance imaging in quantitative analysis of rotator cuff muscle volume. Clin Orthopaed Related Res 2003; 415: pp. 104-110.</p><li><p>20. Robertson P.L., Schweitzer M.E., Mitchell D.G., et. al.: Rotator cuff disorders: Interobserver and intraobserver variation in diagnosis with MR imaging. Radiology 1995; 194: pp. 831-835.</p><li><p>21. Turk G., O’Brien J.F.: Shape transformation using variational implicit functions. Proc ACM SIGGRAPH 1999; 1: pp. 335-342.</p><li><p>22. Wu T.-F., Lin C.-J., Weng R.C.: Probability estimates for multi-class classification by pairwise coupling. J Machine Learn Res 2004; 5: pp. 975-1005.</p><li><p>23. Guyon I., Elisseeff A.: An introduction to variable and feature selection. J Machine Learn Res 2003; 3: pp. 1157-1182.</p><li><p>24. Vapnik V.: Statistical Learning Theory.1998.WileyNew York</p><li><p>25. Sun Y., Kamel M.S., Wang Y., et. al.: Boosting for learning multiple classes with imbalanced class distribution. Proc. Int Conf Data Mining 2006; 1: pp. 592-602.</p><li><p>26. Fawcett T.: An introduction to ROC analysis. Pattern Recognit Lett 2006; 27: pp. 861-874.</p><li><p>27. Sokolova M.: Assessing invariance properties of evaluation measures. Proc NIPS Workshop on Testing Deployable Learning and Decision Systems 2006;</p><li><p>28. Skurichina M., Verzakov S., Paclik P., et. al.: Effectiveness of spectral band selection/extraction techniques for spectral data. Lecture Notes Computer Sci 2006; 4109: pp. 541-550.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-17/'>Volume 17</a>, <a href='/categories/issue-8/'>Issue 8</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Learning%20Fourier%20Descriptors%20for%20Computer-Aided%20Diagnosis%20of%20the%20Supraspinatus%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Flearning-fourier-descriptors-for-computer-aided-diagnosis-of-the-supraspinatus%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Learning%20Fourier%20Descriptors%20for%20Computer-Aided%20Diagnosis%20of%20the%20Supraspinatus%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Flearning-fourier-descriptors-for-computer-aided-diagnosis-of-the-supraspinatus%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Flearning-fourier-descriptors-for-computer-aided-diagnosis-of-the-supraspinatus%2F&text=Learning%20Fourier%20Descriptors%20for%20Computer-Aided%20Diagnosis%20of%20the%20Supraspinatus%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/cade-prompts-and-observer-performance/"><div class="card-body"> <em class="small" data-ts="1280595600" data-df="ll" > Jul 31, 2010 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CADe Prompts and Observer Performance</h3><div class="text-muted small"><p> In computed tomographic (CT) colonography, also known as virtual colonoscopy, patients are typically scanned in two positions . By comparing the two CT scans, radiologists can maximize the visible ...</p></div></div></a></div><div class="card"> <a href="/posts/ct-colonography-computer-aided-polyp-detection/"><div class="card-body"> <em class="small" data-ts="1280595600" data-df="ll" > Jul 31, 2010 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CT Colonography Computer-Aided Polyp Detection</h3><div class="text-muted small"><p> Rationale and Objectives To determine whether the display of computer-aided detection (CAD) marks on individual polyps on both the supine and prone scans leads to improved polyp detection by radio...</p></div></div></a></div><div class="card"> <a href="/posts/curriculum-development-for-medical-education-a-six-step-approach-2nd-edition/"><div class="card-body"> <em class="small" data-ts="1280595600" data-df="ll" > Jul 31, 2010 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Curriculum Development For Medical Education A Six-Step Approach, 2nd Edition</h3><div class="text-muted small"><p> The second edition of The Johns Hopkins University Press’s outstanding book Curriculum Development for Medical Education: A Six-Step Approach is a tour-de-force and a voyage of discovery, and I ver...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/home-sweet-home/" class="btn btn-outline-primary" prompt="Older"><p>Home Sweet Home</p></a> <a href="/posts/musculoskeletal-trauma-simplified-a-casebook-to-aid-diagnosis-management/" class="btn btn-outline-primary" prompt="Newer"><p>Musculoskeletal Trauma Simplified A Casebook To Aid Diagnosis & Management</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

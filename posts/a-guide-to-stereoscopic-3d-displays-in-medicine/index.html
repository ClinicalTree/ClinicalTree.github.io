<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="A Guide to Stereoscopic 3D Displays in Medicine" /><meta property="og:locale" content="en" /><meta name="description" content="Stereoscopic displays can potentially improve many aspects of medicine. However, weighing the advantages and disadvantages of such displays remains difficult, and more insight is needed to evaluate whether stereoscopic displays are worth adopting. In this article, we begin with a review of monocular and binocular depth cues. We then apply this knowledge to examine how stereoscopic displays can potentially benefit diagnostic imaging, medical training, and surgery. It is apparent that the binocular depth information afforded by stereo displays 1) aid the detection of diagnostically relevant shapes, orientations, and positions of anatomical features, especially when monocular cues are absent or unreliable; 2) help novice surgeons orient themselves in the surgical landscape and perform complicated tasks; and 3) improve the three-dimensional anatomical understanding of students with low visual-spatial skills. The drawbacks of stereo displays are also discussed, including extra eyewear, potential three-dimensional misperceptions, and the hurdle of overcoming familiarity with existing techniques. Finally, we list suggested guidelines for the optimal use of stereo displays. We provide a concise guide for medical practitioners who want to assess the potential benefits of stereo displays before adopting them." /><meta property="og:description" content="Stereoscopic displays can potentially improve many aspects of medicine. However, weighing the advantages and disadvantages of such displays remains difficult, and more insight is needed to evaluate whether stereoscopic displays are worth adopting. In this article, we begin with a review of monocular and binocular depth cues. We then apply this knowledge to examine how stereoscopic displays can potentially benefit diagnostic imaging, medical training, and surgery. It is apparent that the binocular depth information afforded by stereo displays 1) aid the detection of diagnostically relevant shapes, orientations, and positions of anatomical features, especially when monocular cues are absent or unreliable; 2) help novice surgeons orient themselves in the surgical landscape and perform complicated tasks; and 3) improve the three-dimensional anatomical understanding of students with low visual-spatial skills. The drawbacks of stereo displays are also discussed, including extra eyewear, potential three-dimensional misperceptions, and the hurdle of overcoming familiarity with existing techniques. Finally, we list suggested guidelines for the optimal use of stereo displays. We provide a concise guide for medical practitioners who want to assess the potential benefits of stereo displays before adopting them." /><link rel="canonical" href="https://clinicaltree.github.io/posts/a-guide-to-stereoscopic-3d-displays-in-medicine/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/a-guide-to-stereoscopic-3d-displays-in-medicine/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2011-07-31T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="A Guide to Stereoscopic 3D Displays in Medicine" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-10T02:43:55+00:00","datePublished":"2011-07-31T17:00:00+00:00","description":"Stereoscopic displays can potentially improve many aspects of medicine. However, weighing the advantages and disadvantages of such displays remains difficult, and more insight is needed to evaluate whether stereoscopic displays are worth adopting. In this article, we begin with a review of monocular and binocular depth cues. We then apply this knowledge to examine how stereoscopic displays can potentially benefit diagnostic imaging, medical training, and surgery. It is apparent that the binocular depth information afforded by stereo displays 1) aid the detection of diagnostically relevant shapes, orientations, and positions of anatomical features, especially when monocular cues are absent or unreliable; 2) help novice surgeons orient themselves in the surgical landscape and perform complicated tasks; and 3) improve the three-dimensional anatomical understanding of students with low visual-spatial skills. The drawbacks of stereo displays are also discussed, including extra eyewear, potential three-dimensional misperceptions, and the hurdle of overcoming familiarity with existing techniques. Finally, we list suggested guidelines for the optimal use of stereo displays. We provide a concise guide for medical practitioners who want to assess the potential benefits of stereo displays before adopting them.","headline":"A Guide to Stereoscopic 3D Displays in Medicine","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/a-guide-to-stereoscopic-3d-displays-in-medicine/"},"url":"https://clinicaltree.github.io/posts/a-guide-to-stereoscopic-3d-displays-in-medicine/"}</script><title>A Guide to Stereoscopic 3D Displays in Medicine | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>A Guide to Stereoscopic 3D Displays in Medicine</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>A Guide to Stereoscopic 3D Displays in Medicine</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1312131600" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jul 31, 2011 </em> </span> <span> Updated <em class="" data-ts="1681094635" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 10, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Robert T. Held PhD</a> </em>, <em> <a href="">Tiffany T. Hui BS</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3836 words"> <em>21 min</em> read</span></div></div></div><div class="post-content"><p>Stereoscopic displays can potentially improve many aspects of medicine. However, weighing the advantages and disadvantages of such displays remains difficult, and more insight is needed to evaluate whether stereoscopic displays are worth adopting. In this article, we begin with a review of monocular and binocular depth cues. We then apply this knowledge to examine how stereoscopic displays can potentially benefit diagnostic imaging, medical training, and surgery. It is apparent that the binocular depth information afforded by stereo displays 1) aid the detection of diagnostically relevant shapes, orientations, and positions of anatomical features, especially when monocular cues are absent or unreliable; 2) help novice surgeons orient themselves in the surgical landscape and perform complicated tasks; and 3) improve the three-dimensional anatomical understanding of students with low visual-spatial skills. The drawbacks of stereo displays are also discussed, including extra eyewear, potential three-dimensional misperceptions, and the hurdle of overcoming familiarity with existing techniques. Finally, we list suggested guidelines for the optimal use of stereo displays. We provide a concise guide for medical practitioners who want to assess the potential benefits of stereo displays before adopting them.</p><p>Stereoscopic displays can be found in applications ranging from cinema to medical imaging to scientific visualization . Because these displays can convey more accurate depth information than nonstereo displays, they can potentially benefit several aspects of image-based medicine. In particular, stereo imaging could 1) make complicated shapes and structures easier to identify, 2) aid the user in assessing large data sets, and 3) through its integration in virtual-reality modules, decrease the cost of training and health care in general. However, the technology has drawbacks, including equipment complexity and the current necessity for eyewear. Stereo displays therefore must demonstrate a clear advantage over existing techniques if they are to be widely adopted. We provide a resource for evaluating and implementing stereo displays for a wide range of medical applications. We begin by discussing the unique visual cues afforded by stereoscopic displays. We then discuss the specific advantages and disadvantages of existing medical applications of stereo displays, and possible reasons why it has not been adopted more widely. The general advantages and disadvantages are also summarized, followed by tips for the optimal use of stereo displays to help avoid misperceptions and visual fatigue.</p><h2 id="depth-and-displays"><span class="mr-2">Depth and displays</span><a href="#depth-and-displays" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>All stereo displays operate on the same basic mechanism: a unique image is presented to each eye. The differences between the images (known as a stereo pair) are interpreted by the visual system as depth information in a process known as stereopsis. The relative positions of an object’s projections onto the two retinas are used by the visual system to recover the distance to that object . Stereopsis is not the only source of depth information in typical images. In fact, the name three-dimensional (3D) display is a misnomer because images have always conveyed 3D information. The key distinction in 3D displays is that they provide stereoscopic depth information in addition to the monocular depth cues attainable with any display. Therefore, for the remainder of this review we will use the term <em>stereoscopic display</em> or <em>stereo display</em> in place of the more common <em>3D display</em> .</p><p>To differentiate between stereoscopic and conventional displays, we begin with a discussion of the visual depth cues afforded by each technology.</p><h2 id="monocular-depth-cues"><span class="mr-2">Monocular Depth Cues</span><a href="#monocular-depth-cues" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Any conventional display can present monocular depth cues. These are cues to depth that are useful to the visual system, even if they are acquired by only one eye. The depth cues most relevant to our discussion are perspective projection, occlusion, familiar size, shading, and the motion-based cues known as structure from motion and motion parallax.</p><p>“Perspective projection,” or how a 3D scene is projected onto a two-dimensional (2D) image plane, offers several depth cues. Objects that are farther away from the imaging device are projected to smaller sizes than objects that are close. Parallel lines that recede into the scene (such as the lines on a road) project to converging lines in an image. Portions of the parallel lines that are spaced farther apart on the image surface are closer to the observer than portions that are spaced closer together. This phenomenon is evident with the parallel lines on the wall in the right-hand portion of Figure 1 . Perspective projection also produces texture gradients. Texture patches, like those that make up wallpaper, will project to have larger and more widely spaced elements on the image when they are closer to the imaging device. The orientation of texture elements can also reveal 3D shape .</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/0_1s20S1076633211002030.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/0_1s20S1076633211002030.jpg" alt="Figure 1, Several examples of monocular depth cues. Perspective projection causes the more distance supports in the handrail on the right side of the image to project to smaller sizes in the image. Occlusions make it obvious that the tractor is closer to the camera than the board that it is partially blocking from view. Shadows reveal the three-dimensional shape of the shovel on the front of the tractor. Familiar size also makes it possible to estimate the relative distances to the red car and the people in the scene." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="stereoscopic-depth"><span class="mr-2">Stereoscopic Depth</span><a href="#stereoscopic-depth" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/1_1s20S1076633211002030.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/1_1s20S1076633211002030.jpg" alt="Figure 2, Stereogram of a field of dots with floating patches. To view the stereogram, hold the page at arm’s length and either (a) cross your eyes so the left eye is directed at the left image and the right eye is directed at the middle image ( divergent fusing ), or (b) point the left eye at the right image and the right eye at the middle image ( cross fusing ). In both cases, once fusion is attained, four images will be visible. With divergent fusing, attend to the image second from the left. With cross fusing, attend to the image second from the right. Without fusing the images, it is impossible to tell which of the patches is closer. However, once the images are fused, their depth ordering becomes apparent, as well as the three-dimensional positions of the random dots." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="stereo-imaging-and-virtual-reality"><span class="mr-2">Stereo Imaging and Virtual Reality</span><a href="#stereo-imaging-and-virtual-reality" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="medical-applications-of-stereo-displays"><span class="mr-2">Medical applications of stereo displays</span><a href="#medical-applications-of-stereo-displays" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="diagnostics"><span class="mr-2">Diagnostics</span><a href="#diagnostics" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="ophthalmic-imaging"><span class="mr-2">Ophthalmic imaging</span><a href="#ophthalmic-imaging" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="mammography"><span class="mr-2">Mammography</span><a href="#mammography" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/2_1s20S1076633211002030.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/2_1s20S1076633211002030.jpg" alt="Figure 3, Example mammography stereogram. See viewing instructions from Figure 2 . Viewed individually, the images in each panel do not provide depth information. But viewed stereoscopically, the three-dimensional (3D) structure of the tissue becomes apparent, including the location of the mass on the left side. Reproduced from Getty D &amp; Green P, “Clinical applications for stereoscopic 3D displays”, published in the Journal of the Society for Information Display, Vol. 15, No. 6, with permissions by the authors and The Society for Information Display." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="vascular-imaging"><span class="mr-2">Vascular imaging</span><a href="#vascular-imaging" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/3_1s20S1076633211002030.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/3_1s20S1076633211002030.jpg" alt="Figure 4, Example angiographic stereogram. The connectedness and depth ordering of the vessels are most easily understood under stereoscopic viewing. Images courtesy of Maksim Shapiro ( http://neuroangio.org )." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="orthopedic-imaging"><span class="mr-2">Orthopedic imaging</span><a href="#orthopedic-imaging" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="medical-training"><span class="mr-2">Medical Training</span><a href="#medical-training" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/4_1s20S1076633211002030.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/4_1s20S1076633211002030.jpg" alt="Figure 5, Example image from stereoscopic laparoscopy. The lack of strong perspective cues like straight lines and right angles and unfamiliar lighting makes it difficult to recover three-dimensional shape information from a single image. When viewed stereoscopically, however, the tissues’ shapes become evident. In particular, note how the thin flap of tissue is perceived as more separated from the background during stereoscopic viewing. Images courtesy of Peter Mountney and colleagues (94) ." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="surgical-planning"><span class="mr-2">Surgical Planning</span><a href="#surgical-planning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="laparoscopy"><span class="mr-2">Laparoscopy</span><a href="#laparoscopy" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="telesurgery"><span class="mr-2">Telesurgery</span><a href="#telesurgery" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="augmented-reality-surgery"><span class="mr-2">Augmented Reality Surgery</span><a href="#augmented-reality-surgery" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/5_1s20S1076633211002030.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/5_1s20S1076633211002030.jpg" alt="Figure 6, Stereogram of an augmented reality system in use on a surgical phantom. The overlaid computer-generated imagery provides a virtual view directly into the surgical site. Note that the use of stereo imagery more convincingly makes the overlaid graphic appear to be a hole, rather than a texture projected onto the surface of the phantom. Images are from Figure 5 of Fuchs H et al. “Augmented reality visualization for laparoscopic surgery,” in the Proceedings of the First International Conference on Medical Image Computing and Computer-Assisted Intervention, Vol. 1496. Copyright Springer-Verlag Berlin Heidelberg (1998) and appears with kind permission from Henry Fuchs and Springer Science+Business Media B.V." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="summary-of-benefits"><span class="mr-2">Summary of benefits</span><a href="#summary-of-benefits" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="summary-of-drawbacks"><span class="mr-2">Summary of drawbacks</span><a href="#summary-of-drawbacks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="hardware"><span class="mr-2">Hardware</span><a href="#hardware" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="resistance-to-new-technology"><span class="mr-2">Resistance to New Technology</span><a href="#resistance-to-new-technology" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="lost-detail-from-slice-data"><span class="mr-2">Lost Detail from Slice Data</span><a href="#lost-detail-from-slice-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="viewer-discomfort"><span class="mr-2">Viewer Discomfort</span><a href="#viewer-discomfort" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/6_1s20S1076633211002030.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/6_1s20S1076633211002030.jpg" alt="Figure 7, Variations in vergence and accommodation with natural viewing and typical stereoscopic displays. (a) The eyes’ vergence and accommodative states are coupled in natural viewing. Here, vergence and accommodation are both set to the far corner of an open-hinge stimulus. The light from the edges of the hinge are physically closer to the eyes than the far corner, so they appear out of focus. (b) On a typical stereo display, vergence and accommodation are uncoupled. Vergence can vary through the three-dimensional scene (here it is trained on the corner of the hinge), but accommodation must remain fixed on the surface of the display to keep the image sharp. Note that the entire hinge is imaged sharply, because all of the light is originating at the surface of the display. The mismatch between the vergence and accommodative states of the eyes has been proven to be a source of discomfort and fatigue with stereoscopic displays. (c) Partially blurred retinal image. (d) Completely sharp retinal image. Figure adapted with permission from David Hoffman and colleagues (79) ." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="stereoscopic-misperceptions"><span class="mr-2">Stereoscopic Misperceptions</span><a href="#stereoscopic-misperceptions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/7_1s20S1076633211002030.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/7_1s20S1076633211002030.jpg" alt="Figure 8, Common distortions with stereoscopic displays. (a) A viewer at the correct viewing location, observing a stereoscopic image of a 3D cross-section of a human skull. Because the observer is in the correct location, he or she correctly perceives the shape of the skull. However, sitting too far (b) or too close (c) to the display causes the perceived shape to expand or compress, respectively. Stereoscopic viewing software sometimes allows one to adjust the spacing between the left and right images. But (d) shows how increasing the spacing can expand objects in depth and move them farther away. Finally, (e) depicts how 3D shapes shift and shear as the observer moves to the left and right of the optimal viewing location. See the section Avoiding Stereoscopic Misperceptions with Stereoscopic Displays for tips on avoiding such misperceptions. Skull model created by W.E. Lorenson (95) , based on data from the Visible Human Project (96) ." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="avoiding-misperceptions-with-stereoscopic-displays"><span class="mr-2">Avoiding misperceptions with stereoscopic displays</span><a href="#avoiding-misperceptions-with-stereoscopic-displays" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/8_1s20S1076633211002030.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AGuidetoStereoscopic3DDisplaysinMedicine/8_1s20S1076633211002030.jpg" alt="Figure 9, The keystone effect. When the bodies of a pair of stereo cameras are set to converge, vertical magnification of the two images’ projections vary with horizontal position. The mismatch causes regions of misalignment and can produce misperceptions." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="tips-and-guidelines"><span class="mr-2">Tips and guidelines</span><a href="#tips-and-guidelines" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="tip-1-parallel-cameras"><span class="mr-2">Tip 1: Parallel Cameras</span><a href="#tip-1-parallel-cameras" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="tip-2-do-not-flip-images"><span class="mr-2">Tip 2: Do Not Flip Images</span><a href="#tip-2-do-not-flip-images" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="tip-3-keep-eyes-centered-and-parallel-relative-to-display"><span class="mr-2">Tip 3: Keep Eyes Centered and Parallel Relative to Display</span><a href="#tip-3-keep-eyes-centered-and-parallel-relative-to-display" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="tip-4-minimize-vergence-accommodation-conflict"><span class="mr-2">Tip 4: Minimize Vergence-accommodation Conflict</span><a href="#tip-4-minimize-vergence-accommodation-conflict" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="tip-5-appropriate-use-of-pictorial-blur"><span class="mr-2">Tip 5: Appropriate Use of Pictorial Blur</span><a href="#tip-5-appropriate-use-of-pictorial-blur" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="conclusions"><span class="mr-2">Conclusions</span><a href="#conclusions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="acknowledgment"><span class="mr-2">Acknowledgment</span><a href="#acknowledgment" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Lipton L.: Foundations of the stereoscopic cinema: a study in depth.1982.Van Nostrand ReinholdNew York, NY</p><li><p>2. Chan H.P., Goodsitt M.M., Helvie M.A., et. al.: ROC study of the effect of stereoscopic imaging on assessment of breast lesions. Med Phys 2005; 32: pp. 1001-1009.</p><li><p>3. Fröhlich B., Barrass S., Zehner B., et. al.: Exploring geo-scientific data in virtual environments. In: VIS ’99: Proceedings of the conference on Visualization ’99.1999.IEEE Computer Society PressLos Alamitos, CA, USA p. 169–173</p><li><p>4. Palmer S.: Vision science: from photos to phenomenology.1999.MIT PressCambridge, MA</p><li><p>5. Sun J., Perona P.: Where is the sun?. Nat Neurosci 1998; 1: pp. 183-184.</p><li><p>6. O’Shea JP, Banks MS, Agrawala M. The assumed light direction for perceiving shape from shading. In: APGV ’08: Proceedings of the 5th symposium on Applied perception in graphics and visualization. New York, NY. p. 135–142.</p><li><p>7. Simons K.: Stereoacuity norms in young children. Arch Ophthalmol-Chic 1981; 99: pp. 439-445.</p><li><p>8. Ahmed J., Ward T., Bursell S., et. al.: The sensitivity and specificity of nonmydriatic digital stereoscopic retinal imaging in detecting diabetic retinopathy. Diabetes Care 2006; 29: pp. 2205-2209.</p><li><p>9. Abramoff M., Alward W., Greenlee , et. al.: Automated segmentation of the optic disc from stereo color photographs using physiologically plausible features. Invest Ophthalmol Vis Sci 2007; 48: pp. 1665-1673.</p><li><p>10. Bergua A., Mardin C.Y., Horn F.K.: Tele-transmission of stereoscopic images of the optic nerve head in glaucoma via internet. Telemed e-Health 2009; 15: pp. 439-444.</p><li><p>11. Getty D., D’Orsi C., Pickett R.: Stereoscopic digital mammography: Improved accuracy of lesion detection in breast cancer screening. Lecture Notes Comp Sci 2008; 5116: pp. 74-79.</p><li><p>12. Hernandez A., Basset O., Bremond A., et. al.: Stereoscopic visualization of three-dimensional ultrasonic data applied to breast tumours. Eur J ultrasound 1998; 8: pp. 51-65.</p><li><p>13. Tanaka C., Fujii H., Ikeda T., et. al.: Stereoscopic scintigraphic imaging of breast cancer sentinel lymph nodes. Breast Cancer 2007; 14: pp. 92-99.</p><li><p>14. Nelson T., Ji E., Lee J., et. al.: Stereoscopic evaluation of fetal bony structures. J Ultrasound Med 2008; 27: pp. 15-24.</p><li><p>15. Sollenberger R., Milgram P.: Effects of stereoscopic and rotational displays in a three-dimensional path-tracing task. Human Factors J Human Factors Ergon Soc 1993; 3: pp. 483-499.</p><li><p>16. Serra L, Hern N, Choon C, et al. Interactive vessel tracing in volume data. SI3D ’97: Proceedings of the 1997 Symposium on Interactive 3D graphics 1997.</p><li><p>17. Sun Z., Squelch A., Bartlett A., et. al.: 3D stereoscopic visualization of fenestrated stent grafts. Cardiovasc Intervent Radiol 2009; 32: pp. 1053-1058.</p><li><p>18. Zhou L., Wang Y., Goh L., et. al.: Stereoscopic visualization and editing of automatic abdominal aortic aneurysms (AAA) measurements for stent graft planning. Proc SPIE 2006; 6055: pp. 57-65.</p><li><p>19. Sun Z., Lawrence-Brown M.: CT virtual endoscopy and 3D stereoscopic visualisation in the evaluation of coronary stenting. Biomed Imaging Intervention J 2009; 5: pp. 1-6.</p><li><p>20. Moll T., Douek P., Finet G., et. al.: Clinical assessment of a new stereoscopic digital angiography system. Cardiovasc Intervent Radiol 1998; 21: pp. 11-16.</p><li><p>21. Sekiguchi R., Satake M., Oyama H., et. al.: Stereoscopic visualization system for clinical angiography. Studies Health Technol Informatics 1996; 29: pp. 690-693.</p><li><p>22. Kickuth R., Hartung G., Laufer U., et. al.: Stereoscopic 3D CT vs standard 3D CT in the classification of acetabular fractures: an experimental study. Br J Radiol 2002; 75: pp. 422.</p><li><p>23. Luursema J., Verwey W., Kommers P., et. al.: Optimizing conditions for computer-assisted anatomical learning. Interacting Computers 2006; 18: pp. 1123-1138.</p><li><p>24. Nicholson D., Chalk C., Funnell W., et. al.: Can virtual reality improve anatomy education? A randomised controlled study of a computer-generated three-dimensional anatomical ear model. Med Educ 2006; 40: pp. 1081.</p><li><p>25. Luursema J., Verwey W., Kommers P., et. al.: The role of stereopsis in virtual anatomical learning. Interacting Computers 2008; 20: pp. 455-460.</p><li><p>26. Tendick F., Downes M., Cavusoglu M., et. al.: Development of virtual environments for training skills and reducing errors in laparoscopic surgery. Proc SPIE Int Symp Biol Optics (BIOS’98) 1998; pp. 36-44.</p><li><p>27. Wong G., Zhu C., Ahuja A., et. al.: Craniotomy and clipping of intracranial aneurysm in a stereoscopic virtual reality environment. Neurosurgery 2007; 61: pp. 564.</p><li><p>28. Pieper S., Delp S., Rosen J., et. al.: Virtual environment system for simulation of leg surgery. Pro SPIE 1991; 1457: pp. 188.</p><li><p>29. Tuggy M.L.: Virtual reality flexible sigmoidoscopy simulator training: impact on resident performance. J Amer Bd Family Practice/Amer Bd Family Practice 1998; 11: pp. 426-433.</p><li><p>30. Taffinder N., Smith S.G., Huber J., et. al.: The effect of a second-generation 3D endoscope on the laparoscopic precision of novices and experienced surgeons. Surg Endosc 1999; 13: pp. 1087-1092.</p><li><p>31. Patel H., Ribal M., Arya M., et. al.: Is it worth revisiting laparoscopic three-dimensional visualization? A validated assessment. Urology 2007; 70: pp. 47-49.</p><li><p>32. Tevaearai H.T., Mueller X.M., von Segesser L.K.: 3-D vision improves performance in a pelvic trainer. Endoscopy 2000; 32: pp. 464-468.</p><li><p>33. Ilgner J., Park J., Labbé D., et. al.: Using a high-definition stereoscopic video system to teach microscopic surgery. Proc SPIE-IS&amp;T Electron Imaging 2007; 6490: pp. 81-87.</p><li><p>34. Prystowsky J., Regehr G., Rogers D., et. al.: A virtual reality module for intravenous catheter placement. Am J Surg 1999; 177: pp. 171-175.</p><li><p>35. Johnson W., Rickel J., Stiles R., et. al.: Integrating pedagogical agents into virtual environments. Presence 1998; 7: pp. 523-546.</p><li><p>36. Hu Y. The role of three-dimensional visualization in surgical planning of treating lung cancer. Engineering in Medicine and Biology Society, 2005 IEEE-EMBS 2005 27th Annual International Conference of the 2005; 646–649.</p><li><p>37. Fishman E., Kuszyk B., Heath D., et. al.: Surgical planning for liver resection. Computer 1996; 29: pp. 64-72.</p><li><p>38. Wigmore S., Redhead D., Yan X., et. al.: Virtual hepatic resection using three-dimensional reconstruction of helical computed tomography angioportograms. Ann Surg 2001; 23: pp. 221-226.</p><li><p>39. Hemminger B.M., Molina P.L., Egan T.M., et. al.: Assessment of real-time 3D visualization for cardiothoracic diagnostic evaluation and surgery planning. J Digital Imaging 2005; 18: pp. 145-153.</p><li><p>40. Lee S., Shinohara H., Matsuki M., et. al.: Preoperative simulation of vascular anatomy by three-dimensional computed tomography imaging in laparoscopic gastric cancer surgery. J Amer Coll Surg 2003; 197: pp. 927-936.</p><li><p>41. Xia J., Ip H.H., Samman N., et. al.: Computer-assisted three-dimensional surgical planning and simulation: 3D virtual osteotomy. Int J Oral Maxillofacial Surg 2000; 29: pp. 11-17.</p><li><p>42. Kikinis R., Gleason P., Moriarty T., et. al.: Computer-assisted interactive three-dimensional planning for neurosurgical procedures. Neurosurgery 1996; 38: pp. 640-651.</p><li><p>43. Gering D., Nabavi A., Kikinis R., et. al.: An integrated visualization system for surgical planning and guidance using image fusion and interventional imaging. J Magnetic Reson Imaging 2001; 13: pp. 967-975.</p><li><p>44. Kockro R., Serra L., Tseng-Tsai Y., et. al.: Planning and simulation of neurosurgery in a virtual reality environment. Neurosurgery 2000; 46: pp. 118-135.</p><li><p>45. Hernes T., Ommedal S., Lie T.: Stereoscopic navigation-controlled display of preoperative MRI and intraoperative 3D ultrasound in planning and guidance of neurosurgery: new technology for minimally invasive image-guided surgery approaches. Minim Invasive Neurosurg 2003; 46: pp. 129-137.</p><li><p>46. Ng I., Hwang P.Y.K., Kumar D., et. al.: Surgical planning for microsurgical excision of cerebral arterio-venous malformations using virtual reality technology. Acta Neurochir 2009; 151: pp. 453-463.</p><li><p>47. Rosahl S., Gharabaghi A., Hubbe U., et. al.: Virtual reality augmentation in skull base surgery. Skull Base 2006; 16: pp. 59-66.</p><li><p>48. Burt D.: Virtual reality in anaesthesia. Br J Anaesth 1995; 75: pp. 472-480.</p><li><p>49. Tendick F., Downes M., Goktekin T., et. al.: A virtual environment testbed for training laparoscopic surgical skills. Presence: Teleoperators &amp; Virtual Environments 2000; 9: pp. 236-255.</p><li><p>50. Hofmeister J., Frank T., Cuschieri A., et. al.: Perceptual aspects of two-dimensional and stereoscopic display techniques in endoscopic surgery: review and current problems. Surg Innovation 2001; 8: pp. 12-24.</p><li><p>51. Crosthwaite G., Chung T., Dunkley P., et. al.: Comparison of direct vision and electronic two-and three-dimensional display systems on surgical task efficiency in endoscopic surgery. Brit J Surg 1995; 82: pp. 849-851.</p><li><p>52. Hanna G., Shimi S., Cuschieri A.: Randomised study of influence of two-dimensional versus three-dimensional imaging on performance of laparoscopic cholecystectomy. Lancet 1998; 351: pp. 248-251.</p><li><p>53. McDougall E.M., Soble J.J., Wolf J.S., et. al.: Comparison of three-dimensional and two-dimensional laparoscopic video systems. J Endourol 1996; 10: pp. 371-374.</p><li><p>54. Blavier A., Nyssen A.S.: Influence of 2D and 3D view on performance and time estimation in minimal invasive surgery. Ergonomics 2009; 52: pp. 1342-1349.</p><li><p>55. Mueller-Richter U., Limberger A., Weber P.: Comparison between three-dimensional presentation of endoscopic procedures with polarization glasses and an autostereoscopic display. Surg Endosc 2003; 17: pp. 1432-2218.</p><li><p>56. Jourdan I., Dutson E., Garcia A., et. al.: Stereoscopic vision provides a significant advantage for precision robotic laparoscopy. Br J Surg 2004; 91: pp. 879-885.</p><li><p>57. Pietrabissa A., Scarcello E., Carobbi A., et. al.: Three-dimensional versus two-dimensional video system for the trained endoscopic surgeon and the beginner. Endoscopic Surg Allied Technol 1994; 2: pp. 315-317.</p><li><p>58. Blavier A., Gaudissart Q., Cadiere G., et. al.: Impact of 2D and 3D vision on performance of novice subjects using da Vinci robotic system. Acta Chir Belgica 2006; 106: pp. 662-664.</p><li><p>59. Byrn J., Schluender S., Divino C., et. al.: Three-dimensional imaging improves surgical performance for both novice and experienced operators using the da Vinci robot system. The Amer J Surg 2007; 193: pp. 519-522.</p><li><p>60. Maurer C.J., Sauer F., Hu B., et. al.: Augmented reality visualization of brain structures with stereo and kinetic depth cues: system description and initial evaluation with head phantom. Proc SPIE: Medical Imaging 2001; 6: pp. 445-456.</p><li><p>61. Nikou C., Digioia A., Blackwell M., et. al.: Augmented reality imaging technology for orthopaedic surgery. Operative Techniques Orthopaed 2000; 10: pp. 82-86.</p><li><p>62. Wendt M., Sauer F., Khamene A., et. al.: A head-mounted display system for augmented reality: Initial evaluation for interventional MRI. RöFo Fortschr Geb Rontgenstr Neuen Bildgeb Verfahr 2003; 3: pp. 418-421.</p><li><p>63. Rosenthal M., State A., Lee J., et. al.: Augmented reality guidance for needle biopsies: an initial randomized, controlled trial in phantoms. Med Image Anal 2002; 6: pp. 313-320.</p><li><p>64. Wacker F., Vogt S., Khamene A., et. al.: An augmented reality system for MR image-guided needle biopsy: initial results in a swine model. Radiology 2006; 238: pp. 497-504.</p><li><p>65. Edwards P., Johnson L., Hawkes D., et. al.: Clinical experience and perception in stereo augmented reality surgical navigation. Proc Intl Workshop on Med Imaging and Augmented Reality 2004; 3150: pp. 369-376.</p><li><p>66. Bajura M, Fuchs H, Ohbuchi R. Merging virtual objects with the real world: seeing ultrasound imagery within the patient. Proc 19th Annu Conference on Computer Graphics and Interactive Techniques 1992; 203–210.</p><li><p>67. Fuchs H, Livingston M, Raskar R, et al. Augmented reality visualization for laparoscopic surgery. Proc First Intl Conf on Medical Image Computing and Computer-Assisted Intervention 1998; 934–943.</p><li><p>68. Zhai S., Buxton W., Milgram P.: The partial-occlusion effect: Utilizing semitransparency in 3D human-computer interaction. ACM Transactions on Computer-Human Interaction (TOCHI) 1996; 3: pp. 254-284.</p><li><p>69. Chan H., Goodsitt M., Hadjiiski L., et. al.: Effects of magnification and zooming on depth perception in digital stereomammography: an observer performance study. Phys Med Biol 2003; 48: pp. 3721-3734.</p><li><p>70. Goodsitt M., Chan H., Hadjiiski L.: Stereomammography: evaluation of depth perception using a virtual 3d cursor. Med Phys 2000; 27: pp. 1305.</p><li><p>71. Novotny P, Kettler D, Jordan P, et al. Stereo display of 3D ultrasound images for surgical robot guidance. IEEE Intl Conf of the Engineering in Medicine and Biology Society, New York, NY 2006.</p><li><p>72. van Bergen P., Kunert W., Bessell J., et. al.: Comparative study of two-dimensional and three-dimensional vision systems for minimally invasive surgery. Surg Endosc 1998; 12: pp. 948-954.</p><li><p>73. Hu T., Allen P., Nadkarni T., et. al.: Insertable stereoscopic 3D surgical imaging device with pan and tilt. Intl J Robotics Res 2009; 28: pp. 1373-1386.</p><li><p>74. Matusik W., Pfister H.: 3D TV: a scalable system for real-time acquisition, transmission, and autostereoscopic display of dynamic scenes. ACM Transactions on Graphics 2004; 23: pp. 814-824.</p><li><p>75. Maidment A.D.A., Bakic P.R., Albert M.: Effects of quantum noise and binocular summation on dose requirements in stereoradiography. Med Phys 2003; 30: pp. 3061-3071.</p><li><p>76. Ilgner J.F.R., Kawai T., Shibata T., et. al.: Evaluation of stereoscopic medical video content on an autostereoscopic display for undergraduate medical education. Pro SPIE 2006; 6055: pp. 605506.</p><li><p>77. Lambooij M., IJsselsteijn W., Fortuin M., et. al.: Visual discomfort and visual fatigue of stereoscopic displays: a review. J Imaging Sci Technol 2009; 53: pp. 030201. p. 14</p><li><p>78. Martens T.G., Ogle K.N.: Observations on accommodative convergence; especially its nonlinear relationships. Amer J Ophthalmol 1959; 47: pp. 455-463.</p><li><p>79. Hoffman D.M., Girshick A.R., Akeley K., et. al.: Vergence-accommodation conflicts hinder visual performance and cause visual fatigue. J Vision 2008; 8: pp. 33.</p><li><p>80. Vishwanath D., Girshick A.R., Banks M.S.: Why pictures look right when viewed from the wrong place. Nature Neurosci 2005; 8: pp. 1401-1410.</p><li><p>81. Woods A.J., Docherty T., Koch R.: Image distortions in stereoscopic video systems. SPIE: Stereoscopic Displays and Applications IV 1993; 1915: pp. 36-48.</p><li><p>82. Held RT, Banks MS. Misperceptions in stereoscopic displays: a vision-science perspective. In: APGV ’08: Proceedings of the 5th Symposium on Applied Perception in Graphics and Visualization. New York, NY, 2008, p. 23–32.</p><li><p>83. Getty D., Green P.: Clinical applications for stereoscopic 3-D displays. J SID 2007; 15: pp. 377-384.</p><li><p>84. Bernstein J. The five senses of man: 91 woodcuts. London: Harry S. King &amp; Co., 1876.</p><li><p>85. Balassy C., Prokop M., Weber M., et. al.: Flat-panel display (LCD) versus high-resolution gray-scale display (CRT) for chest radiography: an observer preference study. AJR Amer J Roentgenol 2005; 184: pp. 752-756.</p><li><p>86. Pisano E.D., Seibert J.A., Andriole K.P., et. al.: Practice guideline for determinants of image quality in digital mammography.2007.American College of RadiologyReston, VA</p><li><p>87. Watt S.J., Akeley K., Ernst M.O., et. al.: Focus cues affect perceived depth. J Vis 2005; 5: pp. 834-862.</p><li><p>88. Love G., Hoffman D., Hands P., et. al.: High-speed switchable lens enables the development of a volumetric stereoscopic display. Optics Express 2009; 17: pp. 15716-15725.</p><li><p>89. Cole F., DeCarlo D., Finkelstein A., et. al.: Directing gaze in 3D models with stylized focus. Eurographics Symp Rendering 2006; pp. 377-387.</p><li><p>90. DiPaola S., Riebe C., Enns J.: Rembrandt’s textural agency: a shared perspective in visual art and science. Leonardo 2010; 4: pp. 145-151.</p><li><p>91. Hillaire S, Lécuyer A, Cozot R, et al. Depth-of-field blur effects for first-person navigation in virtual environments. In: VRST ’07: Proceedings of the 2007 ACM symposium on Virtual reality software and technology. 2007; 203–206.</p><li><p>92. Hillaire S., Lecuyer A., Cozot R., et. al.: Using an eye-tracking system to improve camera motions and depth-of-field blur effects in virtual environments. Virtual Reality Conference, 2008 VR ’08 IEEE 2008; pp. 47-50.</p><li><p>93. Held R.T., Cooper E.A., O’Brien J.F., et. al.: Using blur to affect perceived distance and size. ACM Transactions on Graphics 2010; 29: pp. 1-16.</p><li><p>94. Mountney P., Stoyanov D., Yang G.: Three-dimensional tissue deformation recovery and tracking. Signal Proc Magazine IEEE 2010; 27: pp. 14-24.</p><li><p>95. Lorensen WE. Marching through the visible man. In: Proceedings of the 6th Conference on Visualization ’95; VIS ’95. Washington, DC.</p><li><p>96. Ackerman M.: The visible human project. Proc IEEE 1998; 86: pp. 504-511.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-18/'>Volume 18</a>, <a href='/categories/issue-8/'>Issue 8</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=A%20Guide%20to%20Stereoscopic%203D%20Displays%20in%20Medicine%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fa-guide-to-stereoscopic-3d-displays-in-medicine%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=A%20Guide%20to%20Stereoscopic%203D%20Displays%20in%20Medicine%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fa-guide-to-stereoscopic-3d-displays-in-medicine%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fa-guide-to-stereoscopic-3d-displays-in-medicine%2F&text=A%20Guide%20to%20Stereoscopic%203D%20Displays%20in%20Medicine%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/a-low-tube-voltage-technique-reduces-the-radiation-dose-at-retrospective-ecg-gated-cardiac-computed/"><div class="card-body"> <em class="small" data-ts="1312131600" data-df="ll" > Jul 31, 2011 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>A Low Tube Voltage Technique Reduces the Radiation Dose at Retrospective ECG-gated Cardiac Computed Tomography for Anatomical and Functional Analyses</h3><div class="text-muted small"><p> Rationale and Objectives To investigate the effect of low-tube-voltage technique on a cardiac computed tomography (CT) for coronary arterial and cardiac functional analyses and radiation dose in s...</p></div></div></a></div><div class="card"> <a href="/posts/correlation-of-immunohistologic-and-perfusion-vascular-parameters-with-mr-contrast-enhancement-using/"><div class="card-body"> <em class="small" data-ts="1312131600" data-df="ll" > Jul 31, 2011 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Correlation of Immunohistologic and Perfusion Vascular Parameters with MR Contrast Enhancement Using Image-guided Biopsy Specimens in Gliomas</h3><div class="text-muted small"><p> Rationale and Objectives The purpose of this study was to correlate the status of magnetic resonance contrast enhancement with immunohistologic vascular parameters such as microvascular cellular p...</p></div></div></a></div><div class="card"> <a href="/posts/every-state/"><div class="card-body"> <em class="small" data-ts="1312131600" data-df="ll" > Jul 31, 2011 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Every State</h3><div class="text-muted small"><p> One of my somewhat questionable mental habits, when I am sitting somewhere without anything to read, is to make lists of some of the things I have done over the many years of my adult careers. I us...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/usefulness-of-acoustic-radiation-force-impulse-imaging-in-the-differential-diagnosis-of-benign-and-m/" class="btn btn-outline-primary" prompt="Older"><p>Usefulness of Acoustic Radiation Force Impulse Imaging in the Differential Diagnosis of Benign and Malignant Liver Lesions</p></a> <a href="/posts/a-low-tube-voltage-technique-reduces-the-radiation-dose-at-retrospective-ecg-gated-cardiac-computed/" class="btn btn-outline-primary" prompt="Newer"><p>A Low Tube Voltage Technique Reduces the Radiation Dose at Retrospective ECG-gated Cardiac Computed Tomography for Anatomical and Functional Analyses</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Automatic Segmentation and Quantitative Analysis of White Matter Hyperintensities on FLAIR Images Using Trimmed-Likelihood Estimator" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/automatic-segmentation-and-quantitative-analysis-of-white-matter-hyperintensities-on-flair-images-us/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/automatic-segmentation-and-quantitative-analysis-of-white-matter-hyperintensities-on-flair-images-us/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2014-11-30T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Automatic Segmentation and Quantitative Analysis of White Matter Hyperintensities on FLAIR Images Using Trimmed-Likelihood Estimator" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-10T02:43:55+00:00","datePublished":"2014-11-30T17:00:00+00:00","description":"Rationale and Objectives","headline":"Automatic Segmentation and Quantitative Analysis of White Matter Hyperintensities on FLAIR Images Using Trimmed-Likelihood Estimator","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/automatic-segmentation-and-quantitative-analysis-of-white-matter-hyperintensities-on-flair-images-us/"},"url":"https://clinicaltree.github.io/posts/automatic-segmentation-and-quantitative-analysis-of-white-matter-hyperintensities-on-flair-images-us/"}</script><title>Automatic Segmentation and Quantitative Analysis of White Matter Hyperintensities on FLAIR Images Using Trimmed-Likelihood Estimator | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Automatic Segmentation and Quantitative Analysis of White Matter Hyperintensities on FLAIR Images Using Trimmed-Likelihood Estimator</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Automatic Segmentation and Quantitative Analysis of White Matter Hyperintensities on FLAIR Images Using Trimmed-Likelihood Estimator</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1417366800" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Nov 30, 2014 </em> </span> <span> Updated <em class="" data-ts="1681094635" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 10, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Rui Wang PhD</a> </em>, <em> <a href="">Chao Li PhD</a> </em>, <em> <a href="">Jie Wang BS</a> </em>, <em> <a href="">Xiaoer Wei MD</a> </em>, <em> <a href="">Yuehua Li MD</a> </em>, <em> <a href="">Chun Hui PhD</a> </em>, <em> <a href="">Yuemin Zhu PhD</a> </em>, <em> <a href="">Su Zhang PhD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3179 words"> <em>17 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Quantitative analysis of white matter hyperintensities (WMHs) on fluid-attenuated inversion recovery (FLAIR) images provides information for disease tracking, therapeutic efficacy assessment, and cognitive science research. This study developed an automatic segmentation method to detect and quantify WMHs on FLAIR images. This study aims to assess the accuracy and reproducibility of the proposed method.</p><h2 id="materials-and-methods"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The FLAIR images of 82 patients (58–84 years) with different WMH burdens were acquired with the same 3T scanner (Intera-achieva SMI-2.1; Philip Medical System, Sixth Affiliated People’s Hospital, Shanghai, China). The FLAIR images were preprocessed through brain extraction and intensity inhomogeneity correction. An anatomy atlas built from a set of 20 patients with different WMH burdens (mild, 11 patients; moderate, 6 patients; and severe, 3 patients) was used to estimate a control parameter in the framework of segmentation. The general flow for WMH segmentation included classification of foreground and background regions, detection of abnormally high signals, and WMH refinement. The performance of automatic segmentation was evaluated by a volumetric comparison with manual segmentation on patients with different WMH burdens.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Similarity index values for the accuracy of automatic segmentation compared to manual segmentation were consistently high for patients with different WMH burdens (mild, 0.78 ± 0.08; moderate, 0.83 ± 0.06; severe, 0.84 ± 0.08; and total, 0.80 ± 0.08). Linear regression demonstrated a strong correlation between the WMH volumes measured by the two methods in all patients ( <em>r</em> = 0.98, <em>P</em> = .006). Small average differences were detected between the WMH volumes obtained through manual and automatic segmentations (mild, 4.76%; moderate, 6.84%; and severe, 7.59%). The results of Bland–Altman analysis show a system bias of 0.68 cm 3 and a standard deviation of 2.10 cm 3 over the range of 2.58–53.9 cm 3 .</p><h2 id="conclusions"><span class="mr-2">Conclusions</span><a href="#conclusions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The developed method is accurate and efficient in detecting and quantifying differently sized WMHs on FLAIR images. Automatic segmentation is a promising computer-aided diagnostic tool to study WMHs in aging and dementia in basic research and even in clinical trials.</p><p>White matter hyperintensities (WMHs) are focal or diffuse lesions of high signals commonly found in the cerebral white matter (WM) on T 2 -weighted (T 2 -w) and fluid-attenuated inversion recovery (FLAIR) magnetic resonance (MR) images . The pathologic mechanism of WMHs remains unclear, but the lesions are suggested to be associated with age, demyelination, gliosis, and stroke . The typical clinical manifestations of WMHs include cognitive dysfunctions, movement disorder, and depressive symptoms . Both T 2 -w sequences and FLAIR are used to detect WMHs. FLAIR sequence exhibits a better effect than T 2 -w images when imaging WMHs near cerebrospinal fluid (CSF) spaces because it suppresses high CSF signals by adopting a long inversion time . Moreover, the contrast between WM and gray matter (GM) is reduced on FLAIR images for the elderly population, thereby producing a homogeneous low background signal and making WMHs prominent .</p><p>Accurate detection of WMHs contributes to measuring the number and volume of lesions for disease tracking, therapeutic efficacy assessment, and cognitive science research. WMHs correlate with an increased risk of stroke, dementia, and death . The issue of whether different WMH volumes are associated with cognitive dysfunctions and movement disorder has been discussed widely and constantly . Qualitative and quantitative analyses of MR images have been used to assess the lesion load of these signal abnormalities. Qualitative analysis is performed by an experienced radiologist using different visual rating scales, but the results are often affected by subjective factors and ceiling effects . Quantitative analysis methods, including manual and automatic segmentation, provide information on WMH volume . Although manual segmentation is the gold standard for validating other segmentation methods, this technique is labor intensive and time consuming. Automatic segmentation is based on machine learning and pattern recognition technique; it combines various feature selections and classification methods to detect WMHs accurately and effectively. Fuzzy connectedness and threshold-based technique are commonly used in different automatic segmentation methods. Automatic segmentation is completely reproducible, whereas manual segmentation often suffers from intra-and inter-expert variability .</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="materials-and-methods-1"><span class="mr-2">Materials and methods</span><a href="#materials-and-methods-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="subjects-and-image-acquisition"><span class="mr-2">Subjects and Image Acquisition</span><a href="#subjects-and-image-acquisition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="data-preparation"><span class="mr-2">Data Preparation</span><a href="#data-preparation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="image-preprocessing"><span class="mr-2">Image Preprocessing</span><a href="#image-preprocessing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="segmentation-method"><span class="mr-2">Segmentation Method</span><a href="#segmentation-method" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/0_1s20S1076633214002451.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/0_1s20S1076633214002451.jpg" alt="Figure 1, (a) FLAIR image of WMHs in the periventricular white matter. (b) Gray-level histogram of the FLAIR image. The horizontal axis represents the range of the gray-scale distribution, and the vertical axis is the logarithmic number of voxels with a specific gray level. The left tail in the gray histogram corresponds to the peripheral area in FLAIR images with a gray level of 0. The right tail in the gray histogram indicates areas (WMH, skull, and scalp) with abnormally high signals on the FLAIR image. (c) And (d) are pseudocolor images and correspond to color histograms. The color information simplifies locating a specific tissue on the FLAIR images in the statistical histogram. FLAIR, fluid-attenuated inversion recovery; WMH, white matter hyperintensity. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/1_1s20S1076633214002451.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/1_1s20S1076633214002451.jpg" alt="Figure 2, Flow diagram of automatic WMH segmentation. EM, expectation–maximization; FLAIR, fluid-attenuated inversion recovery; TLE, trimmed-likelihood estimator; WMH, white matter hyperintensity." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="classification-of-foreground-and-background-regions"><span class="mr-2">Classification of Foreground and Background Regions</span><a href="#classification-of-foreground-and-background-regions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>φ(yi;xi)=∑kj=1πjψ(yi;xi,μj,σj) φ</p><p>(</p><p>y</p><p>i</p><p>;</p><p>x</p><p>i</p><p>)</p><p>=</p><p>∑</p><p>j</p><p>=</p><p>1</p><p>k</p><p>π</p><p>j</p><p>ψ</p><p>(</p><p>y</p><p>i</p><p>;</p><p>x</p><p>i</p><p>,</p><p>μ</p><p>j</p><p>,</p><p>σ</p><p>j</p><p>)</p><p>where ψ ( <em>y__i</em> ; <em>x__i</em> , μ <em>j</em> , σ <em>j</em> ) denotes the PDF of a Gaussian distribution with unknown parameters, including the mean μ <em>j</em> , standard deviation σ <em>j</em> , and proportion of the <em>j</em> th classifier π <em>j</em> . Each Gaussian in GMM provides a probabilistic model for a specific tissue class in the FLAIR images. <em>x__j</em> is a discrete label that represents the classification of voxel <em>y__i</em> with respect to the two tissue classes ( <em>k</em> = 2), namely, foreground and background. In the EM algorithm, unknown parameters must be properly initialized using the Otsu method . Specifically, we first used the Otsu method to classify the FLAIR images into two parts, namely, the foreground and background regions. μ(0)j μ</p><p>j</p><p>(</p><p>0</p><p>) and σ(0)j σ</p><p>j</p><p>(</p><p>0</p><p>) were then initialized using the mean values and standard deviations of these preclassified regions. Furthermore, we computed the proportions of the foreground and background regions with respect to the images as a whole. These proportions were used to initialize the parameters π(0)j π</p><p>j</p><p>(</p><p>0</p><p>) . With these initial starting values, the EM algorithm estimates MLE parameters by iteratively performing expectation (E) and maximization (M) steps. The former step creates an expectation function of log likelihood using the estimated unknown parameters. The latter step estimates the unknown parameters and maximizes the expectation function . The final GMM was estimated by MLE with the EM algorithm. The probabilities of voxel <em>y__i</em> assigned to the foreground and background were calculated based on Bayes posterior probability in the EM algorithm. The brain voxels were finally classified into the foreground and background regions. The corresponding PDF φ ( <em>y__i</em> ) for each voxel <em>y__i</em> was stored until used to detect abnormally high signals on the FLAIR images. The results obtained after the classification of the foreground (white) and background (black) regions are shown in Figure 3 b.</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/2_1s20S1076633214002451.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/2_1s20S1076633214002451.jpg" alt="Figure 3, (a) Brain extraction with the standard software BET. The signals of skull and scalp were eliminated, producing a clean brain template to be used in the following WMH refinement step. (b) Results obtained after classification of foreground (white) and background (black) regions. (c) Abnormally high signals consisting of WMH, skull, and scalp detected based on EM-TLE segmentation. WMHs are displayed in red color. The green signal indicates skull and scalp in the brain to be eliminated in the following WMH refinement step. (d) Final segmentation result obtained after the WMH refinement step. EM, expectation–maximization; TLE, trimmed-likelihood estimator; WMH, white matter hyperintensity. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="detection-of-abnormally-high-signals"><span class="mr-2">Detection of Abnormally High Signals</span><a href="#detection-of-abnormally-high-signals" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>θˆTLE:=argmaxθ∈Θ∑nTi=1f(yv(i);θ) θ</p><p>ˆ</p><p>TLE</p><p>:</p><p>=</p><p>arg</p><p>max</p><p>θ</p><p>∈</p><p>Θ</p><p>∑</p><p>i</p><p>=</p><p>1</p><p>n</p><p>T</p><p>f</p><p>(</p><p>y</p><p>v</p><p>(</p><p>i</p><p>)</p><p>;</p><p>θ</p><p>)</p><p>where f(yi;θ)=logφ(yi;θ) f</p><p>(</p><p>y</p><p>i</p><p>;</p><p>θ</p><p>)</p><p>=</p><p>log</p><p>φ</p><p>(</p><p>y</p><p>i</p><p>;</p><p>θ</p><p>) is the logarithmic value of PDF for voxel <em>y__i</em> in a FLAIR image and f(yv(1);θ)≥f(yv(2);θ)≥⋅⋅⋅≥f(yv(nT);θ) f</p><p>(</p><p>y</p><p>v</p><p>(</p><p>1</p><p>)</p><p>;</p><p>θ</p><p>)</p><p>≥</p><p>f</p><p>(</p><p>y</p><p>v</p><p>(</p><p>2</p><p>)</p><p>;</p><p>θ</p><p>)</p><p>≥</p><p>⋅</p><p>⋅</p><p>⋅</p><p>≥</p><p>f</p><p>(</p><p>y</p><p>v</p><p>(</p><p>n</p><p>T</p><p>)</p><p>;</p><p>θ</p><p>) . The corresponding permutation of the indices is represented as <em>v</em> = [ <em>v</em> (1), …, <em>v</em> ( <em>n__T</em> )], which sorts all voxels of the FLAIR images according to the values of their probability <em>f</em> ( <em>y__v</em> ( <em>i</em> ) ;θ). The number of voxels for normal tissues was calculated using the trimming parameter <em>n__T</em> = <em>n</em> × (1 − <em>h</em> ), where <em>n</em> is the denoted total number of voxels in FLAIR images and <em>h</em> represents the proportion of abnormal high signals to the FLAIR images. The detection of abnormally high signals on FLAIR images was divided into two stages: parameter <em>h</em> estimation and TLE-EM segmentation.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="stage-1-estimation-of-parameter-h"><span class="mr-2">Stage 1: Estimation of Parameter <em>h</em></span><a href="#stage-1-estimation-of-parameter-h" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="stage-2-tle-em-segmentation"><span class="mr-2">Stage 2: TLE-EM Segmentation</span><a href="#stage-2-tle-em-segmentation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="wmhs-refinement"><span class="mr-2">WMHs Refinement</span><a href="#wmhs-refinement" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="validation-of-segmentation-and-quantitative-measures"><span class="mr-2">Validation of Segmentation and Quantitative Measures</span><a href="#validation-of-segmentation-and-quantitative-measures" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>SI=2×(M∩A)M+A SI</p><p>=</p><p>2</p><p>×</p><p>(</p><p>M</p><p>∩</p><p>A</p><p>)</p><p>M</p><p>+</p><p>A</p><p>FPR=!M∩AM FPR</p><p>=</p><p>!M</p><p>∩</p><p>A</p><p>M</p><p>FNR=M∩!AM FNR</p><p>=</p><p>M</p><p>∩</p><p>!</p><p>A</p><p>M</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">Results</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="volumetric-comparison-between-manual-and-automatic-segmentations"><span class="mr-2">Volumetric Comparison Between Manual and Automatic Segmentations</span><a href="#volumetric-comparison-between-manual-and-automatic-segmentations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/3_1s20S1076633214002451.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/3_1s20S1076633214002451.jpg" alt="Figure 4, Automatic versus manual segmentation in patients with mild (a) , moderate (b) , and severe (c) WMH burdens. First column : original FLAIR images. Second column : results ( red signals ) of automatic segmentation. Third column : results ( blue signals ) of manual segmentation. Fourth column : overlap map generated by combining manual and automatic segmentations. Green : true positive, WMH signals simultaneously detected by manual and automatic segmentations; Blue : false negative, WMH signals detected by manual segmentation but undetected by automatic segmentation; Red : false positive, WMH signals detected by automatic segmentation but undetected by manual segmentation. FLAIR, fluid-attenuated inversion recovery; WMH, white matter hyperintensity. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p>Table 1</p><p>Similarity Measurement Comparison Between Results of Automatic Segmentation and Manual Segmentation</p><p>WMH Burden SI FPR FNR Mild ( <em>N</em> = 44) 0.78 ± 0.08 0.26 ± 0.06 0.19 ± 0.06 Moderate ( <em>N</em> = 26) 0.83 ± 0.06 0.11 ± 0.06 0.21 ± 0.06 Severe ( <em>N</em> = 12) 0.84 ± 0.08 0.08 ± 0.06 0.22 ± 0.07 Total ( <em>N</em> = 82) 0.80 ± 0.08 0.19 ± 0.07 0.20 ± 0.06</p><p>FNR, false-negative rate; FPR, false-positive rate; SI, similarity index; WMH, white matter hyperintensity.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="regression-and-blandaltman-analysis"><span class="mr-2">Regression and Bland–Altman Analysis</span><a href="#regression-and-blandaltman-analysis" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 2</p><p>Quantitative Analysis of Automated Segmentation with Respect to Manual Segmentation</p><p>WMH Burden Automatic (cm 3 ) Manual (cm 3 )<em>R</em> Mild ( <em>N</em> = 44) 6.84 ± 2.10 6.5 ± 1.96 0.91 Moderate ( <em>N</em> = 26) 18.83 ± 4.87 20.1 ± 4.93 0.92 Severe ( <em>N</em> = 12) 37.73 ± 8.51 40.7 ± 7.61 0.93 Total ( <em>N</em> = 82) 15.16 ± 11.69 15.84 ± 12.73 0.98</p><p>Automatic and manual refer to quantitative white matter hyperintensity (WMH) volume detected by automatic and manual segmentation methods, respectively.</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/4_1s20S1076633214002451.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/4_1s20S1076633214002451.jpg" alt="Figure 5, Volumetric comparisons of WMHs detected by manual and automatic segmentations. (a) Linear regression analysis of WMH volumes obtained by manual and automatic segmentations. The blue line corresponds to the regression line, whereas the red line corresponds to the equality line. (b) Bland–Altman analysis of WMH volumes obtained by manual and automatic methods. SD, standard deviation; WMH, white matter hyperintensity. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="effect-of-different-parameters-h-values-on-automatic-segmentation-of-wmhs"><span class="mr-2">Effect of Different Parameters <em>h</em> Values on Automatic Segmentation of WMHs</span><a href="#effect-of-different-parameters-h-values-on-automatic-segmentation-of-wmhs" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/5_1s20S1076633214002451.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/AutomaticSegmentationandQuantitativeAnalysisofWhiteMatterHyperintensitiesonFLAIRImagesUsingTrimmedLikelihoodEstimator/5_1s20S1076633214002451.jpg" alt="Figure 6, Similarity measurements change as a function of h with respect to different WMH burden: (a) mild (b) moderate (c) severe. WMH, white matter hyperintensity; FNR, false-negative rate; FPR, false-positive rate. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">Discussion</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 3</p><p>Comparison of Similarity Index for the WMH Segmentation Between Different Methods on Different Real Data Sets</p><p>WMH Burden Mild Moderate Severe Total TLE-EM 0.78 0.83 0.84 0.80 Anbeek et al. 0.50 0.75 0.85 0.80 Behloul et al. 0.70 0.75 0.82 0.75 Khayati et al. 0.73 0.75 0.81 0.75</p><p>EM, expectation–maximization; TLE, trimmed-likelihood estimator; WMH, white matter hyperintensity.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="conclusions-1"><span class="mr-2">Conclusions</span><a href="#conclusions-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="acknowledgments"><span class="mr-2">Acknowledgments</span><a href="#acknowledgments" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. de Groot J.C., Oudkerk M., Gijn Jv, et. al.: Cerebral white matter lesions and cognitive function: the Rotterdam Scan Study. Ann Neurol 2000; 47: pp. 145-151.</p><li><p>2. Debette S., Markus H.: The clinical importance of white matter hyperintensities on brain magnetic resonance imaging: systematic review and meta-analysis. BMJ 2010; 341: pp. c3666.</p><li><p>3. Silbert L., Nelson C., Howieson D., et. al.: Impact of white matter hyperintensity volume progression on rate of cognitive and motor decline. Neurology 2008; 71: pp. 108-113.</p><li><p>4. Barkhof F., Scheltens P.: Imaging of white matter lesions. Cerebrovas Dis 2002; 13: pp. 21-30.</p><li><p>5. Gerdes V.E., Kwa V.I., ten Cate H., et. al.: Cerebral white matter lesions predict both ischemic strokes and myocardial infarctions in patients with established atherosclerotic disease. Atherosclerosis 2006; 186: pp. 166-172.</p><li><p>6. Naka H., Nomura E., Takahashi T., et. al.: Combinations of the presence or absence of cerebral microbleeds and advanced white matter hyperintensity as predictors of subsequent stroke types. Am J Neuroradiol 2006; 27: pp. 830-835.</p><li><p>7. Soumaré A., Elbaz A., Zhu Y., et. al.: White matter lesions volume and motor performances in the elderly. Ann Neurol 2009; 65: pp. 706-715.</p><li><p>8. Scheltens P., Erkinjunti T., Leys D., et. al.: White matter changes on CT and MRI: an overview of visual rating scales. Eur Neuro 1998; 39: pp. 80-89.</p><li><p>9. Fazekas F., Barkhof F., Wahlund L., et. al.: CT and MRI rating of white matter lesions. Cerebrovas Dis 2002; 13: pp. 31-36.</p><li><p>10. Yamamoto D., Arimura H., Kakeda S., et. al.: Computer-aided detection of multiple sclerosis lesions in brain magnetic resonance images: false positive reduction scheme consisted of rule-based, level set method, and support vector machine. Comput Med Imaging Graph 2010; 34: pp. 404-413.</p><li><p>11. Hulsey K.M., Gupta M., King K.S., et. al.: Automated quantification of white matter disease extent at 3T: Comparison with volumetric readings. J Magn Reson Imaging 2012; 36: pp. 305-311.</p><li><p>12. Archip N., Jolesz F.A., Warfield S.K.: A validation framework for brain tumor segmentation. Acad Radiol 2007; 14: pp. 1242-1251.</p><li><p>13. Clas P., Groeschel S., Wilke M.: A semi–automatic algorithm for determining the demyelination load in metachromatic leukodystrophy. Acad Radiol 2012; 19: pp. 26-34.</p><li><p>14. Lao Z., Shen D., Liu D., et. al.: Computer-assisted segmentation of white matter lesions in 3D MR images using support vector machine. Acad Radiol 2008; 15: pp. 300-313.</p><li><p>15. García–Lorenzo D., Francis S., Narayanan S., et. al.: Review of automatic segmentation methods of multiple sclerosis white matter lesions on conventional magnetic resonance imaging. Med Image Anal 2013; 17: pp. 1-18.</p><li><p>16. Liu J.G., Udupa J.K., Odhner D., et. al.: A system for brain tumor volume estimation via MR imaging and fuzzy connectedness. Comput Med Imaging Graph 2005; 29: pp. 21-34.</p><li><p>17. Udupa J.K., Wei L., Samarasekera S., et. al.: Multiple sclerosis lesion quantification using fuzzy-connectedness principles. IEEE T Med Imaging 1997; 16: pp. 598-609.</p><li><p>18. Udupa J.K., Saha P.K., Lotufo R.A.: Relative fuzzy connectedness and object definition: theory, algorithms, and applications in image segmentation. IEEE T Pattern Anal 2002; 24: pp. 1485-1500.</p><li><p>19. Van Leemput K., Maes F., Vandermeulen D., et. al.: Automated segmentation of multiple sclerosis lesions by model outlier detection. IEEE T Med Imaging 2001; 20: pp. 677-688.</p><li><p>20. Zhang Y., Brady M., Smith S.: Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm. IEEE T Med Imaging 2001; 20: pp. 45-57.</p><li><p>21. Wells W.M., Grimson W.E.L., Kikinis R., et. al.: Adaptive segmentation of MRI data. IEEE T Med Imaging 1996; 15: pp. 429-442.</p><li><p>22. Neykov N., Filzmoser P., Dimova R., et. al.: Robust fitting of mixtures using the trimmed likelihood estimator. Comput Stat Data Anal 2007; 52: pp. 299-308.</p><li><p>23. Bricq S, Collet C, Armspach J–P. Lesions detection on 3D brain MRI using trimmed likelihood estimator and probabilistic atlas. In: Proceedings of the 5th IEEE International Symposium on Biomedical Imaging: From Nano to Macro. ISBI 2008: Paris, France, 2008;93–96.</p><li><p>24. Galimzianova A, Špiclin Ž, Likar B, et al. Automated segmentation of MS lesions in brain MR images using localized trimmed-likelihood estimation. In: Proc. SPIE 8669, Medical Imaging: Image Processing. Lake Buena Vista (Orlando Area), Florida, USA: 2013;86693E–86693E–86697.</p><li><p>25. García–Lorenzo D., Prima S., Arnold D.L., et. al.: Trimmed-likelihood estimation for focal lesions and tissue segmentation in multisequence MRI for multiple sclerosis. IEEE T Med Imaging 2011; 30: pp. 1455-1467.</p><li><p>26. Varela F., Lachaux J.–P., Rodriguez E., et. al.: The BrainWeb: phase synchronization and large-scale integration. Nat Rev Neurosci 2001; 2: pp. 229-239.</p><li><p>27. Gibson E., Gao F., Black S.E., et. al.: Automatic segmentation of white matter hyperintensities in the elderly using Flair images at 3T. J Magn Reson Imaging 2010; 31: pp. 1311-1322.</p><li><p>28. Sled J.G., Zijdenbos A.P., Evans A.C.: A nonparametric method for automatic correction of intensity nonuniformity in MRI data. IEEE T Med Imaging 1998; 17: pp. 87-97.</p><li><p>29. Smith S.M.: Fast robust automated brain extraction. Hum Brain Mapp 2002; 17: pp. 143-155.</p><li><p>30. Otsu N.: A threshold selection method from gray-level histograms. Automatica 1975; 11: pp. 23-27.</p><li><p>31. Dempster A.P., Laird N.M., Rubin D.B.: Maximum likelihood from incomplete data via the EM algorithm. J Roy Stat Soc 1977; 39: pp. 1-38.</p><li><p>32. Khayati R., Vafadust M., Towhidkhah F., et. al.: Fully automatic segmentation of multiple sclerosis lesions in brain MR FLAIR images using adaptive mixtures method and Markov random field model. Comput Biol Med 2008; 38: pp. 379-390.</p><li><p>33. Dice L.R.: Measures of the amount of ecologic association between species. Ecology 1945; 26: pp. 297-302.</p><li><p>34. Zijdenbos A.P., Dawant B.M., Margolin R.A., et. al.: Morphometric analysis of white matter lesions in MR images: method and validation. IEEE T Med Imaging 1994; 13: pp. 716-724.</p><li><p>35. Anbeek P., Vincken K.L., van Osch M.J., et. al.: Automatic segmentation of different-sized white matter lesions by voxel probability estimation. Med Image Anal 2004; 8: pp. 205-215.</p><li><p>36. Anbeek P., Vincken K.L., van Osch M.J., et. al.: Probabilistic segmentation of white matter lesions in MR imaging. Neuroimage 2004; 21: pp. 1037-1044.</p><li><p>37. de Boer R., Vrooman H.A., van der Lijn F., et. al.: White matter lesion extension to automatic brain tissue segmentation on MRI. Neuroimage 2009; 45: pp. 1151-1161.</p><li><p>38. Udupa J.K., LeBlanc V.R., Ying Z.G., et. al.: A framework for evaluating image segmentation algorithms. Comput Med Imaging Grap 2006; 30: pp. 75-87.</p><li><p>39. Altman D.G., Bland J.M.: Measurement in medicine: the analysis of method comparison studies. Stat 1983; 32: pp. 307-317.</p><li><p>40. Bland J.M., Altman D.G.: Measuring agreement in method comparison studies. Stat Methods Med Res 1999; 8: pp. 135-160.</p><li><p>41. Admiraal–Behloul F., Van Den Heuvel D., Olofsen H., et. al.: Fully automatic segmentation of white matter hyperintensities in MR images of the elderly. Neuroimage 2005; 28: pp. 607-617.</p><li><p>42. Madabhushi A., Udupa J.K.: Interplay between intensity standardization and inhomogeneity correction in MR image processing. IEEE T Med Imaging 2005; 24: pp. 561-576.</p><li><p>43. Madabhushi A., Udupa J.K.: New methods of MR image intensity standardization via generalized scale. Med Phys 2006; 33: pp. 3426-3434.</p><li><p>44. Zhuge Y., Udupa J.K.: Intensity standardization simplifies brain MR image segmentation. Comput Vis Image Und 2009; 113: pp. 1095-1103.</p><li><p>45. Nyul L.G., Udupa J.K.: On standardizing the MR image intensity scale. Magn Reson Med 1999; 42: pp. 1072-1081.</p><li><p>46. Nyul L.G., Udupa J.K., Zhang X.: New variants of a method of MRI scale standardization. IEEE T Med Imaging 2000; 19: pp. 143-150.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-21/'>Volume 21</a>, <a href='/categories/issue-12/'>Issue 12</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Automatic%20Segmentation%20and%20Quantitative%20Analysis%20of%20White%20Matter%20Hyperintensities%20on%20FLAIR%20Images%20Using%20Trimmed-Likelihood%20Estimator%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fautomatic-segmentation-and-quantitative-analysis-of-white-matter-hyperintensities-on-flair-images-us%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Automatic%20Segmentation%20and%20Quantitative%20Analysis%20of%20White%20Matter%20Hyperintensities%20on%20FLAIR%20Images%20Using%20Trimmed-Likelihood%20Estimator%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fautomatic-segmentation-and-quantitative-analysis-of-white-matter-hyperintensities-on-flair-images-us%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fautomatic-segmentation-and-quantitative-analysis-of-white-matter-hyperintensities-on-flair-images-us%2F&text=Automatic%20Segmentation%20and%20Quantitative%20Analysis%20of%20White%20Matter%20Hyperintensities%20on%20FLAIR%20Images%20Using%20Trimmed-Likelihood%20Estimator%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/assessment-of-repeatability-of-hyperpolarized-gas-mr-ventilation-functional-imaging-in-cystic-fibros/"><div class="card-body"> <em class="small" data-ts="1417366800" data-df="ll" > Nov 30, 2014 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Assessment of Repeatability of Hyperpolarized Gas MR Ventilation Functional Imaging in Cystic Fibrosis</h3><div class="text-muted small"><p> Rationale and Objectives Hyperpolarized (HP) gas magnetic resonance imaging (MRI) is an advanced imaging technique that provides high-resolution regional information on lung function without using...</p></div></div></a></div><div class="card"> <a href="/posts/comparison-of-a-stationary-digital-breast-tomosynthesis-system-to-magnified-2d-mammography-using-bre/"><div class="card-body"> <em class="small" data-ts="1417366800" data-df="ll" > Nov 30, 2014 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Comparison of a Stationary Digital Breast Tomosynthesis System to Magnified 2D Mammography Using Breast Tissue Specimens</h3><div class="text-muted small"><p> Rational and Objectives The objective of this study was to compare the stationary digital breast tomosynthesis (s-DBT) system to a conventional mammography system in a study of breast specimens. R...</p></div></div></a></div><div class="card"> <a href="/posts/ct-texture-analysis-of-renal-masses/"><div class="card-body"> <em class="small" data-ts="1417366800" data-df="ll" > Nov 30, 2014 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CT Texture Analysis of Renal Masses</h3><div class="text-muted small"><p> Rationale and Objectives Computed tomography texture analysis (CTTA) allows quantification of heterogeneity within a region of interest. This study investigates the possibility of distinguishing b...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/assessment-of-repeatability-of-hyperpolarized-gas-mr-ventilation-functional-imaging-in-cystic-fibros/" class="btn btn-outline-primary" prompt="Older"><p>Assessment of Repeatability of Hyperpolarized Gas MR Ventilation Functional Imaging in Cystic Fibrosis</p></a> <a href="/posts/comparison-of-a-stationary-digital-breast-tomosynthesis-system-to-magnified-2d-mammography-using-bre/" class="btn btn-outline-primary" prompt="Newer"><p>Comparison of a Stationary Digital Breast Tomosynthesis System to Magnified 2D Mammography Using Breast Tissue Specimens</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

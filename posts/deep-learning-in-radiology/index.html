<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Deep Learning in Radiology" /><meta property="og:locale" content="en" /><meta name="description" content="As radiology is inherently a data-driven specialty, it is especially conducive to utilizing data processing techniques. One such technique, deep learning (DL), has become a remarkably powerful tool for image processing in recent years. In this work, the Association of University Radiologists Radiology Research Alliance Task Force on Deep Learning provides an overview of DL for the radiologist. This article aims to present an overview of DL in a manner that is understandable to radiologists; to examine past, present, and future applications; as well as to evaluate how radiologists may benefit from this remarkable new tool. We describe several areas within radiology in which DL techniques are having the most significant impact: lesion or disease detection, classification, quantification, and segmentation. The legal and ethical hurdles to implementation are also discussed. By taking advantage of this powerful tool, radiologists can become increasingly more accurate in their interpretations with fewer errors and spend more time to focus on patient care." /><meta property="og:description" content="As radiology is inherently a data-driven specialty, it is especially conducive to utilizing data processing techniques. One such technique, deep learning (DL), has become a remarkably powerful tool for image processing in recent years. In this work, the Association of University Radiologists Radiology Research Alliance Task Force on Deep Learning provides an overview of DL for the radiologist. This article aims to present an overview of DL in a manner that is understandable to radiologists; to examine past, present, and future applications; as well as to evaluate how radiologists may benefit from this remarkable new tool. We describe several areas within radiology in which DL techniques are having the most significant impact: lesion or disease detection, classification, quantification, and segmentation. The legal and ethical hurdles to implementation are also discussed. By taking advantage of this powerful tool, radiologists can become increasingly more accurate in their interpretations with fewer errors and spend more time to focus on patient care." /><link rel="canonical" href="https://clinicaltree.github.io/posts/deep-learning-in-radiology/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/deep-learning-in-radiology/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2018-10-31T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Deep Learning in Radiology" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-10T03:59:08+00:00","datePublished":"2018-10-31T17:00:00+00:00","description":"As radiology is inherently a data-driven specialty, it is especially conducive to utilizing data processing techniques. One such technique, deep learning (DL), has become a remarkably powerful tool for image processing in recent years. In this work, the Association of University Radiologists Radiology Research Alliance Task Force on Deep Learning provides an overview of DL for the radiologist. This article aims to present an overview of DL in a manner that is understandable to radiologists; to examine past, present, and future applications; as well as to evaluate how radiologists may benefit from this remarkable new tool. We describe several areas within radiology in which DL techniques are having the most significant impact: lesion or disease detection, classification, quantification, and segmentation. The legal and ethical hurdles to implementation are also discussed. By taking advantage of this powerful tool, radiologists can become increasingly more accurate in their interpretations with fewer errors and spend more time to focus on patient care.","headline":"Deep Learning in Radiology","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/deep-learning-in-radiology/"},"url":"https://clinicaltree.github.io/posts/deep-learning-in-radiology/"}</script><title>Deep Learning in Radiology | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Deep Learning in Radiology</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Deep Learning in Radiology</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1541005200" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Oct 31, 2018 </em> </span> <span> Updated <em class="" data-ts="1681099148" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 10, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Morgan P. McBee MD</a> </em>, <em> <a href="">Omer A. Awan MD MPH CIIP</a> </em>, <em> <a href="">Andrew T. Colucci MD</a> </em>, <em> <a href="">Comeron W. Ghobadi MD</a> </em>, <em> <a href="">Nadja Kadom MD</a> </em>, <em> <a href="">Akash P. Kansagra MD MS</a> </em>, <em> <a href="">Srini Tridapani MD PhD MSEE MSCR MBA</a> </em>, <em> <a href="">William F. Auffermann MD PhD</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2718 words"> <em>15 min</em> read</span></div></div></div><div class="post-content"><p>As radiology is inherently a data-driven specialty, it is especially conducive to utilizing data processing techniques. One such technique, deep learning (DL), has become a remarkably powerful tool for image processing in recent years. In this work, the Association of University Radiologists Radiology Research Alliance Task Force on Deep Learning provides an overview of DL for the radiologist. This article aims to present an overview of DL in a manner that is understandable to radiologists; to examine past, present, and future applications; as well as to evaluate how radiologists may benefit from this remarkable new tool. We describe several areas within radiology in which DL techniques are having the most significant impact: lesion or disease detection, classification, quantification, and segmentation. The legal and ethical hurdles to implementation are also discussed. By taking advantage of this powerful tool, radiologists can become increasingly more accurate in their interpretations with fewer errors and spend more time to focus on patient care.</p><h2 id="introduction"><span class="mr-2">Introduction</span><a href="#introduction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Recent rapid advances in computer hardware and software now allow computers to perform an increasing number of tasks that have historically not been possible . The technologies that can in some ways mimic the decision-making abilities of humans are known by several names, depending on the nature of the algorithms used. One of the more sophisticated sets of algorithms is often referred to as deep learning (DL). DL has made great advances in recent years, now performing tasks that only humans could perform just a few years ago. Some may perceive DL algorithms as a threat to medicine and radiology. However, DL is like any other tool, intrinsically neither good nor evil, but rather dependent on the application. In this work, the Association of University Radiologists Radiology Research Alliance Task Force on Deep Learning provides an overview of DL for the radiologist. The goal of this task force was to examine developments in DL and how they will influence the current and future practice of radiology. This article seeks to present an overview of DL in a manner that is understandable to radiologists; to examine past, present, and future applications; and to evaluate how radiologists may benefit from this remarkable new tool. Additional resources providing greater depth of coverage are included for the interested reader.</p><h2 id="evolution-of-artificial-intelligence-and-machine-learning"><span class="mr-2">Evolution of Artificial Intelligence and Machine Learning</span><a href="#evolution-of-artificial-intelligence-and-machine-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Most people’s knowledge of artificial intelligence (AI) is derived from science fiction movies. AI is defined as “the capacity of computers or other machines to exhibit or simulate intelligent behavior” and is now a thriving field and the focus of a great amount of research and investment. Early on, the focus of AI was to address problems that were difficult for humans but relatively straight forward for computers to solve. Such problems include abstract and formal mathematical problems, such as adjusting the window and the level of a radiographic image on a viewing workstation. Additionally, the early attempts of AI were based on rigid predefined rules, but this approach was largely unsuccessful .</p><p>An advance in AI was the advent of machine learning (ML), which is the ability of an AI system to extract information from raw data and to learn from experience. This avoids the need for “human operators to formally specify all of the knowledge that the computer needs” . For example, an ML algorithm introduced in 1990 utilized logistic regression to determine whether or not cesarean section was appropriate .</p><p>Broadly speaking, ML comprises a set of algorithms that aim to allow computers to receive an assortment of input data and to generate complex inferences that are based on potentially obscure relationships between inputs. For example, ML algorithms may play an important role in combining financial data (such as company and industry earnings reports) and nonfinancial data (including information of geopolitical events and weather patterns) to generate nuanced recommendations about whether to buy or sell an equity stock position.</p><h2 id="what-is-deep-learning"><span class="mr-2">What Is Deep Learning?</span><a href="#what-is-deep-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>DL has received a great deal of attention lately both in the consumer world and throughout the medical community, whereas ML algorithms have been a focus of research for many years. There has been a renewed interest in DL algorithms lately since they reduced the top-5 error by 10% in 2012 at the ImageNet Large Scale Visual Recognition Challenge . Top-5 error is defined as “the fraction of test images for which the correct label is not among the five labels considered most probable by the model.” Every year since then, DL models have dominated the challenges, significantly reducing the top-5 error, and in 2015, human performance was surpassed by DL algorithms.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/DeepLearninginRadiology/0_1s20S1076633218301041.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/DeepLearninginRadiology/0_1s20S1076633218301041.jpg" alt="Figure 1, Basic representation of an artificial neural network with neurons similar to those within a brain. The left layer of the neural network is called the input layer and contains neurons that encode the values of the input pixels. The rightmost layer is called the output layer , which contains the output neurons. The middle contains “n” number of hidden layers , which perform mathematical transformations or convolutions of the data. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/DeepLearninginRadiology/1_1s20S1076633218301041.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/DeepLearninginRadiology/1_1s20S1076633218301041.jpg" alt="Figure 2, A representative example of how increasing the number of layers ( x axis) increases the test accuracy ( y axis)." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/DeepLearninginRadiology/2_1s20S1076633218301041.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/DeepLearninginRadiology/2_1s20S1076633218301041.jpg" alt="Figure 3, A curve showing the convergence of accuracy for a machine learning algorithm for chest radiograph data as a function of the number of iterations (epochs)." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="current-advances-in-deep-learning-outside-of-medicine"><span class="mr-2">Current Advances in Deep Learning Outside of Medicine</span><a href="#current-advances-in-deep-learning-outside-of-medicine" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="gaming"><span class="mr-2">Gaming</span><a href="#gaming" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="chess"><span class="mr-2">Chess</span><a href="#chess" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="go"><span class="mr-2">Go</span><a href="#go" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="language"><span class="mr-2">Language</span><a href="#language" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="imaging"><span class="mr-2">Imaging</span><a href="#imaging" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="deep-learning-in-medicine"><span class="mr-2">Deep Learning in Medicine</span><a href="#deep-learning-in-medicine" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="current-applications-in-radiology"><span class="mr-2">Current Applications in Radiology</span><a href="#current-applications-in-radiology" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="lesion-or-disease-detection"><span class="mr-2">Lesion or Disease Detection</span><a href="#lesion-or-disease-detection" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="classification"><span class="mr-2">Classification</span><a href="#classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/DeepLearninginRadiology/3_1s20S1076633218301041.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/DeepLearninginRadiology/3_1s20S1076633218301041.jpg" alt="Figure 4, Differences between classification using conventional algorithms and deep learning algorithms. Note that Σ indicates combination of data inputs." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="quantification"><span class="mr-2">Quantification</span><a href="#quantification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p>1. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>2. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>3. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>4. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>5. <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="segmentation"><span class="mr-2">Segmentation</span><a href="#segmentation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/DeepLearninginRadiology/4_1s20S1076633218301041.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/DeepLearninginRadiology/4_1s20S1076633218301041.jpg" alt="Figure 5, A representative example of chest and lung segmentation. (a) Original computed tomography image of the chest in lung windows. (b) Region of the image corresponding to the lungs. (c) Segmented image with the chest wall and the mediastinum removed and the lungs isolated." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="speech-recognition"><span class="mr-2">Speech Recognition</span><a href="#speech-recognition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="current-limitations"><span class="mr-2">Current Limitations</span><a href="#current-limitations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="future-applications"><span class="mr-2">Future Applications</span><a href="#future-applications" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="conclusion"><span class="mr-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Schmidhuber J.: Deep learning in neural networks: An overview. Neural Netw 2015; 61: pp. 85-117.</p><li><p>2. Dictionary OE : Artificial intelligence, n. Oxford University Press; Available at: http://www.oed.com</p><li><p>3. Goodfellow I., Bengio Y., Courville A.: Deep learning.2016.MIT Press</p><li><p>4. Mor-Yosef S., Samueloff A., Modan B., et. al.: Ranking the risk factors for cesarean: logistic regression analysis of a nationwide study. Obstet Gynecol 1990; 75: pp. 944-947.</p><li><p>5. Krizhevsky A., Sutskever I., Hinton G.E.: ImageNet classification with deep convolutional neural networks. Lake Tahoe, Nevada, Curran Associates Inc2012.</p><li><p>6. Moeskops P., Viergever M.A., Mendrik A.M., et. al.: Automatic segmentation of MR brain images with a convolutional neural network. IEEE Trans Med Imaging 2016; 35: pp. 1252-1261.</p><li><p>7. Tajbakhsh N., Shin J.Y., Gurudu S.R., et. al.: Convolutional neural networks for medical image analysis: full training or fine tuning?. IEEE Trans Med Imaging 2017;</p><li><p>8. Bar Y., Diamant I., Wolf L., et. al.: Chest pathology detection using deep learning with non-medical training. In 2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)2015.pp. 294-297.</p><li><p>9. Huynh B.Q., Li H., Giger M.L.: Digital mammographic tumor classification using transfer learning from deep convolutional neural networks. J Med Imaging (Bellingham) 2016; 3: pp. 034501.</p><li><p>10. Goodfellow I., Bengio Y., Courville A.: Deep learning.2016.The MIT PressCambridge, MA</p><li><p>11. Campbell M., Hoane A.J., Hsu F.-H.: Deep blue. Artif Intell 2002; 134: pp. 57-83.</p><li><p>12. Deep learning machine teaches itself chess in 72 hours, plays at international master level. Available at: https://www.technologyreview.com/s/541276/deep-learning-machine-teaches-itself-chess-in-72-hours-plays-at-international-master/#comments</p><li><p>13. Koch C.: How the computer beat the Go master. Nature America, Inc2016.</p><li><p>14. Gibney E.: Go players react to computer defeat.2016.</p><li><p>15. Perez S.: Google’s smarter, A.I.-powered translation system expands to more languages. AOL Inc2017.</p><li><p>16. French K.: Your New Best Friend: AI Chatbot. Futurism.. Available at: https://futurism.com/ai-chatbot-meaningful-conversation/</p><li><p>17. Coldewey D.: This neural network “hallucinates” the right colors into black and white pictures. TechCrunch2016.</p><li><p>18. Sebastiani F.: Classification of text, automatic.Brown K.Encyclopedia of language &amp; linguistics.2006.ElsevierOxford:</p><li><p>19. Gulshan V., Peng L., Coram M., et. al.: Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. JAMA 2016; 316: pp. 2402-2410.</p><li><p>20. Esteva A., Kuprel B., Novoa R.A., et. al.: Dermatologist-level classification of skin cancer with deep neural networks. Nature 2017; 542: pp. 115-118.</p><li><p>21. Liu Y., Gadepalli K., Norouzi M., et. al.: Detecting cancer metastases on gigapixel pathology images. arXiv2017.</p><li><p>22. Bar Y., Diamant I., Wolf L., et. al.: Deep learning with non-medical training used for chest pathology identification. In SPIE Medical Imaging2015. SPIE, 9414, 7</p><li><p>23. Lakhani P., Sundaram B.: Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks. Radiology 2017; 284: pp. 162326.</p><li><p>24. Cheng J.Z., Ni D., Chou Y.H., et. al.: Computer-aided diagnosis with deep learning architecture: applications to breast lesions in us images and pulmonary nodules in CT scans. Sci Rep 2016; 6: pp. 24454.</p><li><p>25. Kooi T., Litjens G., van Ginneken B., et. al.: Large scale deep learning for computer aided detection of mammographic lesions. Med Image Anal 2017; 35: pp. 303-312.</p><li><p>26. Wang J., Yang X., Cai H., et. al.: Discrimination of breast cancer with microcalcifications on mammography by deep learning. Sci Rep 2016; 6: pp. 27327.</p><li><p>27. Hua K.L., Hsu C.H., Hidayati S.C., et. al.: Computer-aided classification of lung nodules on computed tomography images via deep learning technique. Onco Targets Ther 2015; 8: pp. 2015-2022.</p><li><p>28. Rajkomar A., Lingam S., Taylor A.G., et. al.: High-throughput classification of radiographs using deep convolutional neural networks. J Digit Imaging 2016; pp. 1-7.</p><li><p>29. Wang C., Elazab A., Wu J., et. al.: Lung nodule classification using deep feature fusion in chest radiography. Comput Med Imaging Graph 2017; 57: pp. 10-18.</p><li><p>30. van Ginneken B.: Fifty years of computer analysis in chest imaging: rule-based, machine learning, deep learning. Radiol Phys Technol 2017; 10: pp. 23-32.</p><li><p>31. Armato S.G., Altman M.B., Wilkie J., et. al.: Automated lung nodule classification following automated nodule detection on CT: a serial approach. Med Phys 2003; 30: pp. 1188-1197.</p><li><p>32. Dou Q., Chen H., Yu L., et. al.: Multilevel contextual 3-D CNNs for false positive reduction in pulmonary nodule detection. IEEE Trans Biomed Eng 2017; 64: pp. 1558-1567.</p><li><p>33. Nibali A., He Z., Wollersheim D.: Pulmonary nodule classification with deep residual networks. Int J Comput Assist Radiol Surg 2017; LID</p><li><p>34. Ciompi F., Chung K., van Riel S.J., et. al.: Towards automatic pulmonary nodule management in lung cancer screening with deep learning. Sci Rep 2017;</p><li><p>35. Kim N., Seo J.B., Lee Y., et. al.: Development of an automatic classification system for differentiation of obstructive lung disease using HRCT. J Digit Imaging 2009; 22: pp. 136-148.</p><li><p>36. Anthimopoulos M., Christodoulidis S., Ebner L., et. al.: Lung pattern classification for interstitial lung diseases using a deep convolutional neural network. IEEE Trans Med Imaging 2017; 35: pp. 1207-1216.</p><li><p>37. Lakhani P.: Deep convolutional neural networks for endotracheal tube position and x-ray image classification: challenges and opportunities. J Digit Imaging 2017; LID</p><li><p>38. Wang J., Kato F., Yamashita H., et. al.: Automatic estimation of volumetric breast density using artificial neural network-based calibration of full-field digital mammography: feasibility on Japanese women with and without breast cancer. J Digit Imaging 2016; pp. 1-13.</p><li><p>39. Lee H., Tajmir S., Lee J., et. al.: Fully automated deep learning system for bone age assessment. J Digit Imaging 2017; pp. 1-15.</p><li><p>40. Cheng P.M., Malhi H.S.: Transfer learning with convolutional neural networks for classification of abdominal ultrasound images. J Digit Imaging 2016; pp. 1-10.</p><li><p>41. Cha K.H., Hadjiiski L.M., Chan H.-P., et. al.: Bladder cancer treatment response assessment using deep learning in CT with transfer learning. In SPIE Medical Imaging2017. SPIE, 10134, 6</p><li><p>42. Chen Y., Dhar R., Heitsch L., et. al.: Automated quantification of cerebral edema following hemispheric infarction: application of a machine-learning algorithm to evaluate CSF shifts on serial head CTs. Neuroimage Clin 2016; 12: pp. 673-680.</p><li><p>43. Haralick R.M., Shanmugam K., Dinstein I.H.: Textural features for image classification. IEEE Trans Syst Man Cybern 1973; 3: pp. 610-621.</p><li><p>44. Galloway M.M.: Texture analysis using gray level run lengths. Comput Graph Image Process 1975; 4: pp. 172-179.</p><li><p>45. Tixier F., Le Rest C.C., Hatt M., et. al.: Intratumor heterogeneity characterized by textural features on baseline 18F-FDG PET images predicts response to concomitant radiochemotherapy in esophageal cancer. J Nucl Med 2011; 52: pp. 369-378.</p><li><p>46. Coroller T.P., Grossmann P., Hou Y., et. al.: CT-based radiomic signature predicts distant metastasis in lung adenocarcinoma. Radiother Oncol 2015; 114: pp. 345-350.</p><li><p>47. Akkus Z., Galimzianova A., Hoogi A., et. al.: Deep learning for brain MRI segmentation: state of the art and future directions. J Digit Imaging 2017; LID</p><li><p>48. Gaonkar B., Hovda D., Martin N., et. al.: Deep learning in the small sample size setting: cascaded feed forward neural networks for medical image segmentation. In SPIE Medical Imaging2016. SPIE, 9785, 8</p><li><p>49. Cheng R., Roth H.R., Lu L., et. al.: Active appearance model and deep learning for more accurate prostate segmentation on MRI. In SPIE Medical Imaging2016. SPIE, 9784, 9</p><li><p>50. Hammana I., Lepanto L., Poder T., et. al.: Speech recognition in the radiology department: a systematic review. Health Inf Manag 2015; 44: pp. 4-10.</p><li><p>51. Deng L., Li X.: Machine learning paradigms for speech recognition: an overview. IEEE Trans Audio Speech Lang Process 2013; 21: pp. 1060-1089.</p><li><p>52. Launchbury J.: A DARPA perspective on artificial intelligence.2017.</p><li><p>53. Moosavi-Dezfooli S.-M., Fawzi A., Fawzi O., et. al.: Universal adversarial perturbations.2016.</p><li><p>54. Summers R.M.: Progress in fully automated abdominal CT interpretation. AJR Am J Roentgenol 2016; 207: pp. 67-79.</p><li><p>55. Wang S., Summers R.M.: Machine learning and radiology. Med Image Anal 2012; 16: pp. 933-951.</p><li><p>56. Mikolas P., Melicher T., Skoch A., et. al.: Connectivity of the anterior insula differentiates participants with first-episode schizophrenia spectrum disorders from controls: a machine-learning study. Psychol Med 2016; 46: pp. 2695-2704.</p><li><p>57. Collij L.E., Heeman F., Kuijer J.P.A., et. al.: Application of machine learning to arterial spin labeling in mild cognitive impairment and Alzheimer disease. Radiology 2016; 281: pp. 865-875.</p><li><p>58. Bryan R.N.: Machine learning applied to Alzheimer disease. Radiology 2016; 281: pp. 665-668.</p><li><p>59. Motwani M., Dey D., Berman D.S., et. al.: Machine learning for prediction of all-cause mortality in patients with suspected coronary artery disease: a 5-year multicentre prospective registry analysis. Eur Heart J 2016; 38: pp. 500-507. ehw188</p><li><p>60. Gaonkar B., Macyszyn L., Bilello M., et. al.: Automated tumor volumetry using computer-aided image segmentation. Acad Radiol 2015; 22: pp. 653-661.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-25/'>Volume 25</a>, <a href='/categories/issue-11/'>Issue 11</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Deep%20Learning%20in%20Radiology%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fdeep-learning-in-radiology%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Deep%20Learning%20in%20Radiology%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fdeep-learning-in-radiology%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fdeep-learning-in-radiology%2F&text=Deep%20Learning%20in%20Radiology%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/automated-breast-ultrasonography-abus-in-the-screening-and-diagnostic-setting/"><div class="card-body"> <em class="small" data-ts="1541005200" data-df="ll" > Oct 31, 2018 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Automated Breast Ultrasonography (ABUS) in the Screening and Diagnostic Setting</h3><div class="text-muted small"><p> Automated breast ultrasonography (ABUS) is a new imaging technology for automatic breast scanning through ultrasound. It was first developed to overcome the limitation of operator dependency and la...</p></div></div></a></div><div class="card"> <a href="/posts/change-in-nephrometry-scoring-in-small-renal-masses-4-cm-on-active-surveillance/"><div class="card-body"> <em class="small" data-ts="1541005200" data-df="ll" > Oct 31, 2018 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Change in Nephrometry Scoring in Small Renal Masses (<4 cm) on Active Surveillance</h3><div class="text-muted small"><p> Rationale and Objectives Prediction of growth, in particular knowing the possibility of aggressive cancer in small renal masses on active surveillance, remains poorly understood. The study was des...</p></div></div></a></div><div class="card"> <a href="/posts/comparison-of-natural-language-processing-rules-based-and-machine-learning-systems-to-identify-lumba/"><div class="card-body"> <em class="small" data-ts="1541005200" data-df="ll" > Oct 31, 2018 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Comparison of Natural Language Processing Rules-based and Machine-learning Systems to Identify Lumbar Spine Imaging Findings Related to Low Back Pain</h3><div class="text-muted small"><p> Rationale and Objectives To evaluate a natural language processing (NLP) system built with open-source tools for identification of lumbar spine imaging findings related to low back pain on magneti...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/cultivating-physician-character-in-diagnostic-radiology-through-virtuous-caring-and-collaborative-pr/" class="btn btn-outline-primary" prompt="Older"><p>Cultivating Physician Character in Diagnostic Radiology Through Virtuous Caring and Collaborative Professionalism</p></a> <a href="/posts/differentiation-of-benign-and-malignant-thyroid-nodules-by-using-comb-push-ultrasound-shear-elastogr/" class="btn btn-outline-primary" prompt="Newer"><p>Differentiation of Benign and Malignant Thyroid Nodules by Using Comb-push Ultrasound Shear Elastography</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>

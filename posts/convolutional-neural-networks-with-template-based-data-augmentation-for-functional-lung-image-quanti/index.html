<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Convolutional Neural Networks with Template-Based Data Augmentation for Functional Lung Image Quantification" /><meta property="og:locale" content="en" /><meta name="description" content="Rationale and Objectives" /><meta property="og:description" content="Rationale and Objectives" /><link rel="canonical" href="https://clinicaltree.github.io/posts/convolutional-neural-networks-with-template-based-data-augmentation-for-functional-lung-image-quanti/" /><meta property="og:url" content="https://clinicaltree.github.io/posts/convolutional-neural-networks-with-template-based-data-augmentation-for-functional-lung-image-quanti/" /><meta property="og:site_name" content="Radiology Tree" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-02-28T17:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Convolutional Neural Networks with Template-Based Data Augmentation for Functional Lung Image Quantification" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="RFHVRgQqK0eGjftEMCTDhsDrR8cJ_ZYcfCX52gXW8KM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-10T03:59:08+00:00","datePublished":"2019-02-28T17:00:00+00:00","description":"Rationale and Objectives","headline":"Convolutional Neural Networks with Template-Based Data Augmentation for Functional Lung Image Quantification","mainEntityOfPage":{"@type":"WebPage","@id":"https://clinicaltree.github.io/posts/convolutional-neural-networks-with-template-based-data-augmentation-for-functional-lung-image-quanti/"},"url":"https://clinicaltree.github.io/posts/convolutional-neural-networks-with-template-based-data-augmentation-for-functional-lung-image-quanti/"}</script><title>Convolutional Neural Networks with Template-Based Data Augmentation for Functional Lung Image Quantification | Radiology Tree</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Radiology Tree"><meta name="application-name" content="Radiology Tree"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://storage.googleapis.com/clinicalpub.com/images/favicon.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title"> <a href="/">Radiology Tree</a></div><div class="site-subtitle font-italic">Update every day the best and the lastest articles, books, journals, clinical cases, videos, images... for radiologist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/clinicaltree" aria-label="github" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['clinicalpub.team','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Convolutional Neural Networks with Template-Based Data Augmentation for Functional Lung Image Quantification</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Convolutional Neural Networks with Template-Based Data Augmentation for Functional Lung Image Quantification</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1551373200" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Feb 28, 2019 </em> </span> <span> Updated <em class="" data-ts="1681099148" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 10, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="">Nicholas J. Tustison DSc</a> </em>, <em> <a href="">Brian B. Avants</a> </em>, <em> <a href="">Zixuan Lin</a> </em>, <em> <a href="">Xue Feng</a> </em>, <em> <a href="">Nicholas Cullen</a> </em>, <em> <a href="">Jaime F. Mata</a> </em>, <em> <a href="">Lucia Flors</a> </em>, <em> <a href="">James C. Gee</a> </em>, <em> <a href="">Talissa A. Altes</a> </em>, <em> <a href="">III Mugler John P.</a> </em>, <em> <a href="">Kun Qing</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2861 words"> <em>15 min</em> read</span></div></div></div><div class="post-content"><h2 id="rationale-and-objectives"><span class="mr-2">Rationale and Objectives</span><a href="#rationale-and-objectives" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>We propose an automated segmentation pipeline based on deep learning for proton lung MRI segmentation and ventilation-based quantification which improves on our previously reported methodologies in terms of computational efficiency while demonstrating accuracy and robustness. The large data requirement for the proposed framework is made possible by a novel template-based data augmentation strategy. Supporting this work is the open-source <em>ANTsRNet</em> —a growing repository of well-known deep learning architectures first introduced here.</p><h2 id="materials-and-methods"><span class="mr-2">Materials and Methods</span><a href="#materials-and-methods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Deep convolutional neural network (CNN) models were constructed and trained using a custom multilabel Dice metric loss function and a novel template-based data augmentation strategy. Training (including template generation and data augmentation) employed 205 proton MR images and 73 functional lung MRI. Evaluation was performed using data sets of size 63 and 40 images, respectively.</p><h2 id="results"><span class="mr-2">Results</span><a href="#results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Accuracy for CNN-based proton lung MRI segmentation (in terms of Dice overlap) was left lung: 0.93 ± 0.03, right lung: 0.94 ± 0.02, and whole lung: 0.94 ± 0.02. Although slightly less accurate than our previously reported joint label fusion approach (left lung: 0.95 ± 0.02, right lung: 0.96 ± 0.01, and whole lung: 0.96 ± 0.01), processing time is &lt;1 second per subject for the proposed approach versus ∼30 minutes per subject using joint label fusion. Accuracy for quantifying ventilation defects was determined based on a consensus labeling where average accuracy (Dice multilabel overlap of ventilation defect regions plus normal region) was 0.94 for the CNN method; 0.92 for our previously reported method; and 0.90, 0.92, and 0.94 for expert readers.</p><h2 id="conclusion"><span class="mr-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The proposed framework yields accurate automated quantification in near real time. CNNs drastically reduce processing time after offline model construction and demonstrate significant future potential for facilitating quantitative analysis of functional lung MRI.</p><h2 id="introduction"><span class="mr-2">INTRODUCTION</span><a href="#introduction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Probing lung function under a variety of conditions and/or pathologies has been significantly facilitated by the use of hyperpolarized gas imaging and corresponding quantitative image analysis methodologies. Such developments have provided direction and opportunity for current and future research trends . Computational techniques targeting these imaging technologies permit spatial quantification of localized ventilation with potential for increased reproducibility, resolution, and robustness over traditional spirometry and radiological readings , .</p><p>One of the most frequently used image-based biomarkers for the study of pulmonary development and disease is based on the quantification of regions of limited ventilation, also known as <em>ventilation defects</em> . These features have been shown to be particularly salient in a clinical context. For example, ventilation defect volume to total lung volume ratio has been shown to outperform other image-based features in discriminating asthmatics versus nonasthmatics . Ventilation defects have also demonstrated discriminative capabilities in chronic obstructive pulmonary disease and asthma . These findings, along with related research, have motivated the development of multiple automated and semiautomated segmentation algorithms which have been proposed in the literature (eg, ) and are currently used in a variety of clinical research investigations (eg, ).</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="materials-and-methods-1"><span class="mr-2">MATERIALS AND METHODS</span><a href="#materials-and-methods-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="image-acquisition"><span class="mr-2">Image Acquisition</span><a href="#image-acquisition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="image-processing-and-analysis"><span class="mr-2">Image Processing and Analysis</span><a href="#image-processing-and-analysis" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/0_1s20S1076633218303878.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/0_1s20S1076633218303878.jpg" alt="Figure 1, Illustration of the proposed workflow. Training the U-net models for both proton and ventilation imaging includes template-based data augmentation. This offline training is computationally intensive but is only performed once. Subsequent individual subject preprocessing includes MR denoising and bias correction. The proton mask determined from the proton U-net model is included as a separate channel (in deep learning software parlance) for ventilation image processing. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="previous-approaches-from-our-group-for-lung-and-ventilation-based-segmentation"><span class="mr-2">Previous Approaches From Our Group for Lung and Ventilation-Based Segmentation</span><a href="#previous-approaches-from-our-group-for-lung-and-ventilation-based-segmentation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="preprocessing"><span class="mr-2">Preprocessing</span><a href="#preprocessing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/1_1s20S1076633218303878.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/1_1s20S1076633218303878.jpg" alt="Figure 2, Side-by-side image comparison showing the effects of preprocessing on the proton (top) and ventilation (bottom) MRI. (a) Uncorrected image showing MR field inhomogeneity and noise. (b) Corresponding corrected image in which the bias effects have been ameliorated." class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="u-net-architecture-for-structuralfunctional-lung-segmentation"><span class="mr-2">U-Net Architecture for Structural/Functional Lung Segmentation</span><a href="#u-net-architecture-for-structuralfunctional-lung-segmentation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/2_1s20S1076633218303878.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/2_1s20S1076633218303878.jpg" alt="Figure 3, The modified U-net architecture for both structural and functional lung segmentation (although certain parameters, specifically the number of filters per convolution layer, are specific to the functional case). Network layers are represented as boxes with arrows designating connections between layers. The main parameter value for each layer is provided above the corresponding box. Each layer of the descending (or “encoding”) branch of the network is characterized by two convolutional layers. Modification of the original architecture includes an intermediate dropout layer for regularization (dropout rate = 0.2). A max pooling operation produces the feature map for the next series. The ascending (or “decoding”) branch is similarly characterized. A convolutional transpose operation is used to upsample the feature map following a convolution → dropout → convolution layer series until the final convolutional operation which yields the segmentation probability maps. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="template-based-data-augmentation"><span class="mr-2">Template-Based Data Augmentation</span><a href="#template-based-data-augmentation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Snew=Ssource(φ−1target(φsource)) S</p><p>n</p><p>e</p><p>w</p><p>=</p><p>S</p><p>s</p><p>o</p><p>u</p><p>r</p><p>c</p><p>e</p><p>(</p><p>φ</p><p>t</p><p>a</p><p>r</p><p>g</p><p>e</p><p>t</p><p>−</p><p>1</p><p>(</p><p>φ</p><p>s</p><p>o</p><p>u</p><p>r</p><p>c</p><p>e</p><p>)</p><p>)</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/3_1s20S1076633218303878.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/3_1s20S1076633218303878.jpg" alt="Figure 4, Template-based data augmentation for the proton (left) and ventilation (right) U-net model generation. For both cases, a template is created, or selected, to generate the transforms to and from the template. The derived deformable, invertible transform for the k th subject, S k to the template, T , is denoted by φ k : S k ↔ T . These subject-specific mappings are used during model training (but not the template itself). Data augmentation occurs by randomly choosing a reference subject and a target subject during batch processing. In the illustration above, the sample mapping of Subject 1 to the space of Subject 2, represented by the green curved arrow, is defined as φ−12(φ1) φ2−1(φ1) . (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="antsrnet"><span class="mr-2">ANTsRNet</span><a href="#antsrnet" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>Table 1</p><p>Current ANTsRNet Capabilities Comprising Architectures for Applications in Image Segmentation, Image Classification, Object Localization, and Image Super-Resolution. Self-Contained Examples with Data are also Provided to Demonstrate Usage for Each of the Architectures. Although the Majority of Neural Network Architectures are Originally Described for 2-D Images, we Generalized the Work to 3-D Implementations Where Possible</p><p><strong>ANTsRNet</strong><strong>Image Segmentation</strong> U-net (2-D) Extends fully convolutional neural networks by including an upsampling decoding path with skip connections linking corresponding encoding/decoding layers. V-net (3-D) 3-D extension of U-net which incorporates a customized Dice loss function.<strong>Image Classification</strong> AlexNet (2-D, 3-D) Convolutional neural network that precipitated renewed interest in neural networks. VGG16/VGG19 (2-D, 3-D) Also known as “OxfordNet.” VGG architectures are much deeper than AlexNet. Two popular styles are implemented. GoogLeNet (2-D) A 22-layer network formed from <em>inception blocks</em> meant to reduce the number of parameters relative to other architectures. ResNet (2-D, 3-D) Characterized by specialized <em>residualized blocks</em> (and skip connections. ResNeXt (2-D, 3-D) A variant of ResNet distinguished by a hyperparameter called <em>cardinality</em> defining the number of independent paths. DenseNet (2-D, 3-D) Based on the observation that performance is typically enhanced with shorter connections between the layers and the input.<strong>Object Localization</strong> SSD (2-D, 3-D) The Multibox Single-Shot Detection (SSD) algorithm for determining bounding boxes around objects of interest. SSD7 (2-D, 3-D) Lightweight SSD variant which increases speed by slightly sacrificing accuracy. Training size requirements are smaller.<strong>Image super-resolution</strong> SRCNN (2-D, 3-D) Image super-resolution using CNNs.</p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="processing-specifics"><span class="mr-2">Processing Specifics</span><a href="#processing-specifics" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></ul></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><ul><li><p>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><li><p>- <a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p></ul></ul><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="results-1"><span class="mr-2">RESULTS</span><a href="#results-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h2 id="proton-mri-lung-segmentation"><span class="mr-2">Proton MRI Lung Segmentation</span><a href="#proton-mri-lung-segmentation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p>we applied it to the evaluation data consisting of the same 62 proton MRI used in . We performed a direct comparison with the JLF method of with an adopted modification that we currently use in our studies. Instead of using the entire atlas set (which would require a large number of pairwise image registrations), we align the center of the image to be segmented with each atlas image and compute a neighborhood cross-correlation similarity metric . We then select the 10 atlas images that are most similar for use in the JLF scheme. The resulting performance numbers (in terms of Dice overlap) are similar to what we obtained previously and are given in Figure 5 along with the Dice overlap numbers from the CNN-based approach.</p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/4_1s20S1076633218303878.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/4_1s20S1076633218303878.jpg" alt="Figure 5, The Dice overlap coefficient for the left and right lungs (and their combination) between the updated latter requires significantly less computation time. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="ventilation-mri-lung-segmentation"><span class="mr-2">Ventilation MRI Lung Segmentation</span><a href="#ventilation-mri-lung-segmentation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/5_1s20S1076633218303878.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/5_1s20S1076633218303878.jpg" alt="Figure 6, The Dice overlap coefficient for total, normal lung, and ventilation defect regions for segmentation of the functional evaluation data set. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="discussion"><span class="mr-2">DISCUSSION</span><a href="#discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/6_1s20S1076633218303878.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/6_1s20S1076633218303878.jpg" alt="Figure 7, Problematic case showing potential issues with the JLF approach (left) for proton lung segmentation where a difficult pairwise image registration caused segmentation failure. In contrast, by learning features directly, the U-net approach (right) avoids possible registration difficulties. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/7_1s20S1076633218303878.jpg" class="popup img-link "><img data-src="https://storage.googleapis.com/dl.dentistrykey.com/clinical/ConvolutionalNeuralNetworkswithTemplateBasedDataAugmentationforFunctionalLungImageQuantification/7_1s20S1076633218303878.jpg" alt="Figure 8, Ventilation segmentation comparison between a human reader and the two computational approaches. Notice the effects of the partial voluming at the apex of the lungs, indicated by the yellow arrow, which are labeled as ventilation defect by the Atropos approach whereas U-net and the human reader correctly label this region. (Color version of figure is available online.)" class="lazyload" data-proofer-ignore></a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="acknowledgments"><span class="mr-2">ACKNOWLEDGMENTS</span><a href="#acknowledgments" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><p><a href="https://clinicalpub.com/app">Get Radiology Tree app to read full this article&lt;</a></p><h2 id="references"><span class="mr-2">REFERENCES</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><p>1. Liu Z, Araki T, Okajima Y, et. al.: Pulmonary hyperpolarized noble gas MRI: recent advances and perspectives in clinical application. Eur J Radiol 2014; 83: pp. 1282-1291.</p><li><p>2. Roos JE, McAdams HP, Kaushik SS, et. al.: Hyperpolarized gas MR imaging: technique and applications. Magn Reson Imaging Clin N Am 2015; 23: pp. 217-229.</p><li><p>3. Adamson EB, Ludwig KD, Mummy DG, et. al.: Magnetic resonance imaging with hyperpolarized agents: methods and applications. Phys Med Biol 2017; 62: pp. R81-R123.</p><li><p>4. Svenningsen S, Kirby M, Starr D, et. al.: What are ventilation defects in asthma?. Thorax 2014; 69: pp. 63-71.</p><li><p>5. Tustison NJ, Altes TA, Song G, et. al.: Feature analysis of hyperpolarized helium-3 pulmonary MRI: a study of asthmatics versus nonasthmatics. Magn Reson Med 2010; 63: pp. 1448-1455.</p><li><p>6. Kirby M, Pike D, Coxson HO, et. al.: Hyperpolarized (3) He ventilation defects used to predict pulmonary exacerbations in mild to moderate chronic obstructive pulmonary disease. Radiology 2014; 273: pp. 887-896.</p><li><p>7. Altes TA, Mugler JP, Ruppert K, et. al.: Clinical correlates of lung ventilation defects in asthmatic children. J Allergy Clin Immunol 2016; 137: pp. 789-796. e7</p><li><p>8. Tustison NJ, Avants BB, Flors L, et. al.: Ventilation-based segmentation of the lungs using hyperpolarized (3) He MRI. J Magn Reson Imaging 2011; 34: pp. 831-841.</p><li><p>9. Kirby M, Heydarian M, Svenningsen S, et. al.: Hyperpolarized 3He magnetic resonance functional imaging semiautomated segmentation. Acad Radiol 2012; 19: pp. 141-152.</p><li><p>10. He M, Kaushik SS, Robertson SH, et. al.: Extending semiautomatic ventilation defect analysis for hyperpolarized (129)Xe ventilation MRI. Acad Radiol 2014; 21: pp. 1530-1541.</p><li><p>11. Zha W, Niles DJ, Kruger SJ, et. al.: Semiautomated ventilation defect quantification in exercise-induced bronchoconstriction using hyperpolarized helium-3 magnetic resonance imaging: a repeatability study. Acad Radiol 2016; 23: pp. 1104-1114.</p><li><p>12. Hughes PJC, Horn FC, Collier GJ, et. al.: Spatial fuzzy c-means thresholding for semiautomated calculation of percentage lung ventilated volume from hyperpolarized gas and 1 H MRI. J Magn Reson Imaging 2018; 47: pp. 640-646.</p><li><p>13. Trivedi A, Hall C, Hoffman EA, et. al.: Using imaging as a biomarker for asthma. J Allergy Clin Immunol 2017; 139: pp. 1-10.</p><li><p>14. LeCun Y, Bengio Y, Hinton G: Deep learning. Nature 2015; 521: pp. 436-444.</p><li><p>15. Russakovsky O, Deng J, Su H, et. al.: ImageNet large scale visual recognition challenge. Int J Comput Vis 2015; 115: pp. 211-252.</p><li><p>16. Krizhevsky A, Sutskever I, Hinton GE: ImageNet classification with deep convolutional neural networks.Proceedings of the 25th international conference on neural information processing systems - volume 1.2012.pp. 1097-1105. Available at http://dl.acm.org/citation.cfm? id=2999134.2999257</p><li><p>17. Simonyan K, Zisserman A: Very deep convolutional networks for large-scale image recognition. CoRR 2014; abs/1409.1556 2014. Available at: http://arxiv.org/abs/1409.1556</p><li><p>18. Szegedy C, Vanhoucke V, Ioffe S, et. al.: Rethinking the inception architecture for computer vision. CoRR 2015; abs/1512.00567 2015. Available at: http://arxiv.org/abs/1512.00567</p><li><p>19. LeCun Y, Bottou L, Bengio Y, et. al.: Gradient-based learning applied to document recognition. Proc IEEE 1998; 86: pp. 2278-2324.</p><li><p>20. Fukushima K: Neocognitron: a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biol Cybern 1980; 36: pp. 193-202.</p><li><p>21. Hubel DH, Wiesel TN: Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex. J Physiol 1962; 160: pp. 106-154.</p><li><p>22. Litjens G, Kooi T, Bejnordi BE, et. al.: A survey on deep learning in medical image analysis. Med Image Anal 2017; 42: pp. 60-88.</p><li><p>23. Ronneberger O, Fischer P, Brox T: U-net: convolutional networks for biomedical image segmentation. Proc Int Conf Med Image Comput Comput-Assist Interv 2015; 9351: pp. 234-241.</p><li><p>24. Tustison Nicholas J., Qing Kun, Wang Chengbo, Altes Talissa A, Mugler III John P: Atlas-based estimation of lung and lobar anatomy in proton MRI. Magn Reson Med Jul 2016; 76: pp. 315-320.</p><li><p>25. Taylor L, Nitschke G: Improving deep learning using generic data augmentation. CoRR 2017; abs/1708.06020, 2017. Available at: http://arxiv.org/abs/1708.06020</p><li><p>26. Tustison NJ, Avants BB: Explicit B-spline regularization in diffeomorphic image registration. Front Neuroinform 2013; 7: pp. 39.</p><li><p>27. Avants BB, Tustison NJ, Song G, et. al.: A reproducible evaluation of ANTs similarity metric performance in brain image registration. Neuroimage 2011; 54: pp. 2033-2044.</p><li><p>28. Available at: https://github.com/stnava/ANTsR</p><li><p>29. Available at: https://github.com/ntustison/DeepVentNet</p><li><p>30. Altes TA, Johnson M, Fidler M, et. al.: Use of hyperpolarized helium-3 MRI to assess response to ivacaftor treatment in patients with cystic fibrosis. J Cyst Fibros 2017; 16: pp. 267-274.</p><li><p>31. Tustison NJ, Avants BB, Cook PA, et. al.: N4ITK: improved N3 bias correction. IEEE Trans Med Imaging 2010; 29: pp. 1310-1320.</p><li><p>32. Qing K, Altes TA, Tustison NJ, et. al.: Rapid acquisition of helium-3 and proton three-dimensional image sets of the human lung in a single breath-hold using compressed sensing. Magn Reson Med 2015; 74: pp. 1110-1115.</p><li><p>33. Wang H, Suh JW, Das SR, et. al.: Multi-Atlas Segmentation with Joint Label Fusion. IEEE Trans Pattern Anal Machine Intell March 2013; 35: pp. 611-623.</p><li><p>34. Available at: https://github.com/ntustison/LungAndLobeEstimationExample</p><li><p>35. Available at: https://github.com/ntustison/LungVentilationSegmentationExample</p><li><p>36. Manjón JV, Coupé P, Martí-Bonmatí L, et. al.: Adaptive non-local means denoising of MR images with spatially varying noise levels. J Magn Reson Imaging 2010; 31: pp. 192-203.</p><li><p>37. Shelhamer E, Long J, Darrell T: Fully convolutional networks for semantic segmentation. IEEE Trans Pattern Anal Mach Intell 2017; 39: pp. 640-651.</p><li><p>38. Srivastava N, Hinton G, Krizhevsky A, et. al.: Dropout: a simple way to prevent neural networks from overfitting. J Machine Learn Res 2014; 15: pp. 1929-1958.</p><li><p>39. Available at: https://github.com/ANTsX/ANTsRNet</p><li><p>40. Avants BB, Yushkevich P, Pluta J, et. al.: The optimal template effect in hippocampus studies of diseased populations. Neuroimage 2010; 49: pp. 2457-2466.</p><li><p>41. Yang X, Kwitt R, Styner M, et. al.: Quicksilver: fast predictive image registration—a deep learning approach. Neuroimage 2017; 158: pp. 378-396.</p><li><p>42. Available at: https://doi.org/10.6084/m9.figshare.4964915.v1 .</p><li><p>43. Cullen NC, Avants BB: Convolutional neural networks for rapid and simultaneous brain extraction and tissue segmentation. Brain Morphometry 2018; 136: pp. 13-36.</p><li><p>44. Nair V, Hinton GE: Rectified linear units improve restricted Boltzmann machines.Proceedings of the 27th international conference on machine learning.2010.</p><li><p>45. Warfield SK, Zou KH, Wells WM: Simultaneous truth and performance level estimation (STAPLE): an algorithm for the validation of image segmentation. IEEE Trans Med Imaging 2004; 23: pp. 903-921.</p><li><p>46. Wong SC, Gatt A, Stamatescu V, et. al.: Understanding data augmentation for classification: when to warp?. CoRR 2016; abs/1609.08764, 2016</p><li><p>47. Milletari F, Navab N, Ahmadi S: V-net: fully convolutional neural networks for volumetric medical image segmentation. CoRR 2016; abs/1606.04797, 2016. Available at: http://arxiv.org/abs/1606.04797</p><li><p>48. He K, Zhang X, Ren S, et. al.: Deep residual learning for image recognition. CoRR 2015; abs/1512.03385, 2015. Available at: http://arxiv.org/abs/1512.03385</p><li><p>49. Xie S, Girshick RB, Dollár P, et. al.: Aggregated residual transformations for deep neural networks. CoRR 2016; abs/1611.05431, 2016. Available at: http://arxiv.org/abs/1611.05431</p><li><p>50. Huang G, Liu Z, Weinberger KQ: Densely connected convolutional networks. CoRR 2016; abs/1608.06993, 2016 Available at :http://arxiv.org/abs/1608.06993</p><li><p>51. Liu W, Anguelov D, Erhan D, et. al.: SSD: single shot multibox detector. CoRR 2015; abs/1512.02325, 2015. Available at: http://arxiv.org/abs/1512.02325</p><li><p>52. Available at: https://github.com/pierluigiferrari/ssd_keras</p><li><p>53. Dong C, Loy CC, He K, et. al.: Image super-resolution using deep convolutional networks. IEEE Trans Pattern Anal Mach Intell 2016; 38: pp. 295-307.</p></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/academic-radiology/'>Academic Radiology</a>, <a href='/categories/volume-26/'>Volume 26</a>, <a href='/categories/issue-3/'>Issue 3</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/journals/" class="post-tag no-text-decoration" >Journals</a> <a href="/tags/general-radiology/" class="post-tag no-text-decoration" >General Radiology</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Convolutional%20Neural%20Networks%20with%20Template-Based%20Data%20Augmentation%20for%20Functional%20Lung%20Image%20Quantification%20-%20Radiology%20Tree&url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fconvolutional-neural-networks-with-template-based-data-augmentation-for-functional-lung-image-quanti%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Convolutional%20Neural%20Networks%20with%20Template-Based%20Data%20Augmentation%20for%20Functional%20Lung%20Image%20Quantification%20-%20Radiology%20Tree&u=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fconvolutional-neural-networks-with-template-based-data-augmentation-for-functional-lung-image-quanti%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fclinicaltree.github.io%2Fposts%2Fconvolutional-neural-networks-with-template-based-data-augmentation-for-functional-lung-image-quanti%2F&text=Convolutional%20Neural%20Networks%20with%20Template-Based%20Data%20Augmentation%20for%20Functional%20Lung%20Image%20Quantification%20-%20Radiology%20Tree" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/neurometabolites-alteration-in-the-acute-phase-of-mild-traumatic-brain-injury-mtbi/">Neurometabolites Alteration in the Acute Phase of Mild Traumatic Brain Injury (mTBI)</a><li><a href="/posts/reinforcing-the-importance-and-feasibility-of-implementing-a-low-dose-protocol-for-ct-guided-biopsie/">Reinforcing the Importance and Feasibility of Implementing a Low-dose Protocol for CT-guided Biopsies</a><li><a href="/posts/rethinking-the-pgy-1-basic-clinical-year/">Rethinking the PGY-1 Basic Clinical Year</a><li><a href="/posts/single-injection-dual-phase-cone-beam-ct-dp-cbct-vascular-anatomy-assessment-and-occult-nodule-det/">Single Injection Dual-Phase Cone Beam CT (DP-CBCT) Vascular Anatomy Assessment and Occult Nodule Detection; Have We Reached the Focus?</a><li><a href="/posts/the-yellow-scale-is-superior-to-the-gray-scale-for-detecting-acute-ischemic-stroke-on-a-monitor-disp/">The Yellow Scale Is Superior to the Gray Scale for Detecting Acute Ischemic Stroke on a Monitor Display in Computed Tomography</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc"></nav></div><script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/current-advances-in-copd-imaging/"><div class="card-body"> <em class="small" data-ts="1551373200" data-df="ll" > Feb 28, 2019 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Current Advances in COPD Imaging</h3><div class="text-muted small"><p> Objective To review the recent advances in available technologies for imaging COPD and present the novel optical coherence tomography (OCT) airway imaging technology. Materials and Methods This ...</p></div></div></a></div><div class="card"> <a href="/posts/foreword-recent-developments-on-imaging-pulmonary-system/"><div class="card-body"> <em class="small" data-ts="1551373200" data-df="ll" > Feb 28, 2019 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Foreword Recent Developments on Imaging Pulmonary System</h3><div class="text-muted small"><p> A variety of imaging techniques have been utilized to study and further understand the pulmonary system over the past few decades. Researchers have refined and optimized techniques across a range o...</p></div></div></a></div><div class="card"> <a href="/posts/hyperpolarized-gas-magnetic-resonance-imaging-of-pediatric-cystic-fibrosis-lung-disease/"><div class="card-body"> <em class="small" data-ts="1551373200" data-df="ll" > Feb 28, 2019 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Hyperpolarized Gas Magnetic Resonance Imaging of Pediatric Cystic Fibrosis Lung Disease</h3><div class="text-muted small"><p> Conventional pulmonary function tests appear normal in early cystic fibrosis (CF) lung disease. Therefore, new diagnostic approaches are required that can detect CF lung disease in children and mon...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/applications-of-out-of-body-lung-perfusion/" class="btn btn-outline-primary" prompt="Older"><p>Applications of Out of Body Lung Perfusion</p></a> <a href="/posts/current-advances-in-copd-imaging/" class="btn btn-outline-primary" prompt="Newer"><p>Current Advances in COPD Imaging</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/general-radiology/">General Radiology</a> <a class="post-tag" href="/tags/journals/">Journals</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Clinical Team</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-L66SLQK23K"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-L66SLQK23K'); }); </script>
